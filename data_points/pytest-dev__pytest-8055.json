{
  "repo": "pytest-dev/pytest",
  "instance_id": "pytest-dev__pytest-8055",
  "base_commit": "d59a4996ae7d32498b2bd4c2f2a36eda4599a2e1",
  "patch": "diff --git a/src/_pytest/config/__init__.py b/src/_pytest/config/__init__.py\n--- a/src/_pytest/config/__init__.py\n+++ b/src/_pytest/config/__init__.py\n@@ -251,6 +251,7 @@ def directory_arg(path: str, optname: str) -> str:\n     \"warnings\",\n     \"logging\",\n     \"reports\",\n+    *([\"unraisableexception\", \"threadexception\"] if sys.version_info >= (3, 8) else []),\n     \"faulthandler\",\n )\n \ndiff --git a/src/_pytest/pytester.py b/src/_pytest/pytester.py\n--- a/src/_pytest/pytester.py\n+++ b/src/_pytest/pytester.py\n@@ -1349,7 +1349,7 @@ def run(\n                 stderr=f2,\n                 close_fds=(sys.platform != \"win32\"),\n             )\n-            if isinstance(stdin, bytes):\n+            if popen.stdin is not None:\n                 popen.stdin.close()\n \n             def handle_timeout() -> None:\ndiff --git a/src/_pytest/threadexception.py b/src/_pytest/threadexception.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/_pytest/threadexception.py\n@@ -0,0 +1,90 @@\n+import threading\n+import traceback\n+import warnings\n+from types import TracebackType\n+from typing import Any\n+from typing import Callable\n+from typing import Generator\n+from typing import Optional\n+from typing import Type\n+\n+import pytest\n+\n+\n+# Copied from cpython/Lib/test/support/threading_helper.py, with modifications.\n+class catch_threading_exception:\n+    \"\"\"Context manager catching threading.Thread exception using\n+    threading.excepthook.\n+\n+    Storing exc_value using a custom hook can create a reference cycle. The\n+    reference cycle is broken explicitly when the context manager exits.\n+\n+    Storing thread using a custom hook can resurrect it if it is set to an\n+    object which is being finalized. Exiting the context manager clears the\n+    stored object.\n+\n+    Usage:\n+        with threading_helper.catch_threading_exception() as cm:\n+            # code spawning a thread which raises an exception\n+            ...\n+            # check the thread exception: use cm.args\n+            ...\n+        # cm.args attribute no longer exists at this point\n+        # (to break a reference cycle)\n+    \"\"\"\n+\n+    def __init__(self) -> None:\n+        # See https://github.com/python/typeshed/issues/4767 regarding the underscore.\n+        self.args: Optional[\"threading._ExceptHookArgs\"] = None\n+        self._old_hook: Optional[Callable[[\"threading._ExceptHookArgs\"], Any]] = None\n+\n+    def _hook(self, args: \"threading._ExceptHookArgs\") -> None:\n+        self.args = args\n+\n+    def __enter__(self) -> \"catch_threading_exception\":\n+        self._old_hook = threading.excepthook\n+        threading.excepthook = self._hook\n+        return self\n+\n+    def __exit__(\n+        self,\n+        exc_type: Optional[Type[BaseException]],\n+        exc_val: Optional[BaseException],\n+        exc_tb: Optional[TracebackType],\n+    ) -> None:\n+        assert self._old_hook is not None\n+        threading.excepthook = self._old_hook\n+        self._old_hook = None\n+        del self.args\n+\n+\n+def thread_exception_runtest_hook() -> Generator[None, None, None]:\n+    with catch_threading_exception() as cm:\n+        yield\n+        if cm.args:\n+            if cm.args.thread is not None:\n+                thread_name = cm.args.thread.name\n+            else:\n+                thread_name = \"<unknown>\"\n+            msg = f\"Exception in thread {thread_name}\\n\\n\"\n+            msg += \"\".join(\n+                traceback.format_exception(\n+                    cm.args.exc_type, cm.args.exc_value, cm.args.exc_traceback,\n+                )\n+            )\n+            warnings.warn(pytest.PytestUnhandledThreadExceptionWarning(msg))\n+\n+\n+@pytest.hookimpl(hookwrapper=True, trylast=True)\n+def pytest_runtest_setup() -> Generator[None, None, None]:\n+    yield from thread_exception_runtest_hook()\n+\n+\n+@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n+def pytest_runtest_call() -> Generator[None, None, None]:\n+    yield from thread_exception_runtest_hook()\n+\n+\n+@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n+def pytest_runtest_teardown() -> Generator[None, None, None]:\n+    yield from thread_exception_runtest_hook()\ndiff --git a/src/_pytest/unraisableexception.py b/src/_pytest/unraisableexception.py\nnew file mode 100644\n--- /dev/null\n+++ b/src/_pytest/unraisableexception.py\n@@ -0,0 +1,93 @@\n+import sys\n+import traceback\n+import warnings\n+from types import TracebackType\n+from typing import Any\n+from typing import Callable\n+from typing import Generator\n+from typing import Optional\n+from typing import Type\n+\n+import pytest\n+\n+\n+# Copied from cpython/Lib/test/support/__init__.py, with modifications.\n+class catch_unraisable_exception:\n+    \"\"\"Context manager catching unraisable exception using sys.unraisablehook.\n+\n+    Storing the exception value (cm.unraisable.exc_value) creates a reference\n+    cycle. The reference cycle is broken explicitly when the context manager\n+    exits.\n+\n+    Storing the object (cm.unraisable.object) can resurrect it if it is set to\n+    an object which is being finalized. Exiting the context manager clears the\n+    stored object.\n+\n+    Usage:\n+        with catch_unraisable_exception() as cm:\n+            # code creating an \"unraisable exception\"\n+            ...\n+            # check the unraisable exception: use cm.unraisable\n+            ...\n+        # cm.unraisable attribute no longer exists at this point\n+        # (to break a reference cycle)\n+    \"\"\"\n+\n+    def __init__(self) -> None:\n+        self.unraisable: Optional[\"sys.UnraisableHookArgs\"] = None\n+        self._old_hook: Optional[Callable[[\"sys.UnraisableHookArgs\"], Any]] = None\n+\n+    def _hook(self, unraisable: \"sys.UnraisableHookArgs\") -> None:\n+        # Storing unraisable.object can resurrect an object which is being\n+        # finalized. Storing unraisable.exc_value creates a reference cycle.\n+        self.unraisable = unraisable\n+\n+    def __enter__(self) -> \"catch_unraisable_exception\":\n+        self._old_hook = sys.unraisablehook\n+        sys.unraisablehook = self._hook\n+        return self\n+\n+    def __exit__(\n+        self,\n+        exc_type: Optional[Type[BaseException]],\n+        exc_val: Optional[BaseException],\n+        exc_tb: Optional[TracebackType],\n+    ) -> None:\n+        assert self._old_hook is not None\n+        sys.unraisablehook = self._old_hook\n+        self._old_hook = None\n+        del self.unraisable\n+\n+\n+def unraisable_exception_runtest_hook() -> Generator[None, None, None]:\n+    with catch_unraisable_exception() as cm:\n+        yield\n+        if cm.unraisable:\n+            if cm.unraisable.err_msg is not None:\n+                err_msg = cm.unraisable.err_msg\n+            else:\n+                err_msg = \"Exception ignored in\"\n+            msg = f\"{err_msg}: {cm.unraisable.object!r}\\n\\n\"\n+            msg += \"\".join(\n+                traceback.format_exception(\n+                    cm.unraisable.exc_type,\n+                    cm.unraisable.exc_value,\n+                    cm.unraisable.exc_traceback,\n+                )\n+            )\n+            warnings.warn(pytest.PytestUnraisableExceptionWarning(msg))\n+\n+\n+@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n+def pytest_runtest_setup() -> Generator[None, None, None]:\n+    yield from unraisable_exception_runtest_hook()\n+\n+\n+@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n+def pytest_runtest_call() -> Generator[None, None, None]:\n+    yield from unraisable_exception_runtest_hook()\n+\n+\n+@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n+def pytest_runtest_teardown() -> Generator[None, None, None]:\n+    yield from unraisable_exception_runtest_hook()\ndiff --git a/src/_pytest/warning_types.py b/src/_pytest/warning_types.py\n--- a/src/_pytest/warning_types.py\n+++ b/src/_pytest/warning_types.py\n@@ -90,6 +90,28 @@ class PytestUnknownMarkWarning(PytestWarning):\n     __module__ = \"pytest\"\n \n \n+@final\n+class PytestUnraisableExceptionWarning(PytestWarning):\n+    \"\"\"An unraisable exception was reported.\n+\n+    Unraisable exceptions are exceptions raised in :meth:`__del__ <object.__del__>`\n+    implementations and similar situations when the exception cannot be raised\n+    as normal.\n+    \"\"\"\n+\n+    __module__ = \"pytest\"\n+\n+\n+@final\n+class PytestUnhandledThreadExceptionWarning(PytestWarning):\n+    \"\"\"An unhandled exception occurred in a :class:`~threading.Thread`.\n+\n+    Such exceptions don't propagate normally.\n+    \"\"\"\n+\n+    __module__ = \"pytest\"\n+\n+\n _W = TypeVar(\"_W\", bound=PytestWarning)\n \n \ndiff --git a/src/pytest/__init__.py b/src/pytest/__init__.py\n--- a/src/pytest/__init__.py\n+++ b/src/pytest/__init__.py\n@@ -44,7 +44,9 @@\n from _pytest.warning_types import PytestDeprecationWarning\n from _pytest.warning_types import PytestExperimentalApiWarning\n from _pytest.warning_types import PytestUnhandledCoroutineWarning\n+from _pytest.warning_types import PytestUnhandledThreadExceptionWarning\n from _pytest.warning_types import PytestUnknownMarkWarning\n+from _pytest.warning_types import PytestUnraisableExceptionWarning\n from _pytest.warning_types import PytestWarning\n \n set_trace = __pytestPDB.set_trace\n@@ -85,7 +87,9 @@\n     \"PytestDeprecationWarning\",\n     \"PytestExperimentalApiWarning\",\n     \"PytestUnhandledCoroutineWarning\",\n+    \"PytestUnhandledThreadExceptionWarning\",\n     \"PytestUnknownMarkWarning\",\n+    \"PytestUnraisableExceptionWarning\",\n     \"PytestWarning\",\n     \"raises\",\n     \"register_assert_rewrite\",\n",
  "test_patch": "diff --git a/testing/acceptance_test.py b/testing/acceptance_test.py\n--- a/testing/acceptance_test.py\n+++ b/testing/acceptance_test.py\n@@ -1288,3 +1288,6 @@ def test_no_brokenpipeerror_message(pytester: Pytester) -> None:\n     ret = popen.wait()\n     assert popen.stderr.read() == b\"\"\n     assert ret == 1\n+\n+    # Cleanup.\n+    popen.stderr.close()\ndiff --git a/testing/test_threadexception.py b/testing/test_threadexception.py\nnew file mode 100644\n--- /dev/null\n+++ b/testing/test_threadexception.py\n@@ -0,0 +1,137 @@\n+import sys\n+\n+import pytest\n+from _pytest.pytester import Pytester\n+\n+\n+if sys.version_info < (3, 8):\n+    pytest.skip(\"threadexception plugin needs Python>=3.8\", allow_module_level=True)\n+\n+\n+@pytest.mark.filterwarnings(\"default\")\n+def test_unhandled_thread_exception(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        import threading\n+\n+        def test_it():\n+            def oops():\n+                raise ValueError(\"Oops\")\n+\n+            t = threading.Thread(target=oops, name=\"MyThread\")\n+            t.start()\n+            t.join()\n+\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == 0\n+    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"*= warnings summary =*\",\n+            \"test_it.py::test_it\",\n+            \"  * PytestUnhandledThreadExceptionWarning: Exception in thread MyThread\",\n+            \"  \",\n+            \"  Traceback (most recent call last):\",\n+            \"  ValueError: Oops\",\n+            \"  \",\n+            \"    warnings.warn(pytest.PytestUnhandledThreadExceptionWarning(msg))\",\n+        ]\n+    )\n+\n+\n+@pytest.mark.filterwarnings(\"default\")\n+def test_unhandled_thread_exception_in_setup(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        import threading\n+        import pytest\n+\n+        @pytest.fixture\n+        def threadexc():\n+            def oops():\n+                raise ValueError(\"Oops\")\n+            t = threading.Thread(target=oops, name=\"MyThread\")\n+            t.start()\n+            t.join()\n+\n+        def test_it(threadexc): pass\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == 0\n+    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"*= warnings summary =*\",\n+            \"test_it.py::test_it\",\n+            \"  * PytestUnhandledThreadExceptionWarning: Exception in thread MyThread\",\n+            \"  \",\n+            \"  Traceback (most recent call last):\",\n+            \"  ValueError: Oops\",\n+            \"  \",\n+            \"    warnings.warn(pytest.PytestUnhandledThreadExceptionWarning(msg))\",\n+        ]\n+    )\n+\n+\n+@pytest.mark.filterwarnings(\"default\")\n+def test_unhandled_thread_exception_in_teardown(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        import threading\n+        import pytest\n+\n+        @pytest.fixture\n+        def threadexc():\n+            def oops():\n+                raise ValueError(\"Oops\")\n+            yield\n+            t = threading.Thread(target=oops, name=\"MyThread\")\n+            t.start()\n+            t.join()\n+\n+        def test_it(threadexc): pass\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == 0\n+    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"*= warnings summary =*\",\n+            \"test_it.py::test_it\",\n+            \"  * PytestUnhandledThreadExceptionWarning: Exception in thread MyThread\",\n+            \"  \",\n+            \"  Traceback (most recent call last):\",\n+            \"  ValueError: Oops\",\n+            \"  \",\n+            \"    warnings.warn(pytest.PytestUnhandledThreadExceptionWarning(msg))\",\n+        ]\n+    )\n+\n+\n+@pytest.mark.filterwarnings(\"error::pytest.PytestUnhandledThreadExceptionWarning\")\n+def test_unhandled_thread_exception_warning_error(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        import threading\n+        import pytest\n+\n+        def test_it():\n+            def oops():\n+                raise ValueError(\"Oops\")\n+            t = threading.Thread(target=oops, name=\"MyThread\")\n+            t.start()\n+            t.join()\n+\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == pytest.ExitCode.TESTS_FAILED\n+    assert result.parseoutcomes() == {\"passed\": 1, \"failed\": 1}\ndiff --git a/testing/test_unraisableexception.py b/testing/test_unraisableexception.py\nnew file mode 100644\n--- /dev/null\n+++ b/testing/test_unraisableexception.py\n@@ -0,0 +1,133 @@\n+import sys\n+\n+import pytest\n+from _pytest.pytester import Pytester\n+\n+\n+if sys.version_info < (3, 8):\n+    pytest.skip(\"unraisableexception plugin needs Python>=3.8\", allow_module_level=True)\n+\n+\n+@pytest.mark.filterwarnings(\"default\")\n+def test_unraisable(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        class BrokenDel:\n+            def __del__(self):\n+                raise ValueError(\"del is broken\")\n+\n+        def test_it():\n+            obj = BrokenDel()\n+            del obj\n+\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == 0\n+    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"*= warnings summary =*\",\n+            \"test_it.py::test_it\",\n+            \"  * PytestUnraisableExceptionWarning: Exception ignored in: <function BrokenDel.__del__ at *>\",\n+            \"  \",\n+            \"  Traceback (most recent call last):\",\n+            \"  ValueError: del is broken\",\n+            \"  \",\n+            \"    warnings.warn(pytest.PytestUnraisableExceptionWarning(msg))\",\n+        ]\n+    )\n+\n+\n+@pytest.mark.filterwarnings(\"default\")\n+def test_unraisable_in_setup(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        import pytest\n+\n+        class BrokenDel:\n+            def __del__(self):\n+                raise ValueError(\"del is broken\")\n+\n+        @pytest.fixture\n+        def broken_del():\n+            obj = BrokenDel()\n+            del obj\n+\n+        def test_it(broken_del): pass\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == 0\n+    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"*= warnings summary =*\",\n+            \"test_it.py::test_it\",\n+            \"  * PytestUnraisableExceptionWarning: Exception ignored in: <function BrokenDel.__del__ at *>\",\n+            \"  \",\n+            \"  Traceback (most recent call last):\",\n+            \"  ValueError: del is broken\",\n+            \"  \",\n+            \"    warnings.warn(pytest.PytestUnraisableExceptionWarning(msg))\",\n+        ]\n+    )\n+\n+\n+@pytest.mark.filterwarnings(\"default\")\n+def test_unraisable_in_teardown(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        import pytest\n+\n+        class BrokenDel:\n+            def __del__(self):\n+                raise ValueError(\"del is broken\")\n+\n+        @pytest.fixture\n+        def broken_del():\n+            yield\n+            obj = BrokenDel()\n+            del obj\n+\n+        def test_it(broken_del): pass\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == 0\n+    assert result.parseoutcomes() == {\"passed\": 2, \"warnings\": 1}\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"*= warnings summary =*\",\n+            \"test_it.py::test_it\",\n+            \"  * PytestUnraisableExceptionWarning: Exception ignored in: <function BrokenDel.__del__ at *>\",\n+            \"  \",\n+            \"  Traceback (most recent call last):\",\n+            \"  ValueError: del is broken\",\n+            \"  \",\n+            \"    warnings.warn(pytest.PytestUnraisableExceptionWarning(msg))\",\n+        ]\n+    )\n+\n+\n+@pytest.mark.filterwarnings(\"error::pytest.PytestUnraisableExceptionWarning\")\n+def test_unraisable_warning_error(pytester: Pytester) -> None:\n+    pytester.makepyfile(\n+        test_it=\"\"\"\n+        class BrokenDel:\n+            def __del__(self) -> None:\n+                raise ValueError(\"del is broken\")\n+\n+        def test_it() -> None:\n+            obj = BrokenDel()\n+            del obj\n+\n+        def test_2(): pass\n+        \"\"\"\n+    )\n+    result = pytester.runpytest()\n+    assert result.ret == pytest.ExitCode.TESTS_FAILED\n+    assert result.parseoutcomes() == {\"passed\": 1, \"failed\": 1}\n",
  "problem_statement": "set sys.unraisablehook (py38)\nPython 3.8 has a new hook: sys.unraisablehook https://github.com/python/cpython/pull/13187\r\n\r\nPytest should set this to be able to associate unraisable exceptions with tests\n",
  "hints_text": "Also running `gc.collect()` after every test and before resetting the hook can help spot which tests left unclosed files etc.\r\n\r\nThis may be something dedicated to a special mode - eg by default run gc.collect() at the end of the session, and print a message saying to enable the special mode to discover which test caused the problem\nThere are also sys.excepthook and threading.excepthook (new in Python 3.8). Collecting gc.collect() can slow down tests, but it helps to get the error reported in the correct test. Otherwise, an error (like a ResourceWarning) could be logged 1, 2 or 3 tests later which makes no sense when you look at the error. It happens to me frequently when I debug issues in Python buildbots (I'm maintaining the Python upstream CI, Python core & stdlib).\r\n\r\nI would suggest to only emit warnings, not get the tests fail, by default. Otherwise, I'm sure that many projects will be able to run their test suite anymore :-)\r\n\r\nIt's like trying to run a test suite using -Werror... good luck with that :-)\nThis will be nice to have.\r\n\r\nI think it should be straightforward to experiment with using a plugin. Some things the plugin might do are:\r\n\r\n- Set `sys.unraisablehook` for setup/call/teardown.\r\n- Set `threading.excepthook` for setup/call/teardown.\r\n- Add `gc.collect()` calls at appropriate times. Should probably be optional, default off, due to overhead. But can be enabled when want to debug `ResourceWarning`s.\r\n- Enable tracemalloc -- IIRC this makes `ResourceWarning`s more informative. Probably also default off due to overhead?\r\n\r\n(`sys.excepthook` I think is not relevant since pytest would catch any exception which propagates).\r\n\r\nSome questions are:\r\n- Are we OK taking features which don't work on all Python versions we support? If so, should it just no-op on these versions, or error?\r\n- What to do when a hook is triggered - failure, error, warning, make it configurable?\n`sys.excepthook` is relevant for threads that interact with the tes\r\ni think it should be configurable\r\n\r\nits not clear to me what we should do on python versions without the features\n> \r\n> \r\n> This will be nice to have.\r\n> \r\n> I think it should be straightforward to experiment with using a plugin. Some things the plugin might do are:\r\n\r\nmaybe we should close this issue as \"do it in a plugin\"\r\n\r\n> \r\n>     * Set `sys.unraisablehook` for setup/call/teardown.\r\n> \r\n>     * Set `threading.excepthook` for setup/call/teardown.\r\n\r\nwe should set the sys.unraisablehook once at import time, and then handle hook calls in pytests' own context management\r\n\r\n>     * Add `gc.collect()` calls at appropriate times. Should probably be optional, default off, due to overhead. But can be enabled when want to debug `ResourceWarning`s.\r\n> \r\n>     * Enable tracemalloc -- IIRC this makes `ResourceWarning`s more informative. Probably also default off due to overhead?\r\n> \r\n> \r\n> (`sys.excepthook` I think is not relevant since pytest would catch any exception which propagates).\r\n> \r\n> Some questions are:\r\n> \r\n>     * Are we OK taking features which don't work on all Python versions we support? If so, should it just no-op on these versions, or error?\r\n\r\nDoesn't (didn't) pytest already do this?\r\n\r\n>     * What to do when a hook is triggered - failure, error, warning, make it configurable?\r\n\r\nI think we can process hook calls separately during setup, call and teardown\r\n\r\n\nI've created a branch with plugins for unraisablehook and threading.excepthook: https://github.com/bluetech/pytest/commits/unraisable\r\n\r\nStill need to iron out some issues and polish it, then I will submit a PR for consideration.",
  "created_at": "2020-11-20T16:02:57Z",
  "version": "6.2",
  "FAIL_TO_PASS": "[\"testing/acceptance_test.py::TestGeneralUsage::test_docstring_on_hookspec\", \"testing/acceptance_test.py::TestGeneralUsage::test_plugins_given_as_strings\", \"testing/acceptance_test.py::TestInvocationVariants::test_equivalence_pytest_pydottest\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_with_invalid_type\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_with_path\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_plugin_api\", \"testing/acceptance_test.py::TestInvocationVariants::test_core_backward_compatibility\", \"testing/acceptance_test.py::TestInvocationVariants::test_has_plugin\", \"testing/acceptance_test.py::TestGeneralUsage::test_config_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_root_conftest_syntax_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_hook_error_issue38_1\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_hook_configure_error_issue38\", \"testing/acceptance_test.py::TestGeneralUsage::test_file_not_found\", \"testing/acceptance_test.py::TestGeneralUsage::test_file_not_found_unconfigure_issue143\", \"testing/acceptance_test.py::TestGeneralUsage::test_assertion_rewrite[prepend]\", \"testing/acceptance_test.py::TestGeneralUsage::test_assertion_rewrite[append]\", \"testing/acceptance_test.py::TestGeneralUsage::test_assertion_rewrite[importlib]\", \"testing/acceptance_test.py::TestGeneralUsage::test_nested_import_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_not_collectable_arguments\", \"testing/acceptance_test.py::TestGeneralUsage::test_better_reporting_on_conftest_load_failure\", \"testing/acceptance_test.py::TestGeneralUsage::test_early_skip\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue88_initial_file_multinodes\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue93_initialnode_importing_capturing\", \"testing/acceptance_test.py::TestGeneralUsage::test_conftest_printing_shows_if_error\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue109_sibling_conftests_not_loaded\", \"testing/acceptance_test.py::TestGeneralUsage::test_directory_skipped\", \"testing/acceptance_test.py::TestGeneralUsage::test_multiple_items_per_collector_byid\", \"testing/acceptance_test.py::TestGeneralUsage::test_skip_on_generated_funcarg_id\", \"testing/acceptance_test.py::TestGeneralUsage::test_direct_addressing_selects\", \"testing/acceptance_test.py::TestGeneralUsage::test_direct_addressing_notfound\", \"testing/acceptance_test.py::TestGeneralUsage::test_initialization_error_issue49\", \"testing/acceptance_test.py::TestGeneralUsage::test_issue134_report_error_when_collecting_member[test_fun.py::test_a]\", \"testing/acceptance_test.py::TestGeneralUsage::test_report_all_failed_collections_initargs\", \"testing/acceptance_test.py::TestGeneralUsage::test_namespace_import_doesnt_confuse_import_hook\", \"testing/acceptance_test.py::TestGeneralUsage::test_unknown_option\", \"testing/acceptance_test.py::TestGeneralUsage::test_getsourcelines_error_issue553\", \"testing/acceptance_test.py::TestGeneralUsage::test_parametrized_with_bytes_regex\", \"testing/acceptance_test.py::TestGeneralUsage::test_parametrized_with_null_bytes\", \"testing/acceptance_test.py::TestInvocationVariants::test_earlyinit\", \"testing/acceptance_test.py::TestInvocationVariants::test_pydoc\", \"testing/acceptance_test.py::TestInvocationVariants::test_import_star_py_dot_test\", \"testing/acceptance_test.py::TestInvocationVariants::test_import_star_pytest\", \"testing/acceptance_test.py::TestInvocationVariants::test_double_pytestcmdline\", \"testing/acceptance_test.py::TestInvocationVariants::test_python_minus_m_invocation_ok\", \"testing/acceptance_test.py::TestInvocationVariants::test_python_minus_m_invocation_fail\", \"testing/acceptance_test.py::TestInvocationVariants::test_python_pytest_package\", \"testing/acceptance_test.py::TestInvocationVariants::test_pyargs_filename_looks_like_module\", \"testing/acceptance_test.py::TestInvocationVariants::test_invoke_test_and_doctestmodules\", \"testing/acceptance_test.py::TestInvocationVariants::test_cmdline_python_package_not_exists\", \"testing/acceptance_test.py::TestInvocationVariants::test_doctest_id\", \"testing/acceptance_test.py::TestDurations::test_calls\", \"testing/acceptance_test.py::TestDurations::test_calls_show_2\", \"testing/acceptance_test.py::TestDurations::test_calls_showall\", \"testing/acceptance_test.py::TestDurations::test_calls_showall_verbose\", \"testing/acceptance_test.py::TestDurations::test_with_deselected\", \"testing/acceptance_test.py::TestDurations::test_with_failing_collection\", \"testing/acceptance_test.py::TestDurations::test_with_not\", \"testing/acceptance_test.py::TestDurationsWithFixture::test_setup_function\", \"testing/acceptance_test.py::test_zipimport_hook\", \"testing/acceptance_test.py::test_import_plugin_unicode_name\", \"testing/acceptance_test.py::test_pytest_plugins_as_module\", \"testing/acceptance_test.py::test_fixture_order_respects_scope\", \"testing/acceptance_test.py::test_fixture_mock_integration\", \"testing/acceptance_test.py::test_usage_error_code\", \"testing/acceptance_test.py::test_warn_on_async_function\", \"testing/acceptance_test.py::test_warn_on_async_gen_function\", \"testing/acceptance_test.py::test_no_brokenpipeerror_message\", \"testing/test_threadexception.py::test_unhandled_thread_exception\", \"testing/test_threadexception.py::test_unhandled_thread_exception_in_setup\", \"testing/test_threadexception.py::test_unhandled_thread_exception_in_teardown\", \"testing/test_threadexception.py::test_unhandled_thread_exception_warning_error\", \"testing/test_unraisableexception.py::test_unraisable\", \"testing/test_unraisableexception.py::test_unraisable_in_setup\", \"testing/test_unraisableexception.py::test_unraisable_in_teardown\", \"testing/test_unraisableexception.py::test_unraisable_warning_error\", \"testing/acceptance_test.py::test_fixture_values_leak\", \"testing/acceptance_test.py::test_frame_leak_on_failing_test\", \"testing/acceptance_test.py::test_pdb_can_be_rewritten\", \"testing/acceptance_test.py::test_tee_stdio_captures_and_live_prints\"]",
  "PASS_TO_PASS": "[]",
  "environment_setup_commit": "902739cfc3bbc3379e6ef99c8e250de35f52ecde",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.941146",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}