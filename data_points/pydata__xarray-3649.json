{
  "repo": "pydata/xarray",
  "instance_id": "pydata__xarray-3649",
  "base_commit": "3cbc459caa010f9b5042d3fa312b66c9b2b6c403",
  "patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -115,11 +115,12 @@ def _infer_concat_order_from_coords(datasets):\n     return combined_ids, concat_dims\n \n \n-def _check_shape_tile_ids(combined_tile_ids):\n+def _check_dimension_depth_tile_ids(combined_tile_ids):\n+    \"\"\"\n+    Check all tuples are the same length, i.e. check that all lists are\n+    nested to the same depth.\n+    \"\"\"\n     tile_ids = combined_tile_ids.keys()\n-\n-    # Check all tuples are the same length\n-    # i.e. check that all lists are nested to the same depth\n     nesting_depths = [len(tile_id) for tile_id in tile_ids]\n     if not nesting_depths:\n         nesting_depths = [0]\n@@ -128,8 +129,13 @@ def _check_shape_tile_ids(combined_tile_ids):\n             \"The supplied objects do not form a hypercube because\"\n             \" sub-lists do not have consistent depths\"\n         )\n+    # return these just to be reused in _check_shape_tile_ids\n+    return tile_ids, nesting_depths\n \n-    # Check all lists along one dimension are same length\n+\n+def _check_shape_tile_ids(combined_tile_ids):\n+    \"\"\"Check all lists along one dimension are same length.\"\"\"\n+    tile_ids, nesting_depths = _check_dimension_depth_tile_ids(combined_tile_ids)\n     for dim in range(nesting_depths[0]):\n         indices_along_dim = [tile_id[dim] for tile_id in tile_ids]\n         occurrences = Counter(indices_along_dim)\n@@ -536,7 +542,8 @@ def combine_by_coords(\n     coords : {'minimal', 'different', 'all' or list of str}, optional\n         As per the 'data_vars' kwarg, but for coordinate variables.\n     fill_value : scalar, optional\n-        Value to use for newly missing values\n+        Value to use for newly missing values. If None, raises a ValueError if\n+        the passed Datasets do not create a complete hypercube.\n     join : {'outer', 'inner', 'left', 'right', 'exact'}, optional\n         String indicating how to combine differing indexes\n         (excluding concat_dim) in objects\n@@ -653,6 +660,15 @@ def combine_by_coords(\n     temperature    (y, x) float64 1.654 10.63 7.015 2.543 ... 12.46 2.22 15.96\n     precipitation  (y, x) float64 0.2136 0.9974 0.7603 ... 0.6125 0.4654 0.5953\n \n+    >>> xr.combine_by_coords([x1, x2, x3])\n+    <xarray.Dataset>\n+    Dimensions:        (x: 6, y: 4)\n+    Coordinates:\n+    * x              (x) int64 10 20 30 40 50 60\n+    * y              (y) int64 0 1 2 3\n+    Data variables:\n+    temperature    (y, x) float64 1.654 10.63 7.015 nan ... 12.46 2.22 15.96\n+    precipitation  (y, x) float64 0.2136 0.9974 0.7603 ... 0.6125 0.4654 0.5953\n     \"\"\"\n \n     # Group by data vars\n@@ -667,7 +683,13 @@ def combine_by_coords(\n             list(datasets_with_same_vars)\n         )\n \n-        _check_shape_tile_ids(combined_ids)\n+        if fill_value is None:\n+            # check that datasets form complete hypercube\n+            _check_shape_tile_ids(combined_ids)\n+        else:\n+            # check only that all datasets have same dimension depth for these\n+            # vars\n+            _check_dimension_depth_tile_ids(combined_ids)\n \n         # Concatenate along all of concat_dims one by one to create single ds\n         concatenated = _combine_nd(\n",
  "test_patch": "diff --git a/xarray/tests/test_combine.py b/xarray/tests/test_combine.py\n--- a/xarray/tests/test_combine.py\n+++ b/xarray/tests/test_combine.py\n@@ -711,6 +711,22 @@ def test_check_for_impossible_ordering(self):\n         ):\n             combine_by_coords([ds1, ds0])\n \n+    def test_combine_by_coords_incomplete_hypercube(self):\n+        # test that this succeeds with default fill_value\n+        x1 = Dataset({\"a\": ((\"y\", \"x\"), [[1]])}, coords={\"y\": [0], \"x\": [0]})\n+        x2 = Dataset({\"a\": ((\"y\", \"x\"), [[1]])}, coords={\"y\": [1], \"x\": [0]})\n+        x3 = Dataset({\"a\": ((\"y\", \"x\"), [[1]])}, coords={\"y\": [0], \"x\": [1]})\n+        actual = combine_by_coords([x1, x2, x3])\n+        expected = Dataset(\n+            {\"a\": ((\"y\", \"x\"), [[1, 1], [1, np.nan]])},\n+            coords={\"y\": [0, 1], \"x\": [0, 1]},\n+        )\n+        assert_identical(expected, actual)\n+\n+        # test that this fails if fill_value is None\n+        with pytest.raises(ValueError):\n+            combine_by_coords([x1, x2, x3], fill_value=None)\n+\n \n @pytest.mark.filterwarnings(\n     \"ignore:In xarray version 0.15 `auto_combine` \" \"will be deprecated\"\n",
  "problem_statement": "combine_by_coords should allow for missing panels in hypercube\n#### MCVE Code Sample\r\n```python\r\nimport numpy as np\r\nimport xarray as xr\r\nx1 = xr.Dataset(\r\n     {\r\n         \"temperature\": ((\"y\", \"x\"), 20 * np.random.rand(6).reshape(2, 3))\r\n     },\r\n     coords={\"y\": [0, 1], \"x\": [10, 20, 30]},\r\n)\r\nx2 = xr.Dataset(\r\n     {\r\n         \"temperature\": ((\"y\", \"x\"), 20 * np.random.rand(6).reshape(2, 3))\r\n     },\r\n     coords={\"y\": [2, 3], \"x\": [10, 20, 30]},\r\n)\r\nx3 = xr.Dataset(\r\n     {\r\n         \"temperature\": ((\"y\", \"x\"), 20 * np.random.rand(6).reshape(2, 3))\r\n     },\r\n     coords={\"y\": [2, 3], \"x\": [40, 50, 60]},\r\n)\r\nxr.combine_by_coords([x1,x2,x3])\r\n```\r\n\r\n#### Expected Output\r\n```python\r\n<xarray.Dataset>\r\nDimensions:      (x: 6, y: 4)\r\nCoordinates:\r\n  * x            (x) int64 10 20 30 40 50 60\r\n  * y            (y) int64 0 1 2 3\r\nData variables:\r\n    temperature  (y, x) float64 14.11 19.19 10.77 nan ... 4.86 10.57 4.38 15.09\r\n```\r\n\r\n#### Problem Description\r\nCurrently, it throws the following error:\r\n```python\r\nValueError: The supplied objects do not form a hypercube because sub-lists do not have consistent lengths along dimension0\r\n```\r\nThis is b/c `combine_by_coords` calls `xr.core.combine._check_shape_tile_ids`, which mandates that the passed datasets form a complete hypercube. This check functiono also serves the purpose of mandating that the dimension depths are the same. Could we pull that part out as a separate function and, for `combine_by_coords`, only call this first part but NOT mandate that the hypercube is complete? The expected behavior, in my mind, should be to simply replace the missing tiles of the hypercube with `fill_value`. I'll file a PR to this effect and welcome comments.\r\n\r\n#### Output of ``xr.show_versions()``\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.7.3 | packaged by conda-forge | (default, Dec  6 2019, 08:54:18) \r\n[GCC 7.3.0]\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.14.150+\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: en_US.UTF-8\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\nlibhdf5: 1.10.5\r\nlibnetcdf: 4.7.1\r\n\r\nxarray: 0.14.1\r\npandas: 0.25.3\r\nnumpy: 1.17.3\r\nscipy: 1.3.2\r\nnetCDF4: 1.5.3\r\npydap: None\r\nh5netcdf: 0.7.4\r\nh5py: 2.10.0\r\nNio: None\r\nzarr: 2.3.2\r\ncftime: 1.0.4.2\r\nnc_time_axis: 1.2.0\r\nPseudoNetCDF: None\r\nrasterio: 1.1.1\r\ncfgrib: None\r\niris: 2.2.0\r\nbottleneck: None\r\ndask: 2.8.1\r\ndistributed: 2.8.1\r\nmatplotlib: 3.1.2\r\ncartopy: 0.17.0\r\nseaborn: 0.9.0\r\nnumbagg: None\r\nsetuptools: 42.0.2.post20191201\r\npip: 19.3.1\r\nconda: 4.8.0\r\npytest: 5.3.1\r\nIPython: 7.10.1\r\nsphinx: 2.2.2\r\n</details>\r\n\n",
  "hints_text": "",
  "created_at": "2019-12-19T22:08:11Z",
  "version": "0.12",
  "FAIL_TO_PASS": "[\"xarray/tests/test_combine.py::TestCombineAuto::test_combine_by_coords_incomplete_hypercube\"]",
  "PASS_TO_PASS": "[\"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_1d\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_2d\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_3d\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_single_dataset\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_redundant_nesting\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_ignore_empty_list\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_uneven_depth_input\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_uneven_length_input\", \"xarray/tests/test_combine.py::TestTileIDsFromNestedList::test_infer_from_datasets\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_1d\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_2d\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_no_dimension_coords\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_coord_not_monotonic\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_coord_monotonically_decreasing\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_no_concatenation_needed\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_2d_plus_bystander_dim\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_string_coords\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_lexicographic_sort_string_coords\", \"xarray/tests/test_combine.py::TestTileIDsFromCoords::test_datetime_coords\", \"xarray/tests/test_combine.py::TestNewTileIDs::test_new_tile_id[old_id0-new_id0]\", \"xarray/tests/test_combine.py::TestNewTileIDs::test_new_tile_id[old_id1-new_id1]\", \"xarray/tests/test_combine.py::TestNewTileIDs::test_new_tile_id[old_id2-new_id2]\", \"xarray/tests/test_combine.py::TestNewTileIDs::test_new_tile_id[old_id3-new_id3]\", \"xarray/tests/test_combine.py::TestNewTileIDs::test_new_tile_id[old_id4-new_id4]\", \"xarray/tests/test_combine.py::TestNewTileIDs::test_get_new_tile_ids\", \"xarray/tests/test_combine.py::TestCombineND::test_concat_once[dim1]\", \"xarray/tests/test_combine.py::TestCombineND::test_concat_once[new_dim]\", \"xarray/tests/test_combine.py::TestCombineND::test_concat_only_first_dim\", \"xarray/tests/test_combine.py::TestCombineND::test_concat_twice[dim1]\", \"xarray/tests/test_combine.py::TestCombineND::test_concat_twice[new_dim]\", \"xarray/tests/test_combine.py::TestCheckShapeTileIDs::test_check_depths\", \"xarray/tests/test_combine.py::TestCheckShapeTileIDs::test_check_lengths\", \"xarray/tests/test_combine.py::TestNestedCombine::test_nested_concat\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_join[outer-expected0]\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_join[inner-expected1]\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_join[left-expected2]\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_join[right-expected3]\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_join_exact\", \"xarray/tests/test_combine.py::TestNestedCombine::test_empty_input\", \"xarray/tests/test_combine.py::TestNestedCombine::test_nested_concat_along_new_dim\", \"xarray/tests/test_combine.py::TestNestedCombine::test_nested_merge\", \"xarray/tests/test_combine.py::TestNestedCombine::test_concat_multiple_dims\", \"xarray/tests/test_combine.py::TestNestedCombine::test_concat_name_symmetry\", \"xarray/tests/test_combine.py::TestNestedCombine::test_concat_one_dim_merge_another\", \"xarray/tests/test_combine.py::TestNestedCombine::test_auto_combine_2d\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_missing_data_new_dim\", \"xarray/tests/test_combine.py::TestNestedCombine::test_invalid_hypercube_input\", \"xarray/tests/test_combine.py::TestNestedCombine::test_merge_one_dim_concat_another\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_concat_over_redundant_nesting\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_fill_value[fill_value0]\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_fill_value[2]\", \"xarray/tests/test_combine.py::TestNestedCombine::test_combine_nested_fill_value[2.0]\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_by_coords\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_coords_join[outer-expected0]\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_coords_join[inner-expected1]\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_coords_join[left-expected2]\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_coords_join[right-expected3]\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_coords_join_exact\", \"xarray/tests/test_combine.py::TestCombineAuto::test_infer_order_from_coords\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_leaving_bystander_dimensions\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_by_coords_previously_failed\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_by_coords_still_fails\", \"xarray/tests/test_combine.py::TestCombineAuto::test_combine_by_coords_no_concat\", \"xarray/tests/test_combine.py::TestCombineAuto::test_check_for_impossible_ordering\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine_previously_failed\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine_with_new_variables\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine_no_concat\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine_order_by_appearance_not_coords\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine_fill_value[fill_value0]\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine_fill_value[2]\", \"xarray/tests/test_combine.py::TestAutoCombineOldAPI::test_auto_combine_fill_value[2.0]\", \"xarray/tests/test_combine.py::TestAutoCombineDeprecation::test_auto_combine_with_concat_dim\", \"xarray/tests/test_combine.py::TestAutoCombineDeprecation::test_auto_combine_with_merge_and_concat\", \"xarray/tests/test_combine.py::TestAutoCombineDeprecation::test_auto_combine_with_coords\", \"xarray/tests/test_combine.py::TestAutoCombineDeprecation::test_auto_combine_without_coords\"]",
  "environment_setup_commit": "1c198a191127c601d091213c4b3292a8bb3054e1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.872994",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}