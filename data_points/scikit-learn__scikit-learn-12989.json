{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-12989",
  "base_commit": "ff46f6e594efb2bd7adbeba0cf5f26d5cb3a6231",
  "patch": "diff --git a/sklearn/decomposition/nmf.py b/sklearn/decomposition/nmf.py\n--- a/sklearn/decomposition/nmf.py\n+++ b/sklearn/decomposition/nmf.py\n@@ -261,9 +261,11 @@ def _initialize_nmf(X, n_components, init=None, eps=1e-6,\n \n     init :  None | 'random' | 'nndsvd' | 'nndsvda' | 'nndsvdar'\n         Method used to initialize the procedure.\n-        Default: 'nndsvd' if n_components < n_features, otherwise 'random'.\n+        Default: None.\n         Valid options:\n \n+        - None: 'nndsvd' if n_components < n_features, otherwise 'random'.\n+\n         - 'random': non-negative random matrices, scaled with:\n             sqrt(X.mean() / n_components)\n \n@@ -831,7 +833,7 @@ def _fit_multiplicative_update(X, W, H, beta_loss='frobenius',\n \n \n def non_negative_factorization(X, W=None, H=None, n_components=None,\n-                               init='random', update_H=True, solver='cd',\n+                               init='warn', update_H=True, solver='cd',\n                                beta_loss='frobenius', tol=1e-4,\n                                max_iter=200, alpha=0., l1_ratio=0.,\n                                regularization=None, random_state=None,\n@@ -878,11 +880,17 @@ def non_negative_factorization(X, W=None, H=None, n_components=None,\n         Number of components, if n_components is not set all features\n         are kept.\n \n-    init :  None | 'random' | 'nndsvd' | 'nndsvda' | 'nndsvdar' | 'custom'\n+    init : None | 'random' | 'nndsvd' | 'nndsvda' | 'nndsvdar' | 'custom'\n         Method used to initialize the procedure.\n         Default: 'random'.\n+\n+        The default value will change from 'random' to None in version 0.23\n+        to make it consistent with decomposition.NMF.\n+\n         Valid options:\n \n+        - None: 'nndsvd' if n_components < n_features, otherwise 'random'.\n+\n         - 'random': non-negative random matrices, scaled with:\n             sqrt(X.mean() / n_components)\n \n@@ -1009,6 +1017,13 @@ def non_negative_factorization(X, W=None, H=None, n_components=None,\n         raise ValueError(\"Tolerance for stopping criteria must be \"\n                          \"positive; got (tol=%r)\" % tol)\n \n+    if init == \"warn\":\n+        if n_components < n_features:\n+            warnings.warn(\"The default value of init will change from \"\n+                          \"random to None in 0.23 to make it consistent \"\n+                          \"with decomposition.NMF.\", FutureWarning)\n+        init = \"random\"\n+\n     # check W and H, or initialize them\n     if init == 'custom' and update_H:\n         _check_init(H, (n_components, n_features), \"NMF (input H)\")\n@@ -1087,11 +1102,13 @@ class NMF(BaseEstimator, TransformerMixin):\n         Number of components, if n_components is not set all features\n         are kept.\n \n-    init :  'random' | 'nndsvd' |  'nndsvda' | 'nndsvdar' | 'custom'\n+    init : None | 'random' | 'nndsvd' |  'nndsvda' | 'nndsvdar' | 'custom'\n         Method used to initialize the procedure.\n-        Default: 'nndsvd' if n_components < n_features, otherwise random.\n+        Default: None.\n         Valid options:\n \n+        - None: 'nndsvd' if n_components < n_features, otherwise random.\n+\n         - 'random': non-negative random matrices, scaled with:\n             sqrt(X.mean() / n_components)\n \n",
  "test_patch": "diff --git a/sklearn/decomposition/tests/test_nmf.py b/sklearn/decomposition/tests/test_nmf.py\n--- a/sklearn/decomposition/tests/test_nmf.py\n+++ b/sklearn/decomposition/tests/test_nmf.py\n@@ -10,6 +10,7 @@\n import pytest\n \n from sklearn.utils.testing import assert_raise_message, assert_no_warnings\n+from sklearn.utils.testing import assert_warns_message\n from sklearn.utils.testing import assert_array_equal\n from sklearn.utils.testing import assert_array_almost_equal\n from sklearn.utils.testing import assert_almost_equal\n@@ -213,13 +214,16 @@ def test_non_negative_factorization_checking():\n     A = np.ones((2, 2))\n     # Test parameters checking is public function\n     nnmf = non_negative_factorization\n-    assert_no_warnings(nnmf, A, A, A, np.int64(1))\n+    msg = (\"The default value of init will change from \"\n+           \"random to None in 0.23 to make it consistent \"\n+           \"with decomposition.NMF.\")\n+    assert_warns_message(FutureWarning, msg, nnmf, A, A, A, np.int64(1))\n     msg = (\"Number of components must be a positive integer; \"\n            \"got (n_components=1.5)\")\n-    assert_raise_message(ValueError, msg, nnmf, A, A, A, 1.5)\n+    assert_raise_message(ValueError, msg, nnmf, A, A, A, 1.5, 'random')\n     msg = (\"Number of components must be a positive integer; \"\n            \"got (n_components='2')\")\n-    assert_raise_message(ValueError, msg, nnmf, A, A, A, '2')\n+    assert_raise_message(ValueError, msg, nnmf, A, A, A, '2', 'random')\n     msg = \"Negative values in data passed to NMF (input H)\"\n     assert_raise_message(ValueError, msg, nnmf, A, A, -A, 2, 'custom')\n     msg = \"Negative values in data passed to NMF (input W)\"\n@@ -380,8 +384,8 @@ def test_nmf_negative_beta_loss():\n \n     def _assert_nmf_no_nan(X, beta_loss):\n         W, H, _ = non_negative_factorization(\n-            X, n_components=n_components, solver='mu', beta_loss=beta_loss,\n-            random_state=0, max_iter=1000)\n+            X, init='random', n_components=n_components, solver='mu',\n+            beta_loss=beta_loss, random_state=0, max_iter=1000)\n         assert not np.any(np.isnan(W))\n         assert not np.any(np.isnan(H))\n \n",
  "problem_statement": "`NMF` and `non_negative_factorization` have inconsistent default init\n<!--\r\nIf your issue is a usage question, submit it here instead:\r\n- StackOverflow with the scikit-learn tag: https://stackoverflow.com/questions/tagged/scikit-learn\r\n- Mailing List: https://mail.python.org/mailman/listinfo/scikit-learn\r\nFor more information, see User Questions: http://scikit-learn.org/stable/support.html#user-questions\r\n-->\r\n\r\n<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\r\n\r\n#### Description\r\n<!-- Example: Joblib Error thrown when calling fit on LatentDirichletAllocation with evaluate_every > 0-->\r\n`NMF` and `non_negative_factorization` have inconsistent default init. `NMF` has `init=None` while `non_negative_factorization` has `init='random'`.\r\n\r\nSee #11667 \r\n\r\nAs suggested, we could change the default in `non_negative_factorization` with a deprecation process.\r\n\r\n<!--\r\n#### Steps/Code to Reproduce\r\n\r\nExample:\r\n```python\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\nfrom sklearn.decomposition import LatentDirichletAllocation\r\n\r\ndocs = [\"Help I have a bug\" for i in range(1000)]\r\n\r\nvectorizer = CountVectorizer(input=docs, analyzer='word')\r\nlda_features = vectorizer.fit_transform(docs)\r\n\r\nlda_model = LatentDirichletAllocation(\r\n    n_topics=10,\r\n    learning_method='online',\r\n    evaluate_every=10,\r\n    n_jobs=4,\r\n)\r\nmodel = lda_model.fit(lda_features)\r\n```\r\nIf the code is too long, feel free to put it in a public gist and link\r\nit in the issue: https://gist.github.com\r\n-->\r\n\r\n<!--\r\n#### Expected Results\r\n Example: No error is thrown. Please paste or describe the expected results.-->\r\n\r\n<!--\r\n#### Actual Results\r\n Please paste or specifically describe the actual output or traceback. -->\r\n\r\n<!--\r\n#### Versions\r\n\r\nPlease run the following snippet and paste the output below.\r\nFor scikit-learn >= 0.20:\r\nimport sklearn; sklearn.show_versions()\r\nFor scikit-learn < 0.20:\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport numpy; print(\"NumPy\", numpy.__version__)\r\nimport scipy; print(\"SciPy\", scipy.__version__)\r\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\r\n-->\r\n\r\n\r\n<!-- Thanks for contributing! -->\n",
  "hints_text": "",
  "created_at": "2019-01-16T07:19:16Z",
  "version": "0.21",
  "FAIL_TO_PASS": "[\"sklearn/decomposition/tests/test_nmf.py::test_non_negative_factorization_checking\"]",
  "PASS_TO_PASS": "[\"sklearn/decomposition/tests/test_nmf.py::test_initialize_nn_output\", \"sklearn/decomposition/tests/test_nmf.py::test_parameter_checking\", \"sklearn/decomposition/tests/test_nmf.py::test_initialize_close\", \"sklearn/decomposition/tests/test_nmf.py::test_initialize_variants\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_fit_nn_output\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_fit_close[cd]\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_fit_close[mu]\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_transform[cd]\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_transform[mu]\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_transform_custom_init\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_inverse_transform[cd]\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_inverse_transform[mu]\", \"sklearn/decomposition/tests/test_nmf.py::test_n_components_greater_n_features\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_sparse_input\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_sparse_transform\", \"sklearn/decomposition/tests/test_nmf.py::test_non_negative_factorization_consistency\", \"sklearn/decomposition/tests/test_nmf.py::test_beta_divergence\", \"sklearn/decomposition/tests/test_nmf.py::test_special_sparse_dot\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_multiplicative_update_sparse\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_negative_beta_loss\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_regularization\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_decreasing\", \"sklearn/decomposition/tests/test_nmf.py::test_nmf_underflow\"]",
  "environment_setup_commit": "7813f7efb5b2012412888b69e73d76f2df2b50b6",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.978777",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}