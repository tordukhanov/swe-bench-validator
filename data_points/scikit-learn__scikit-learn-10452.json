{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-10452",
  "base_commit": "3e5469eda719956c076ae8e685ec1183bfd98569",
  "patch": "diff --git a/sklearn/preprocessing/data.py b/sklearn/preprocessing/data.py\n--- a/sklearn/preprocessing/data.py\n+++ b/sklearn/preprocessing/data.py\n@@ -1325,7 +1325,7 @@ def fit(self, X, y=None):\n         -------\n         self : instance\n         \"\"\"\n-        n_samples, n_features = check_array(X).shape\n+        n_samples, n_features = check_array(X, accept_sparse=True).shape\n         combinations = self._combinations(n_features, self.degree,\n                                           self.interaction_only,\n                                           self.include_bias)\n@@ -1338,31 +1338,42 @@ def transform(self, X):\n \n         Parameters\n         ----------\n-        X : array-like, shape [n_samples, n_features]\n+        X : array-like or sparse matrix, shape [n_samples, n_features]\n             The data to transform, row by row.\n+            Sparse input should preferably be in CSC format.\n \n         Returns\n         -------\n-        XP : np.ndarray shape [n_samples, NP]\n+        XP : np.ndarray or CSC sparse matrix, shape [n_samples, NP]\n             The matrix of features, where NP is the number of polynomial\n             features generated from the combination of inputs.\n         \"\"\"\n         check_is_fitted(self, ['n_input_features_', 'n_output_features_'])\n \n-        X = check_array(X, dtype=FLOAT_DTYPES)\n+        X = check_array(X, dtype=FLOAT_DTYPES, accept_sparse='csc')\n         n_samples, n_features = X.shape\n \n         if n_features != self.n_input_features_:\n             raise ValueError(\"X shape does not match training shape\")\n \n-        # allocate output data\n-        XP = np.empty((n_samples, self.n_output_features_), dtype=X.dtype)\n-\n         combinations = self._combinations(n_features, self.degree,\n                                           self.interaction_only,\n                                           self.include_bias)\n-        for i, c in enumerate(combinations):\n-            XP[:, i] = X[:, c].prod(1)\n+        if sparse.isspmatrix(X):\n+            columns = []\n+            for comb in combinations:\n+                if comb:\n+                    out_col = 1\n+                    for col_idx in comb:\n+                        out_col = X[:, col_idx].multiply(out_col)\n+                    columns.append(out_col)\n+                else:\n+                    columns.append(sparse.csc_matrix(np.ones((X.shape[0], 1))))\n+            XP = sparse.hstack(columns, dtype=X.dtype).tocsc()\n+        else:\n+            XP = np.empty((n_samples, self.n_output_features_), dtype=X.dtype)\n+            for i, comb in enumerate(combinations):\n+                XP[:, i] = X[:, comb].prod(1)\n \n         return XP\n \n",
  "test_patch": "diff --git a/sklearn/preprocessing/tests/test_data.py b/sklearn/preprocessing/tests/test_data.py\n--- a/sklearn/preprocessing/tests/test_data.py\n+++ b/sklearn/preprocessing/tests/test_data.py\n@@ -7,10 +7,12 @@\n \n import warnings\n import re\n+\n import numpy as np\n import numpy.linalg as la\n from scipy import sparse, stats\n from distutils.version import LooseVersion\n+import pytest\n \n from sklearn.utils import gen_batches\n \n@@ -155,6 +157,28 @@ def test_polynomial_feature_names():\n                        feature_names)\n \n \n+@pytest.mark.parametrize(['deg', 'include_bias', 'interaction_only', 'dtype'],\n+                         [(1, True, False, int),\n+                          (2, True, False, int),\n+                          (2, True, False, np.float32),\n+                          (2, True, False, np.float64),\n+                          (3, False, False, np.float64),\n+                          (3, False, True, np.float64)])\n+def test_polynomial_features_sparse_X(deg, include_bias, interaction_only,\n+                                      dtype):\n+    rng = np.random.RandomState(0)\n+    X = rng.randint(0, 2, (100, 2))\n+    X_sparse = sparse.csr_matrix(X)\n+\n+    est = PolynomialFeatures(deg, include_bias=include_bias)\n+    Xt_sparse = est.fit_transform(X_sparse.astype(dtype))\n+    Xt_dense = est.fit_transform(X.astype(dtype))\n+\n+    assert isinstance(Xt_sparse, sparse.csc_matrix)\n+    assert Xt_sparse.dtype == Xt_dense.dtype\n+    assert_array_almost_equal(Xt_sparse.A, Xt_dense)\n+\n+\n def test_standard_scaler_1d():\n     # Test scaling of dataset along single axis\n     for X in [X_1row, X_1col, X_list_1row, X_list_1row]:\n",
  "problem_statement": "Polynomial Features for sparse data\nI'm not sure if that came up before but PolynomialFeatures doesn't support sparse data, which is not great. Should be easy but I haven't checked ;)\n",
  "hints_text": "I'll take this up.\n@dalmia @amueller any news on this feature? We're eagerly anticipating it ;-)\r\n\nSee also #3512, #3514\nFor the benefit of @amueller, my [comment](https://github.com/scikit-learn/scikit-learn/pull/8380#issuecomment-299164291) on #8380:\r\n\r\n>  [@jnothman] closed both #3512 and #3514 at the time, in favor of #4286, but sparsity is still not conserved. Is there some way to get attention back to the issue of sparse polynomial features?\n@jnothman Thanks! :smiley: \nThis should be pretty straightforward to solve. I've given a couple of options at https://github.com/scikit-learn/scikit-learn/pull/8380#issuecomment-299120531.\r\n\r\nWould a contributor like to take it up? @SebastinSanty, perhaps?\n@jnothman Yes, I would like to take it up.\nIt will be very useful for me, @SebastinSanty when will it be available, even your develop branch:)\nDoes \"Polynomial Features for sparse data\" implemented? \r\nI also asked a question about this in [Stackoverflow](https://stackoverflow.com/questions/48199391/how-to-make-polynomial-features-using-sparse-matrix-in-scikit-learn)\nI've had enough of people asking for this and it not getting closed, despite almost all the work having been done. I'll open a PR soon.",
  "created_at": "2018-01-11T06:56:51Z",
  "version": "0.20",
  "FAIL_TO_PASS": "[\"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[1-True-False-int]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[2-True-False-int]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[2-True-False-float32]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[2-True-False-float64]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[3-False-False-float64]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[3-False-True-float64]\"]",
  "PASS_TO_PASS": "[\"sklearn/preprocessing/tests/test_data.py::test_polynomial_features\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_feature_names\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_scale_1d\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_numerical_stability\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_2d_arrays\", \"sklearn/preprocessing/tests/test_data.py::test_handle_zeros_in_scale\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_partial_fit_numerical_stability\", \"sklearn/preprocessing/tests/test_data.py::test_partial_fit_sparse_input\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_trasform_with_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_iris\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scale_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_without_centering\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_int\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_without_copy\", \"sklearn/preprocessing/tests/test_data.py::test_scale_sparse_with_mean_raise_exception\", \"sklearn/preprocessing/tests/test_data.py::test_scale_input_finiteness_validation\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_2d_arrays\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_transform_one_row_csr\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_iris\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_iris_quantiles\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_iris\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_check_error\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_sparse_ignore_zeros\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_dense_toy\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_subsampling\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_sparse_toy\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_bounds\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_and_inverse\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_invalid_range\", \"sklearn/preprocessing/tests/test_data.py::test_scale_function_without_centering\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scale_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scale_1d_array\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_large_negative_value\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_transform_one_row_csr\", \"sklearn/preprocessing/tests/test_data.py::test_warning_scaling_integers\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_l1\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_l2\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_max\", \"sklearn/preprocessing/tests/test_data.py::test_normalize\", \"sklearn/preprocessing/tests/test_data.py::test_binarizer\", \"sklearn/preprocessing/tests/test_data.py::test_center_kernel\", \"sklearn/preprocessing/tests/test_data.py::test_cv_pipeline_precomputed\", \"sklearn/preprocessing/tests/test_data.py::test_fit_transform\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_coo\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_csc\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_csr\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_sparse\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_dense\", \"sklearn/preprocessing/tests/test_data.py::test_transform_selected\", \"sklearn/preprocessing/tests/test_data.py::test_transform_selected_copy_arg\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_categorical_features\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_unknown_transform\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_onehot\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_onehot_inverse\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_handle_unknown\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_categories\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_specified_categories\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_pandas\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_ordinal\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_ordinal_inverse\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_dtypes\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_dtypes_pandas\", \"sklearn/preprocessing/tests/test_data.py::test_fit_cold_start\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_valid_axis\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_notfitted\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_1d\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_2d\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_strictly_positive_exception\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_shape_exception\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_method_exception\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_lambda_zero\"]",
  "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.951048",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}