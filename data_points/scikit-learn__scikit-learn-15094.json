{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-15094",
  "base_commit": "871b25162339c60557e5bf1754ea553ec33adf52",
  "patch": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -453,6 +453,8 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n     dtypes_orig = None\n     if hasattr(array, \"dtypes\") and hasattr(array.dtypes, '__array__'):\n         dtypes_orig = np.array(array.dtypes)\n+        if all(isinstance(dtype, np.dtype) for dtype in dtypes_orig):\n+            dtype_orig = np.result_type(*array.dtypes)\n \n     if dtype_numeric:\n         if dtype_orig is not None and dtype_orig.kind == \"O\":\n",
  "test_patch": "diff --git a/sklearn/utils/tests/test_validation.py b/sklearn/utils/tests/test_validation.py\n--- a/sklearn/utils/tests/test_validation.py\n+++ b/sklearn/utils/tests/test_validation.py\n@@ -42,7 +42,8 @@\n     _num_samples,\n     check_scalar,\n     _check_sample_weight,\n-    _allclose_dense_sparse)\n+    _allclose_dense_sparse,\n+    FLOAT_DTYPES)\n import sklearn\n \n from sklearn.exceptions import NotFittedError\n@@ -351,6 +352,45 @@ def test_check_array_pandas_dtype_object_conversion():\n     assert check_array(X_df, ensure_2d=False).dtype.kind == \"f\"\n \n \n+def test_check_array_pandas_dtype_casting():\n+    # test that data-frames with homogeneous dtype are not upcast\n+    pd = pytest.importorskip('pandas')\n+    X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)\n+    X_df = pd.DataFrame(X)\n+    assert check_array(X_df).dtype == np.float32\n+    assert check_array(X_df, dtype=FLOAT_DTYPES).dtype == np.float32\n+\n+    X_df.iloc[:, 0] = X_df.iloc[:, 0].astype(np.float16)\n+    assert_array_equal(X_df.dtypes,\n+                       (np.float16, np.float32, np.float32))\n+    assert check_array(X_df).dtype == np.float32\n+    assert check_array(X_df, dtype=FLOAT_DTYPES).dtype == np.float32\n+\n+    X_df.iloc[:, 1] = X_df.iloc[:, 1].astype(np.int16)\n+    # float16, int16, float32 casts to float32\n+    assert check_array(X_df).dtype == np.float32\n+    assert check_array(X_df, dtype=FLOAT_DTYPES).dtype == np.float32\n+\n+    X_df.iloc[:, 2] = X_df.iloc[:, 2].astype(np.float16)\n+    # float16, int16, float16 casts to float32\n+    assert check_array(X_df).dtype == np.float32\n+    assert check_array(X_df, dtype=FLOAT_DTYPES).dtype == np.float32\n+\n+    X_df = X_df.astype(np.int16)\n+    assert check_array(X_df).dtype == np.int16\n+    # we're not using upcasting rules for determining\n+    # the target type yet, so we cast to the default of float64\n+    assert check_array(X_df, dtype=FLOAT_DTYPES).dtype == np.float64\n+\n+    # check that we handle pandas dtypes in a semi-reasonable way\n+    # this is actually tricky because we can't really know that this\n+    # should be integer ahead of converting it.\n+    cat_df = pd.DataFrame([pd.Categorical([1, 2, 3])])\n+    assert (check_array(cat_df).dtype == np.int64)\n+    assert (check_array(cat_df, dtype=FLOAT_DTYPES).dtype\n+            == np.float64)\n+\n+\n def test_check_array_on_mock_dataframe():\n     arr = np.array([[0.2, 0.7], [0.6, 0.5], [0.4, 0.1], [0.7, 0.2]])\n     mock_df = MockDataFrame(arr)\n",
  "problem_statement": "MaxAbsScaler Upcasts Pandas to float64\n<!--\r\nIf your issue is a usage question, submit it here instead:\r\n- StackOverflow with the scikit-learn tag: https://stackoverflow.com/questions/tagged/scikit-learn\r\n- Mailing List: https://mail.python.org/mailman/listinfo/scikit-learn\r\nFor more information, see User Questions: http://scikit-learn.org/stable/support.html#user-questions\r\n-->\r\n\r\n<!-- Instructions For Filing a Bug: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#filing-bugs -->\r\n\r\n#### Description\r\nI am working with the Column transformer, and for memory issues, am trying to produce a float32 sparse matrix. Unfortunately, regardless of pandas input type, the output is always float64.\r\n\r\nI've identified one of the Pipeline scalers, MaxAbsScaler, as being the culprit. Other preprocessing functions, such as OneHotEncoder, have an optional `dtype` argument. This argument does not exist in MaxAbsScaler (among others). It appears that the upcasting happens when `check_array` is executed.\r\n\r\nIs it possible to specify a dtype? Or is there a commonly accepted practice to do so from the Column Transformer?\r\n\r\nThank you!\r\n#### Steps/Code to Reproduce\r\nExample:\r\n```python\r\nimport pandas as pd\r\nfrom sklearn.preprocessing import MaxAbsScaler\r\n\r\ndf = pd.DataFrame({\r\n    'DOW': [0, 1, 2, 3, 4, 5, 6],\r\n    'Month': [3, 2, 4, 3, 2, 6, 7],\r\n    'Value': [3.4, 4., 8, 5, 3, 6, 4]\r\n})\r\ndf = df.astype('float32')\r\nprint(df.dtypes)\r\na = MaxAbsScaler()\r\nscaled = a.fit_transform(df) # providing df.values will produce correct response\r\nprint('Transformed Type: ', scaled.dtype)\r\n```\r\n\r\n#### Expected Results\r\n```\r\nDOW      float32\r\nMonth    float32\r\nValue    float32\r\ndtype: object\r\nTransformed Type: float32\r\n```\r\n\r\n#### Actual Results\r\n```\r\nDOW      float32\r\nMonth    float32\r\nValue    float32\r\ndtype: object\r\nTransformed Type: float64\r\n```\r\n\r\n#### Versions\r\nDarwin-18.7.0-x86_64-i386-64bit\r\nPython 3.6.7 | packaged by conda-forge | (default, Jul  2 2019, 02:07:37) \r\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\r\nNumPy 1.17.1\r\nSciPy 1.3.1\r\nScikit-Learn 0.20.3\r\nPandas 0.25.1\r\n\n",
  "hints_text": "It should probably be preserving dtype. It doesn't look like this issue\nshould result from check_array, which looks like it is set up to preserve\ndtype in MaxAbsScaler.\n\nCan you please confirm that this is still an issue in scikit-learn 0.21\n(you have an old version)?\n\nThanks for the quick response! \r\nSame issue with 0.21.3\r\n\r\n```\r\nDarwin-18.7.0-x86_64-i386-64bit\r\nPython 3.6.7 | packaged by conda-forge | (default, Jul  2 2019, 02:07:37) \r\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\r\nNumPy 1.17.1\r\nSciPy 1.3.1\r\nScikit-Learn 0.21.3\r\nPandas 0.25.1\r\n```\r\n\r\nUpon a closer look, this might be a bug in check_array, though I don't know enough about its desired functionality to comment. `MaxAbsScaler` calls `check_array` with `dtype=FLOAT_DTYPES` which has the value`['float64', 'float32', 'float16']`. In `check_array`,  pandas dtypes are properly pulled but not used. Instead, `check_array` pulls the dtype from first list item in the supplied `dtype=FLOAT_DTYPES`, which results in 'float64'. I placed inline comments next to what I think is going on:\r\n\r\n```python\r\ndtypes_orig = None\r\nif hasattr(array, \"dtypes\") and hasattr(array.dtypes, '__array__'):\r\n    dtypes_orig = np.array(array.dtypes) # correctly pulls the float32 dtypes from pandas\r\n\r\nif dtype_numeric:\r\n    if dtype_orig is not None and dtype_orig.kind == \"O\":\r\n        # if input is object, convert to float.\r\n        dtype = np.float64\r\n    else:\r\n        dtype = None\r\n\r\nif isinstance(dtype, (list, tuple)):\r\n    if dtype_orig is not None and dtype_orig in dtype:\r\n        # no dtype conversion required\r\n        dtype = None\r\n    else:\r\n        # dtype conversion required. Let's select the first element of the\r\n        # list of accepted types.\r\n        dtype = dtype[0] # Should this be dtype = dtypes_orig[0]? dtype[0] is always float64\r\n```\r\nThanks again!\nIt shouldn't be going down that path... It should be using the \"no dtype\nconversion required\" path\n\nCan confirm it's a bug in the handling of pandas introduced here: #10949\r\nIf dtypes has more then one entry we need to figure out the best cast, right?\r\nHere we're in the simple case where ``len(unique(dtypes)))==1`` which is easy to fix.",
  "created_at": "2019-09-25T22:03:47Z",
  "version": "0.22",
  "FAIL_TO_PASS": "[\"sklearn/utils/tests/test_validation.py::test_check_array_pandas_dtype_casting\"]",
  "PASS_TO_PASS": "[\"sklearn/utils/tests/test_validation.py::test_as_float_array\", \"sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X0]\", \"sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X1]\", \"sklearn/utils/tests/test_validation.py::test_np_matrix\", \"sklearn/utils/tests/test_validation.py::test_memmap\", \"sklearn/utils/tests/test_validation.py::test_ordering\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-inf-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-allow-nan]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-inf-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-allow-nan]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-inf-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-inf-allow-nan-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-nan-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-nan-allow-inf-force_all_finite\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-nan-1-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-inf-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-inf-allow-nan-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-nan-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-nan-allow-inf-force_all_finite\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-nan-1-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[True-X0-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[True-X1-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[True-X2-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[True-X3-cannot\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[False-X0-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[False-X1-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[False-X2-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_object_unsafe_casting[False-X3-cannot\", \"sklearn/utils/tests/test_validation.py::test_check_array\", \"sklearn/utils/tests/test_validation.py::test_check_array_pandas_dtype_object_conversion\", \"sklearn/utils/tests/test_validation.py::test_check_array_on_mock_dataframe\", \"sklearn/utils/tests/test_validation.py::test_check_array_dtype_stability\", \"sklearn/utils/tests/test_validation.py::test_check_array_dtype_warning\", \"sklearn/utils/tests/test_validation.py::test_check_array_warn_on_dtype_deprecation\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_type_exception\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_no_exception\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[csr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[csc]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[coo]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[bsr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[csr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[csc]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[coo]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[bsr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_min_samples_and_features_messages\", \"sklearn/utils/tests/test_validation.py::test_check_array_complex_data_error\", \"sklearn/utils/tests/test_validation.py::test_has_fit_parameter\", \"sklearn/utils/tests/test_validation.py::test_check_symmetric\", \"sklearn/utils/tests/test_validation.py::test_check_is_fitted\", \"sklearn/utils/tests/test_validation.py::test_check_consistent_length\", \"sklearn/utils/tests/test_validation.py::test_check_dataframe_fit_attribute\", \"sklearn/utils/tests/test_validation.py::test_suppress_validation\", \"sklearn/utils/tests/test_validation.py::test_check_array_series\", \"sklearn/utils/tests/test_validation.py::test_check_dataframe_warns_on_dtype\", \"sklearn/utils/tests/test_validation.py::test_check_memory\", \"sklearn/utils/tests/test_validation.py::test_check_array_memmap[True]\", \"sklearn/utils/tests/test_validation.py::test_check_array_memmap[False]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[asarray]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[csr_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[csc_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[coo_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[lil_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[bsr_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[dok_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[dia_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_X_y_informative_error\", \"sklearn/utils/tests/test_validation.py::test_retrieve_samples_from_non_standard_shape\", \"sklearn/utils/tests/test_validation.py::test_check_scalar_valid[3-int-2-5]\", \"sklearn/utils/tests/test_validation.py::test_check_scalar_valid[2.5-float-2-5]\", \"sklearn/utils/tests/test_validation.py::test_check_scalar_invalid[1-test_name1-float-2-4-err_msg0]\", \"sklearn/utils/tests/test_validation.py::test_check_scalar_invalid[1-test_name2-int-2-4-err_msg1]\", \"sklearn/utils/tests/test_validation.py::test_check_scalar_invalid[5-test_name3-int-2-4-err_msg2]\", \"sklearn/utils/tests/test_validation.py::test_check_sample_weight\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_equals[array]\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_equals[csr_matrix]\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_equals[csc_matrix]\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_not_equals[array]\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_not_equals[csr_matrix]\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_not_equals[csc_matrix]\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_raise[csr_matrix]\", \"sklearn/utils/tests/test_validation.py::test_allclose_dense_sparse_raise[csc_matrix]\"]",
  "environment_setup_commit": "7e85a6d1f038bbb932b36f18d75df6be937ed00d",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.011001",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}