{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-25747",
  "base_commit": "2c867b8f822eb7a684f0d5c4359e4426e1c9cfe0",
  "patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -34,7 +34,7 @@ def _wrap_in_pandas_container(\n         `range(n_features)`.\n \n     index : array-like, default=None\n-        Index for data.\n+        Index for data. `index` is ignored if `data_to_wrap` is already a DataFrame.\n \n     Returns\n     -------\n@@ -55,8 +55,6 @@ def _wrap_in_pandas_container(\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n-            data_to_wrap.index = index\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
  "test_patch": "diff --git a/sklearn/utils/tests/test_set_output.py b/sklearn/utils/tests/test_set_output.py\n--- a/sklearn/utils/tests/test_set_output.py\n+++ b/sklearn/utils/tests/test_set_output.py\n@@ -33,7 +33,9 @@ def test__wrap_in_pandas_container_dense_update_columns_and_index():\n \n     new_df = _wrap_in_pandas_container(X_df, columns=new_columns, index=new_index)\n     assert_array_equal(new_df.columns, new_columns)\n-    assert_array_equal(new_df.index, new_index)\n+\n+    # Index does not change when the input is a DataFrame\n+    assert_array_equal(new_df.index, X_df.index)\n \n \n def test__wrap_in_pandas_container_error_validation():\n@@ -260,3 +262,33 @@ class C(A, B):\n         pass\n \n     assert C().transform(None) == \"B\"\n+\n+\n+class EstimatorWithSetOutputIndex(_SetOutputMixin):\n+    def fit(self, X, y=None):\n+        self.n_features_in_ = X.shape[1]\n+        return self\n+\n+    def transform(self, X, y=None):\n+        import pandas as pd\n+\n+        # transform by giving output a new index.\n+        return pd.DataFrame(X.to_numpy(), index=[f\"s{i}\" for i in range(X.shape[0])])\n+\n+    def get_feature_names_out(self, input_features=None):\n+        return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n+\n+\n+def test_set_output_pandas_keep_index():\n+    \"\"\"Check that set_output does not override index.\n+\n+    Non-regression test for gh-25730.\n+    \"\"\"\n+    pd = pytest.importorskip(\"pandas\")\n+\n+    X = pd.DataFrame([[1, 2, 3], [4, 5, 6]], index=[0, 1])\n+    est = EstimatorWithSetOutputIndex().set_output(transform=\"pandas\")\n+    est.fit(X)\n+\n+    X_trans = est.transform(X)\n+    assert_array_equal(X_trans.index, [\"s0\", \"s1\"])\n",
  "problem_statement": "FeatureUnion not working when aggregating data and pandas transform output selected\n### Describe the bug\n\nI would like to use `pandas` transform output and use a custom transformer in a feature union which aggregates data. When I'm using this combination I got an error. When I use default `numpy` output it works fine.\n\n### Steps/Code to Reproduce\n\n```python\r\nimport pandas as pd\r\nfrom sklearn.base import BaseEstimator, TransformerMixin\r\nfrom sklearn import set_config\r\nfrom sklearn.pipeline import make_union\r\n\r\nindex = pd.date_range(start=\"2020-01-01\", end=\"2020-01-05\", inclusive=\"left\", freq=\"H\")\r\ndata = pd.DataFrame(index=index, data=[10] * len(index), columns=[\"value\"])\r\ndata[\"date\"] = index.date\r\n\r\n\r\nclass MyTransformer(BaseEstimator, TransformerMixin):\r\n    def fit(self, X: pd.DataFrame, y: pd.Series | None = None, **kwargs):\r\n        return self\r\n\r\n    def transform(self, X: pd.DataFrame, y: pd.Series | None = None) -> pd.DataFrame:\r\n        return X[\"value\"].groupby(X[\"date\"]).sum()\r\n\r\n\r\n# This works.\r\nset_config(transform_output=\"default\")\r\nprint(make_union(MyTransformer()).fit_transform(data))\r\n\r\n# This does not work.\r\nset_config(transform_output=\"pandas\")\r\nprint(make_union(MyTransformer()).fit_transform(data))\r\n```\n\n### Expected Results\n\nNo error is thrown when using `pandas` transform output.\n\n### Actual Results\n\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[5], line 25\r\n     23 # This does not work.\r\n     24 set_config(transform_output=\"pandas\")\r\n---> 25 print(make_union(MyTransformer()).fit_transform(data))\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/utils/_set_output.py:150, in _wrap_method_output.<locals>.wrapped(self, X, *args, **kwargs)\r\n    143 if isinstance(data_to_wrap, tuple):\r\n    144     # only wrap the first output for cross decomposition\r\n    145     return (\r\n    146         _wrap_data_with_container(method, data_to_wrap[0], X, self),\r\n    147         *data_to_wrap[1:],\r\n    148     )\r\n--> 150 return _wrap_data_with_container(method, data_to_wrap, X, self)\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/utils/_set_output.py:130, in _wrap_data_with_container(method, data_to_wrap, original_input, estimator)\r\n    127     return data_to_wrap\r\n    129 # dense_config == \"pandas\"\r\n--> 130 return _wrap_in_pandas_container(\r\n    131     data_to_wrap=data_to_wrap,\r\n    132     index=getattr(original_input, \"index\", None),\r\n    133     columns=estimator.get_feature_names_out,\r\n    134 )\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/utils/_set_output.py:59, in _wrap_in_pandas_container(data_to_wrap, columns, index)\r\n     57         data_to_wrap.columns = columns\r\n     58     if index is not None:\r\n---> 59         data_to_wrap.index = index\r\n     60     return data_to_wrap\r\n     62 return pd.DataFrame(data_to_wrap, index=index, columns=columns)\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/generic.py:5588, in NDFrame.__setattr__(self, name, value)\r\n   5586 try:\r\n   5587     object.__getattribute__(self, name)\r\n-> 5588     return object.__setattr__(self, name, value)\r\n   5589 except AttributeError:\r\n   5590     pass\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/_libs/properties.pyx:70, in pandas._libs.properties.AxisProperty.__set__()\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/generic.py:769, in NDFrame._set_axis(self, axis, labels)\r\n    767 def _set_axis(self, axis: int, labels: Index) -> None:\r\n    768     labels = ensure_index(labels)\r\n--> 769     self._mgr.set_axis(axis, labels)\r\n    770     self._clear_item_cache()\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/internals/managers.py:214, in BaseBlockManager.set_axis(self, axis, new_labels)\r\n    212 def set_axis(self, axis: int, new_labels: Index) -> None:\r\n    213     # Caller is responsible for ensuring we have an Index object.\r\n--> 214     self._validate_set_axis(axis, new_labels)\r\n    215     self.axes[axis] = new_labels\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/internals/base.py:69, in DataManager._validate_set_axis(self, axis, new_labels)\r\n     66     pass\r\n     68 elif new_len != old_len:\r\n---> 69     raise ValueError(\r\n     70         f\"Length mismatch: Expected axis has {old_len} elements, new \"\r\n     71         f\"values have {new_len} elements\"\r\n     72     )\r\n\r\nValueError: Length mismatch: Expected axis has 4 elements, new values have 96 elements\r\n```\n\n### Versions\n\n```shell\nSystem:\r\n    python: 3.10.6 (main, Aug 30 2022, 05:11:14) [Clang 13.0.0 (clang-1300.0.29.30)]\r\nexecutable: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/bin/python\r\n   machine: macOS-11.3-x86_64-i386-64bit\r\n\r\nPython dependencies:\r\n      sklearn: 1.2.1\r\n          pip: 22.3.1\r\n   setuptools: 67.3.2\r\n        numpy: 1.23.5\r\n        scipy: 1.10.1\r\n       Cython: None\r\n       pandas: 1.4.4\r\n   matplotlib: 3.7.0\r\n       joblib: 1.2.0\r\nthreadpoolctl: 3.1.0\r\n\r\nBuilt with OpenMP: True\r\n\r\nthreadpoolctl info:\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/numpy/.dylibs/libopenblas64_.0.dylib\r\n        version: 0.3.20\r\nthreading_layer: pthreads\r\n   architecture: Haswell\r\n    num_threads: 4\r\n\r\n       user_api: openmp\r\n   internal_api: openmp\r\n         prefix: libomp\r\n       filepath: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/.dylibs/libomp.dylib\r\n        version: None\r\n    num_threads: 8\r\n\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/scipy/.dylibs/libopenblas.0.dylib\r\n        version: 0.3.18\r\nthreading_layer: pthreads\r\n   architecture: Haswell\r\n    num_threads: 4\n```\n\n",
  "hints_text": "As noted in the [glossery](https://scikit-learn.org/dev/glossary.html#term-transform), Scikit-learn transformers expects that `transform`'s output have the same number of samples as the input. This exception is held in `FeatureUnion` when processing data and tries to make sure that the output index is the same as the input index. In principle, we can have a less restrictive requirement and only set the index if it is not defined.\r\n\r\nTo better understand your use case, how do you intend to use the `FeatureUnion` in the overall pipeline?\r\n\r\n\n> Scikit-learn transformers expects that transform's output have the same number of samples as the input\r\n\r\nI haven't known that. Good to know. What is the correct way to aggregate or drop rows in a pipeline? Isn't that supported?\r\n\r\n> To better understand your use case, how do you intend to use the FeatureUnion in the overall pipeline?\r\n\r\nThe actual use case: I have a time series (`price`) with hourly frequency. It is a single series with a datetime index. I have built a dataframe with pipeline and custom transformers (by also violating the rule to have same number of inputs and outputs) which aggregates the data (calculates daily mean, and some moving average of daily means) then I have transformed back to hourly frequency (using same values for all the hours of a day). So the dataframe has (`date`, `price`, `mean`, `moving_avg`) columns at that point with hourly frequency (\"same number input/output\" rule violated again). After that I have added the problematic `FeatureUnion`. One part of the union simply drops `price` and \"collapses\" the remaining part to daily data (as I said all the remaining columns has the same values on the same day). On the other part of the feature union I calculate a standard devition between `price` and `moving_avg` on daily basis. So I have the (`date`, `mean`, `moving_avg`) on the left side of the feature union and an `std` on the right side. Both have daily frequency. I would like to have a dataframe with (`date`, `mean`, `moving_avg`, `std`) at the end of the transformation.\nAs I see there is the same \"problem\" in `ColumnTransfromer`.\nI have a look at how `scikit-learn` encapsulates output into a `DataFrame` and found this code block:\r\n\r\nhttps://github.com/scikit-learn/scikit-learn/blob/main/sklearn/utils/_set_output.py#L55-L62\r\n\r\nIs there any reason to set index here? If transformer returned a `DataFrame` this already has some kind of index. Why should we restore the original input index? What is the use case when a transformer changes the `DataFrame`'s index and `scikit-learn` has to restore it automatically to the input index?\r\n\r\nWith index restoration it is also expected for transformers that index should not be changed (or if it is changed by transformer then `scikit-learn` restores the original one which could be a bit unintuitive). Is this an intended behaviour?\r\n\r\nWhat is the design decision to not allow changing index and row count in data by transformers? In time series problems I think it is very common to aggregate raw data and modify original index.",
  "created_at": "2023-03-02T20:38:47Z",
  "version": "1.3",
  "FAIL_TO_PASS": "[\"sklearn/utils/tests/test_set_output.py::test_set_output_pandas_keep_index\"]",
  "PASS_TO_PASS": "[\"sklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_dense\", \"sklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_dense_update_columns_and_index\", \"sklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_error_validation\", \"sklearn/utils/tests/test_set_output.py::test__safe_set_output\", \"sklearn/utils/tests/test_set_output.py::test_set_output_mixin\", \"sklearn/utils/tests/test_set_output.py::test__safe_set_output_error\", \"sklearn/utils/tests/test_set_output.py::test_set_output_method\", \"sklearn/utils/tests/test_set_output.py::test_set_output_method_error\", \"sklearn/utils/tests/test_set_output.py::test__get_output_config\", \"sklearn/utils/tests/test_set_output.py::test_get_output_auto_wrap_false\", \"sklearn/utils/tests/test_set_output.py::test_auto_wrap_output_keys_errors_with_incorrect_input\", \"sklearn/utils/tests/test_set_output.py::test_set_output_mixin_custom_mixin\", \"sklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_column_errors\", \"sklearn/utils/tests/test_set_output.py::test_set_output_mro\"]",
  "environment_setup_commit": "1e8a5b833d1b58f3ab84099c4582239af854b23a",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.022437",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}