{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-13467",
  "base_commit": "a83c8311dfdbf74dea584d45c6f254bc8171054d",
  "patch": "diff --git a/sklearn/metrics/regression.py b/sklearn/metrics/regression.py\n--- a/sklearn/metrics/regression.py\n+++ b/sklearn/metrics/regression.py\n@@ -191,7 +191,7 @@ def mean_absolute_error(y_true, y_pred,\n \n def mean_squared_error(y_true, y_pred,\n                        sample_weight=None,\n-                       multioutput='uniform_average'):\n+                       multioutput='uniform_average', squared=True):\n     \"\"\"Mean squared error regression loss\n \n     Read more in the :ref:`User Guide <mean_squared_error>`.\n@@ -218,6 +218,9 @@ def mean_squared_error(y_true, y_pred,\n         'uniform_average' :\n             Errors of all outputs are averaged with uniform weight.\n \n+    squared : boolean value, optional (default = True)\n+        If True returns MSE value, if False returns RMSE value.\n+\n     Returns\n     -------\n     loss : float or ndarray of floats\n@@ -231,6 +234,10 @@ def mean_squared_error(y_true, y_pred,\n     >>> y_pred = [2.5, 0.0, 2, 8]\n     >>> mean_squared_error(y_true, y_pred)\n     0.375\n+    >>> y_true = [3, -0.5, 2, 7]\n+    >>> y_pred = [2.5, 0.0, 2, 8]\n+    >>> mean_squared_error(y_true, y_pred, squared=False)\n+    0.612...\n     >>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n     >>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n     >>> mean_squared_error(y_true, y_pred)\n@@ -253,7 +260,8 @@ def mean_squared_error(y_true, y_pred,\n             # pass None as weights to np.average: uniform mean\n             multioutput = None\n \n-    return np.average(output_errors, weights=multioutput)\n+    mse = np.average(output_errors, weights=multioutput)\n+    return mse if squared else np.sqrt(mse)\n \n \n def mean_squared_log_error(y_true, y_pred,\ndiff --git a/sklearn/metrics/scorer.py b/sklearn/metrics/scorer.py\n--- a/sklearn/metrics/scorer.py\n+++ b/sklearn/metrics/scorer.py\n@@ -495,6 +495,9 @@ def make_scorer(score_func, greater_is_better=True, needs_proba=False,\n                                              greater_is_better=False)\n neg_median_absolute_error_scorer = make_scorer(median_absolute_error,\n                                                greater_is_better=False)\n+neg_root_mean_squared_error_scorer = make_scorer(mean_squared_error,\n+                                                 greater_is_better=False,\n+                                                 squared=False)\n neg_mean_poisson_deviance_scorer = make_scorer(\n     mean_tweedie_deviance, p=1., greater_is_better=False\n )\n@@ -549,6 +552,7 @@ def make_scorer(score_func, greater_is_better=True, needs_proba=False,\n                neg_mean_absolute_error=neg_mean_absolute_error_scorer,\n                neg_mean_squared_error=neg_mean_squared_error_scorer,\n                neg_mean_squared_log_error=neg_mean_squared_log_error_scorer,\n+               neg_root_mean_squared_error=neg_root_mean_squared_error_scorer,\n                neg_mean_poisson_deviance=neg_mean_poisson_deviance_scorer,\n                neg_mean_gamma_deviance=neg_mean_gamma_deviance_scorer,\n                accuracy=accuracy_scorer, roc_auc=roc_auc_scorer,\n",
  "test_patch": "diff --git a/sklearn/metrics/tests/test_regression.py b/sklearn/metrics/tests/test_regression.py\n--- a/sklearn/metrics/tests/test_regression.py\n+++ b/sklearn/metrics/tests/test_regression.py\n@@ -64,6 +64,9 @@ def test_multioutput_regression():\n     error = mean_squared_error(y_true, y_pred)\n     assert_almost_equal(error, (1. / 3 + 2. / 3 + 2. / 3) / 4.)\n \n+    error = mean_squared_error(y_true, y_pred, squared=False)\n+    assert_almost_equal(error, 0.645, decimal=2)\n+\n     error = mean_squared_log_error(y_true, y_pred)\n     assert_almost_equal(error, 0.200, decimal=2)\n \n@@ -80,6 +83,7 @@ def test_multioutput_regression():\n \n def test_regression_metrics_at_limits():\n     assert_almost_equal(mean_squared_error([0.], [0.]), 0.00, 2)\n+    assert_almost_equal(mean_squared_error([0.], [0.], squared=False), 0.00, 2)\n     assert_almost_equal(mean_squared_log_error([0.], [0.]), 0.00, 2)\n     assert_almost_equal(mean_absolute_error([0.], [0.]), 0.00, 2)\n     assert_almost_equal(median_absolute_error([0.], [0.]), 0.00, 2)\n@@ -231,11 +235,14 @@ def test_regression_custom_weights():\n     y_pred = [[1, 1], [2, -1], [5, 4], [5, 6.5]]\n \n     msew = mean_squared_error(y_true, y_pred, multioutput=[0.4, 0.6])\n+    rmsew = mean_squared_error(y_true, y_pred, multioutput=[0.4, 0.6],\n+                               squared=False)\n     maew = mean_absolute_error(y_true, y_pred, multioutput=[0.4, 0.6])\n     rw = r2_score(y_true, y_pred, multioutput=[0.4, 0.6])\n     evsw = explained_variance_score(y_true, y_pred, multioutput=[0.4, 0.6])\n \n     assert_almost_equal(msew, 0.39, decimal=2)\n+    assert_almost_equal(rmsew, 0.62, decimal=2)\n     assert_almost_equal(maew, 0.475, decimal=3)\n     assert_almost_equal(rw, 0.94, decimal=2)\n     assert_almost_equal(evsw, 0.94, decimal=2)\ndiff --git a/sklearn/metrics/tests/test_score_objects.py b/sklearn/metrics/tests/test_score_objects.py\n--- a/sklearn/metrics/tests/test_score_objects.py\n+++ b/sklearn/metrics/tests/test_score_objects.py\n@@ -41,7 +41,9 @@\n REGRESSION_SCORERS = ['explained_variance', 'r2',\n                       'neg_mean_absolute_error', 'neg_mean_squared_error',\n                       'neg_mean_squared_log_error',\n-                      'neg_median_absolute_error', 'mean_absolute_error',\n+                      'neg_median_absolute_error',\n+                      'neg_root_mean_squared_error',\n+                      'mean_absolute_error',\n                       'mean_squared_error', 'median_absolute_error',\n                       'max_error', 'neg_mean_poisson_deviance',\n                       'neg_mean_gamma_deviance']\n",
  "problem_statement": "Implement RMSE (root-mean-square error) metric and scorer\nRMSE seems to be a popular metric but now one has to calculate it through ``np.sqrt(mean_squared_error(XXX, XXX))``. Maybe we can add ``squared`` option to ``mean_squared_error`` and add a scorer ``neg_root_mean_squared_error``.\r\nWiki page: https://en.wikipedia.org/wiki/Root-mean-square_deviation\n",
  "hints_text": "As the square root is a monotonic function on the positive domain, taking the square root would have no effect on any model selection. Could you please mention a use-case when it taking the root has some real advantage?\n> As the square root is a monotonic function on the positive domain, taking the square root would have no effect on any model selection\r\n\r\nThis is why we reject it previously I think (though I'm unable to find relevant discussions)\r\nI'd argue that given the popularity of RMSE, it might be worthwhile to add several lines of (redundant) code for it (we only need <5 lines of code for the metric I think)\r\nSometimes users might want to report the RMSE of their model instead of MSE, because RMSE is more meaningful (i.e., it reflects the deviation between actual value and predicted value).\r\n\nHi,\r\nIf there is a consensus on this I would like to give this a try.\n> If there is a consensus on this I would like to give this a try.\r\n\r\nnot yet, please wait or try another issue.\nHmm, I found https://github.com/scikit-learn/scikit-learn/pull/6457#issuecomment-253975180\nI would like to work on this.",
  "created_at": "2019-03-18T15:20:08Z",
  "version": "0.22",
  "FAIL_TO_PASS": "[\"sklearn/metrics/tests/test_regression.py::test_multioutput_regression\", \"sklearn/metrics/tests/test_regression.py::test_regression_metrics_at_limits\", \"sklearn/metrics/tests/test_regression.py::test_regression_custom_weights\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_root_mean_squared_error]\"]",
  "PASS_TO_PASS": "[\"sklearn/metrics/tests/test_regression.py::test_regression_metrics\", \"sklearn/metrics/tests/test_regression.py::test__check_reg_targets\", \"sklearn/metrics/tests/test_regression.py::test__check_reg_targets_exception\", \"sklearn/metrics/tests/test_regression.py::test_regression_multioutput_array\", \"sklearn/metrics/tests/test_regression.py::test_regression_single_sample[r2_score]\", \"sklearn/metrics/tests/test_regression.py::test_tweedie_deviance_continuity\", \"sklearn/metrics/tests/test_score_objects.py::test_all_scorers_repr\", \"sklearn/metrics/tests/test_score_objects.py::test_check_scoring_and_check_multimetric_scoring\", \"sklearn/metrics/tests/test_score_objects.py::test_check_scoring_gridsearchcv\", \"sklearn/metrics/tests/test_score_objects.py::test_make_scorer\", \"sklearn/metrics/tests/test_score_objects.py::test_classification_scores\", \"sklearn/metrics/tests/test_score_objects.py::test_regression_scorers\", \"sklearn/metrics/tests/test_score_objects.py::test_thresholded_scorers\", \"sklearn/metrics/tests/test_score_objects.py::test_thresholded_scorers_multilabel_indicator_data\", \"sklearn/metrics/tests/test_score_objects.py::test_supervised_cluster_scorers\", \"sklearn/metrics/tests/test_score_objects.py::test_raises_on_score_list\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_sample_weight\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[explained_variance]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[r2]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[max_error]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_median_absolute_error]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_mean_absolute_error]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_mean_squared_error]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_mean_squared_log_error]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_mean_poisson_deviance]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_mean_gamma_deviance]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[accuracy]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[roc_auc]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[roc_auc_ovr]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[roc_auc_ovo]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[balanced_accuracy]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[average_precision]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[neg_log_loss]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[brier_score_loss]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[adjusted_rand_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[homogeneity_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[completeness_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[v_measure_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[mutual_info_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[adjusted_mutual_info_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[normalized_mutual_info_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[fowlkes_mallows_score]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[precision]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[precision_macro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[precision_micro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[precision_samples]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[precision_weighted]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[recall]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[recall_macro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[recall_micro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[recall_samples]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[recall_weighted]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[f1]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[f1_macro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[f1_micro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[f1_samples]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[f1_weighted]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[jaccard]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[jaccard_macro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[jaccard_micro]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[jaccard_samples]\", \"sklearn/metrics/tests/test_score_objects.py::test_scorer_memmap_input[jaccard_weighted]\", \"sklearn/metrics/tests/test_score_objects.py::test_scoring_is_not_metric\"]",
  "environment_setup_commit": "7e85a6d1f038bbb932b36f18d75df6be937ed00d",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.994736",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}