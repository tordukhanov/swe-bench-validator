{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-12557",
  "base_commit": "4de404d46d24805ff48ad255ec3169a5155986f0",
  "patch": "diff --git a/examples/svm/plot_svm_tie_breaking.py b/examples/svm/plot_svm_tie_breaking.py\nnew file mode 100644\n--- /dev/null\n+++ b/examples/svm/plot_svm_tie_breaking.py\n@@ -0,0 +1,64 @@\n+\"\"\"\n+=========================================================\n+SVM Tie Breaking Example\n+=========================================================\n+Tie breaking is costly if ``decision_function_shape='ovr'``, and therefore it\n+is not enabled by default. This example illustrates the effect of the\n+``break_ties`` parameter for a multiclass classification problem and\n+``decision_function_shape='ovr'``.\n+\n+The two plots differ only in the area in the middle where the classes are\n+tied. If ``break_ties=False``, all input in that area would be classified as\n+one class, whereas if ``break_ties=True``, the tie-breaking mechanism will\n+create a non-convex decision boundary in that area.\n+\"\"\"\n+print(__doc__)\n+\n+\n+# Code source: Andreas Mueller, Adrin Jalali\n+# License: BSD 3 clause\n+\n+\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from sklearn.svm import SVC\n+from sklearn.datasets import make_blobs\n+\n+X, y = make_blobs(random_state=27)\n+\n+fig, sub = plt.subplots(2, 1, figsize=(5, 8))\n+titles = (\"break_ties = False\",\n+          \"break_ties = True\")\n+\n+for break_ties, title, ax in zip((False, True), titles, sub.flatten()):\n+\n+    svm = SVC(kernel=\"linear\", C=1, break_ties=break_ties,\n+              decision_function_shape='ovr').fit(X, y)\n+\n+    xlim = [X[:, 0].min(), X[:, 0].max()]\n+    ylim = [X[:, 1].min(), X[:, 1].max()]\n+\n+    xs = np.linspace(xlim[0], xlim[1], 1000)\n+    ys = np.linspace(ylim[0], ylim[1], 1000)\n+    xx, yy = np.meshgrid(xs, ys)\n+\n+    pred = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n+\n+    colors = [plt.cm.Accent(i) for i in [0, 4, 7]]\n+\n+    points = ax.scatter(X[:, 0], X[:, 1], c=y, cmap=\"Accent\")\n+    classes = [(0, 1), (0, 2), (1, 2)]\n+    line = np.linspace(X[:, 1].min() - 5, X[:, 1].max() + 5)\n+    ax.imshow(-pred.reshape(xx.shape), cmap=\"Accent\", alpha=.2,\n+              extent=(xlim[0], xlim[1], ylim[1], ylim[0]))\n+\n+    for coef, intercept, col in zip(svm.coef_, svm.intercept_, classes):\n+        line2 = -(line * coef[1] + intercept) / coef[0]\n+        ax.plot(line2, line, \"-\", c=colors[col[0]])\n+        ax.plot(line2, line, \"--\", c=colors[col[1]])\n+    ax.set_xlim(xlim)\n+    ax.set_ylim(ylim)\n+    ax.set_title(title)\n+    ax.set_aspect(\"equal\")\n+\n+plt.show()\ndiff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -983,11 +983,13 @@ class GridSearchCV(BaseSearchCV):\n     >>> clf.fit(iris.data, iris.target)\n     ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n     GridSearchCV(cv=5, error_score=...,\n-           estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,\n+           estimator=SVC(C=1.0, break_ties=False, cache_size=...,\n+                         class_weight=..., coef0=...,\n                          decision_function_shape='ovr', degree=..., gamma=...,\n-                         kernel='rbf', max_iter=-1, probability=False,\n-                         random_state=None, shrinking=True, tol=...,\n-                         verbose=False),\n+                         kernel='rbf', max_iter=-1,\n+                         probability=False,\n+                         random_state=None, shrinking=True,\n+                         tol=..., verbose=False),\n            iid=..., n_jobs=None,\n            param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,\n            scoring=..., verbose=...)\ndiff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -501,8 +501,10 @@ class BaseSVC(BaseLibSVM, ClassifierMixin, metaclass=ABCMeta):\n     @abstractmethod\n     def __init__(self, kernel, degree, gamma, coef0, tol, C, nu,\n                  shrinking, probability, cache_size, class_weight, verbose,\n-                 max_iter, decision_function_shape, random_state):\n+                 max_iter, decision_function_shape, random_state,\n+                 break_ties):\n         self.decision_function_shape = decision_function_shape\n+        self.break_ties = break_ties\n         super().__init__(\n             kernel=kernel, degree=degree, gamma=gamma,\n             coef0=coef0, tol=tol, C=C, nu=nu, epsilon=0., shrinking=shrinking,\n@@ -571,7 +573,17 @@ def predict(self, X):\n         y_pred : array, shape (n_samples,)\n             Class labels for samples in X.\n         \"\"\"\n-        y = super().predict(X)\n+        check_is_fitted(self, \"classes_\")\n+        if self.break_ties and self.decision_function_shape == 'ovo':\n+            raise ValueError(\"break_ties must be False when \"\n+                             \"decision_function_shape is 'ovo'\")\n+\n+        if (self.break_ties\n+                and self.decision_function_shape == 'ovr'\n+                and len(self.classes_) > 2):\n+            y = np.argmax(self.decision_function(X), axis=1)\n+        else:\n+            y = super().predict(X)\n         return self.classes_.take(np.asarray(y, dtype=np.intp))\n \n     # Hacky way of getting predict_proba to raise an AttributeError when\ndiff --git a/sklearn/svm/classes.py b/sklearn/svm/classes.py\n--- a/sklearn/svm/classes.py\n+++ b/sklearn/svm/classes.py\n@@ -521,6 +521,15 @@ class SVC(BaseSVC):\n         .. versionchanged:: 0.17\n            Deprecated *decision_function_shape='ovo' and None*.\n \n+    break_ties : bool, optional (default=False)\n+        If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n+        :term:`predict` will break ties according to the confidence values of\n+        :term:`decision_function`; otherwise the first class among the tied\n+        classes is returned. Please note that breaking ties comes at a\n+        relatively high computational cost compared to a simple predict.\n+\n+        .. versionadded:: 0.22\n+\n     random_state : int, RandomState instance or None, optional (default=None)\n         The seed of the pseudo random number generator used when shuffling\n         the data for probability estimates. If int, random_state is the\n@@ -578,10 +587,10 @@ class SVC(BaseSVC):\n     >>> from sklearn.svm import SVC\n     >>> clf = SVC(gamma='auto')\n     >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n-    SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n+    SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n         decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n-        max_iter=-1, probability=False, random_state=None, shrinking=True,\n-        tol=0.001, verbose=False)\n+        max_iter=-1, probability=False,\n+        random_state=None, shrinking=True, tol=0.001, verbose=False)\n     >>> print(clf.predict([[-0.8, -1]]))\n     [1]\n \n@@ -611,6 +620,7 @@ def __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated',\n                  coef0=0.0, shrinking=True, probability=False,\n                  tol=1e-3, cache_size=200, class_weight=None,\n                  verbose=False, max_iter=-1, decision_function_shape='ovr',\n+                 break_ties=False,\n                  random_state=None):\n \n         super().__init__(\n@@ -619,6 +629,7 @@ def __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated',\n             probability=probability, cache_size=cache_size,\n             class_weight=class_weight, verbose=verbose, max_iter=max_iter,\n             decision_function_shape=decision_function_shape,\n+            break_ties=break_ties,\n             random_state=random_state)\n \n \n@@ -707,6 +718,15 @@ class NuSVC(BaseSVC):\n         .. versionchanged:: 0.17\n            Deprecated *decision_function_shape='ovo' and None*.\n \n+    break_ties : bool, optional (default=False)\n+        If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n+        :term:`predict` will break ties according to the confidence values of\n+        :term:`decision_function`; otherwise the first class among the tied\n+        classes is returned. Please note that breaking ties comes at a\n+        relatively high computational cost compared to a simple predict.\n+\n+        .. versionadded:: 0.22\n+\n     random_state : int, RandomState instance or None, optional (default=None)\n         The seed of the pseudo random number generator used when shuffling\n         the data for probability estimates. If int, random_state is the seed\n@@ -750,10 +770,10 @@ class NuSVC(BaseSVC):\n     >>> from sklearn.svm import NuSVC\n     >>> clf = NuSVC(gamma='scale')\n     >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n-    NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n+    NuSVC(break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n           decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n-          max_iter=-1, nu=0.5, probability=False, random_state=None,\n-          shrinking=True, tol=0.001, verbose=False)\n+          max_iter=-1, nu=0.5, probability=False,\n+          random_state=None, shrinking=True, tol=0.001, verbose=False)\n     >>> print(clf.predict([[-0.8, -1]]))\n     [1]\n \n@@ -778,7 +798,8 @@ class NuSVC(BaseSVC):\n     def __init__(self, nu=0.5, kernel='rbf', degree=3, gamma='auto_deprecated',\n                  coef0=0.0, shrinking=True, probability=False, tol=1e-3,\n                  cache_size=200, class_weight=None, verbose=False, max_iter=-1,\n-                 decision_function_shape='ovr', random_state=None):\n+                 decision_function_shape='ovr', break_ties=False,\n+                 random_state=None):\n \n         super().__init__(\n             kernel=kernel, degree=degree, gamma=gamma,\n@@ -786,6 +807,7 @@ def __init__(self, nu=0.5, kernel='rbf', degree=3, gamma='auto_deprecated',\n             probability=probability, cache_size=cache_size,\n             class_weight=class_weight, verbose=verbose, max_iter=max_iter,\n             decision_function_shape=decision_function_shape,\n+            break_ties=break_ties,\n             random_state=random_state)\n \n \n",
  "test_patch": "diff --git a/sklearn/svm/tests/test_svm.py b/sklearn/svm/tests/test_svm.py\n--- a/sklearn/svm/tests/test_svm.py\n+++ b/sklearn/svm/tests/test_svm.py\n@@ -985,6 +985,41 @@ def test_ovr_decision_function():\n     assert np.all(pred_class_deci_val[:, 0] < pred_class_deci_val[:, 1])\n \n \n+@pytest.mark.parametrize(\"SVCClass\", [svm.SVC, svm.NuSVC])\n+def test_svc_invalid_break_ties_param(SVCClass):\n+    X, y = make_blobs(random_state=42)\n+\n+    svm = SVCClass(kernel=\"linear\", decision_function_shape='ovo',\n+                   break_ties=True, random_state=42).fit(X, y)\n+\n+    with pytest.raises(ValueError, match=\"break_ties must be False\"):\n+        svm.predict(y)\n+\n+\n+@pytest.mark.parametrize(\"SVCClass\", [svm.SVC, svm.NuSVC])\n+def test_svc_ovr_tie_breaking(SVCClass):\n+    \"\"\"Test if predict breaks ties in OVR mode.\n+    Related issue: https://github.com/scikit-learn/scikit-learn/issues/8277\n+    \"\"\"\n+    X, y = make_blobs(random_state=27)\n+\n+    xs = np.linspace(X[:, 0].min(), X[:, 0].max(), 1000)\n+    ys = np.linspace(X[:, 1].min(), X[:, 1].max(), 1000)\n+    xx, yy = np.meshgrid(xs, ys)\n+\n+    svm = SVCClass(kernel=\"linear\", decision_function_shape='ovr',\n+                   break_ties=False, random_state=42).fit(X, y)\n+    pred = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n+    dv = svm.decision_function(np.c_[xx.ravel(), yy.ravel()])\n+    assert not np.all(pred == np.argmax(dv, axis=1))\n+\n+    svm = SVCClass(kernel=\"linear\", decision_function_shape='ovr',\n+                   break_ties=True, random_state=42).fit(X, y)\n+    pred = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n+    dv = svm.decision_function(np.c_[xx.ravel(), yy.ravel()])\n+    assert np.all(pred == np.argmax(dv, axis=1))\n+\n+\n def test_gamma_auto():\n     X, y = [[0.0, 1.2], [1.0, 1.3]], [0, 1]\n \n",
  "problem_statement": "SVC.decision_function disagrees with predict\nIn ``SVC`` with ``decision_function_shape=\"ovr\"`` argmax of the decision function is not the same as ``predict``. This is related to the tie-breaking mentioned in #8276.\r\n\r\nThe ``decision_function`` now includes tie-breaking, which the ``predict`` doesn't.\r\nI'm not sure the tie-breaking is good, but we should be consistent either way.\n",
  "hints_text": "The relevant issue on `libsvm` (i.e. issue https://github.com/cjlin1/libsvm/issues/85) seems to be stalled and I'm not sure if it's had a conclusion. At least on the `libsvm` side it seems they prefer not to include the confidences for computational cost of it.\r\n\r\nNow the question is, do we want to change the `svm.cpp` to fix the issue and take the confidences into account? Or do we want the `SVC.predict` to use `SVC.decision_function` instead of calling `libsvm`'s `predict`? Or to fix the documentation and make it clear that `decision_function` and `predict` may not agree in case of a tie?\nDoes this related to #9174 also? Does #10440 happen to fix it??​\n\n@jnothman not really, that's exactly the issue actually. the `predict` function which calls the `libsvm`'s `predict` function, does not use confidences to break the ties, but the `decision_function` does (as a result of the issue and the PR you mentioned).\nAh, I see.​ Hmm...\n\nAnother alternative is to have a `break_ties_in_predict` (or a much better parameter name that you can think of), have the default `False`, and if `True`, return the argmax of the decision_function. It would be very little code and backward compatible.\n@adrinjalali and then change the default value? Or keep it inconsistent by default? (neither of these seems like great options to me ;)\n@amueller I know it's not ideal, but my intuition says:\r\n\r\n1- argmax of decision function is much slower than predict, which is why I'd see why in most usercases people would prefer to just ignore the tie breaking issue.\r\n2- in practice, ties happen very rarely, therefore the inconsistency is actually not that big of an issue (we'd be seeing more reported issues if that was happening more often and people were noticing, I guess).\r\n\r\nTherefore, I'd say the default value `False` is not an unreasonable case at all. On top of that, we'd document this properly both in the docstring and in the user manuals. And if the user really would like them to be consistent, they can make it so.\r\n\r\nOne could make the same argument and say the change is not necessary at all then. In response to which, I'd say the change is trivial and not much code at all, and easy to maintain, therefore there's not much damage the change would do. I kinda see this proposal as a compromise between the two cases of leaving it as is, and fixing it for everybody and breaking backward compatibility.\r\n\r\nAlso, independent of this change, if after the introduction of the change,we see some demand for the default to be `True` (which I'd doubt), we can do it in a rather long deprecation cycle to give people enough time to change/fix their code.\r\n\r\n(I'm just explaining my proposed solution, absolutely no attachments to the proposal :P )\nAdding a parameter would certainly make more users aware of this issue, and\nit is somewhat like other parameters giving efficiency tradeoffs.\n\n>\n",
  "created_at": "2018-11-10T15:45:52Z",
  "version": "0.22",
  "FAIL_TO_PASS": "[\"sklearn/svm/tests/test_svm.py::test_svc_invalid_break_ties_param[SVC]\", \"sklearn/svm/tests/test_svm.py::test_svc_invalid_break_ties_param[NuSVC]\", \"sklearn/svm/tests/test_svm.py::test_svc_ovr_tie_breaking[SVC]\", \"sklearn/svm/tests/test_svm.py::test_svc_ovr_tie_breaking[NuSVC]\"]",
  "PASS_TO_PASS": "[\"sklearn/svm/tests/test_svm.py::test_libsvm_parameters\", \"sklearn/svm/tests/test_svm.py::test_libsvm_iris\", \"sklearn/svm/tests/test_svm.py::test_precomputed\", \"sklearn/svm/tests/test_svm.py::test_svr\", \"sklearn/svm/tests/test_svm.py::test_linearsvr\", \"sklearn/svm/tests/test_svm.py::test_linearsvr_fit_sampleweight\", \"sklearn/svm/tests/test_svm.py::test_svr_errors\", \"sklearn/svm/tests/test_svm.py::test_oneclass\", \"sklearn/svm/tests/test_svm.py::test_oneclass_decision_function\", \"sklearn/svm/tests/test_svm.py::test_oneclass_score_samples\", \"sklearn/svm/tests/test_svm.py::test_tweak_params\", \"sklearn/svm/tests/test_svm.py::test_probability\", \"sklearn/svm/tests/test_svm.py::test_decision_function\", \"sklearn/svm/tests/test_svm.py::test_decision_function_shape\", \"sklearn/svm/tests/test_svm.py::test_svr_predict\", \"sklearn/svm/tests/test_svm.py::test_weight\", \"sklearn/svm/tests/test_svm.py::test_sample_weights\", \"sklearn/svm/tests/test_svm.py::test_auto_weight\", \"sklearn/svm/tests/test_svm.py::test_bad_input\", \"sklearn/svm/tests/test_svm.py::test_unicode_kernel\", \"sklearn/svm/tests/test_svm.py::test_sparse_precomputed\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_parameters\", \"sklearn/svm/tests/test_svm.py::test_linearsvx_loss_penalty_deprecations\", \"sklearn/svm/tests/test_svm.py::test_linear_svx_uppercase_loss_penality_raises_error\", \"sklearn/svm/tests/test_svm.py::test_linearsvc\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_crammer_singer\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_fit_sampleweight\", \"sklearn/svm/tests/test_svm.py::test_crammer_singer_binary\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_iris\", \"sklearn/svm/tests/test_svm.py::test_dense_liblinear_intercept_handling\", \"sklearn/svm/tests/test_svm.py::test_liblinear_set_coef\", \"sklearn/svm/tests/test_svm.py::test_immutable_coef_property\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_verbose\", \"sklearn/svm/tests/test_svm.py::test_svc_clone_with_callable_kernel\", \"sklearn/svm/tests/test_svm.py::test_svc_bad_kernel\", \"sklearn/svm/tests/test_svm.py::test_timeout\", \"sklearn/svm/tests/test_svm.py::test_unfitted\", \"sklearn/svm/tests/test_svm.py::test_consistent_proba\", \"sklearn/svm/tests/test_svm.py::test_linear_svm_convergence_warnings\", \"sklearn/svm/tests/test_svm.py::test_svr_coef_sign\", \"sklearn/svm/tests/test_svm.py::test_linear_svc_intercept_scaling\", \"sklearn/svm/tests/test_svm.py::test_lsvc_intercept_scaling_zero\", \"sklearn/svm/tests/test_svm.py::test_hasattr_predict_proba\", \"sklearn/svm/tests/test_svm.py::test_decision_function_shape_two_class\", \"sklearn/svm/tests/test_svm.py::test_ovr_decision_function\", \"sklearn/svm/tests/test_svm.py::test_gamma_auto\", \"sklearn/svm/tests/test_svm.py::test_gamma_scale\"]",
  "environment_setup_commit": "7e85a6d1f038bbb932b36f18d75df6be937ed00d",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.964953",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}