{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-14764",
  "base_commit": "af2bad4f34e938cb16ada0ae19cc713a275682d6",
  "patch": "diff --git a/sklearn/datasets/samples_generator.py b/sklearn/datasets/samples_generator.py\n--- a/sklearn/datasets/samples_generator.py\n+++ b/sklearn/datasets/samples_generator.py\n@@ -91,7 +91,8 @@ def make_classification(n_samples=100, n_features=20, n_informative=2,\n     n_clusters_per_class : int, optional (default=2)\n         The number of clusters per class.\n \n-    weights : list of floats or None (default=None)\n+    weights : array-like of shape (n_classes,) or (n_classes - 1,),\\\n+              (default=None)\n         The proportions of samples assigned to each class. If None, then\n         classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n         then the last class weight is automatically inferred.\n@@ -160,22 +161,27 @@ def make_classification(n_samples=100, n_features=20, n_informative=2,\n                          \" features\")\n     # Use log2 to avoid overflow errors\n     if n_informative < np.log2(n_classes * n_clusters_per_class):\n-        raise ValueError(\"n_classes * n_clusters_per_class must\"\n-                         \" be smaller or equal 2 ** n_informative\")\n-    if weights and len(weights) not in [n_classes, n_classes - 1]:\n-        raise ValueError(\"Weights specified but incompatible with number \"\n-                         \"of classes.\")\n+        msg = \"n_classes({}) * n_clusters_per_class({}) must be\"\n+        msg += \" smaller or equal 2**n_informative({})={}\"\n+        raise ValueError(msg.format(n_classes, n_clusters_per_class,\n+                                    n_informative, 2**n_informative))\n+\n+    if weights is not None:\n+        if len(weights) not in [n_classes, n_classes - 1]:\n+            raise ValueError(\"Weights specified but incompatible with number \"\n+                             \"of classes.\")\n+        if len(weights) == n_classes - 1:\n+            if isinstance(weights, list):\n+                weights = weights + [1.0 - sum(weights)]\n+            else:\n+                weights = np.resize(weights, n_classes)\n+                weights[-1] = 1.0 - sum(weights[:-1])\n+    else:\n+        weights = [1.0 / n_classes] * n_classes\n \n     n_useless = n_features - n_informative - n_redundant - n_repeated\n     n_clusters = n_classes * n_clusters_per_class\n \n-    if weights and len(weights) == (n_classes - 1):\n-        weights = weights + [1.0 - sum(weights)]\n-\n-    if weights is None:\n-        weights = [1.0 / n_classes] * n_classes\n-        weights[-1] = 1.0 - sum(weights[:-1])\n-\n     # Distribute samples among clusters by weight\n     n_samples_per_cluster = [\n         int(n_samples * weights[k % n_classes] / n_clusters_per_class)\n",
  "test_patch": "diff --git a/sklearn/datasets/tests/test_samples_generator.py b/sklearn/datasets/tests/test_samples_generator.py\n--- a/sklearn/datasets/tests/test_samples_generator.py\n+++ b/sklearn/datasets/tests/test_samples_generator.py\n@@ -146,6 +146,36 @@ def test_make_classification_informative_features():\n              n_clusters_per_class=2)\n \n \n+@pytest.mark.parametrize(\n+    'weights, err_type, err_msg',\n+    [\n+        ([], ValueError,\n+         \"Weights specified but incompatible with number of classes.\"),\n+        ([.25, .75, .1], ValueError,\n+         \"Weights specified but incompatible with number of classes.\"),\n+        (np.array([]), ValueError,\n+         \"Weights specified but incompatible with number of classes.\"),\n+        (np.array([.25, .75, .1]), ValueError,\n+         \"Weights specified but incompatible with number of classes.\"),\n+        (np.random.random(3), ValueError,\n+         \"Weights specified but incompatible with number of classes.\")\n+    ]\n+)\n+def test_make_classification_weights_type(weights, err_type, err_msg):\n+    with pytest.raises(err_type, match=err_msg):\n+        make_classification(weights=weights)\n+\n+\n+@pytest.mark.parametrize(\"kwargs\", [{}, {\"n_classes\": 3, \"n_informative\": 3}])\n+def test_make_classification_weights_array_or_list_ok(kwargs):\n+    X1, y1 = make_classification(weights=[.1, .9],\n+                                 random_state=0, **kwargs)\n+    X2, y2 = make_classification(weights=np.array([.1, .9]),\n+                                 random_state=0, **kwargs)\n+    assert_almost_equal(X1, X2)\n+    assert_almost_equal(y1, y2)\n+\n+\n def test_make_multilabel_classification_return_sequences():\n     for allow_unlabeled, min_length in zip((True, False), (0, 1)):\n         X, Y = make_multilabel_classification(n_samples=100, n_features=20,\n",
  "problem_statement": "datasets :: make_classification() weights parameter should be a sequence (not just a list). \n### `weights` should be passed as list or array (not just list) in `sklearn\\datasets\\samples_generator.py :: make_classification`:\r\n If there is a pertinent reason that `weights` must be a list, while *all other iterable parameters are arrays*, then it should be mentioned in the docstring. Otherwise, the docstring should be amended as in `make_blobs`, e.g.  \"weights : list of floats or None (default=None)\" -> \"weights : sequence of floats or None (default=None)\", along with amended lines 165 and 171 (see Corrections).\r\n\r\n#### Test code to reproduce:\r\n``` \r\nprint('Testing weights type in `datasets.make_classification`:')\r\n# using defaults except for weights (& random_state=1):\r\n\r\nw = [0.25, 0.75]\r\nprint('  Test 1: weights as List {}'.format(w))\r\nX, y = make_classification(weights=w, random_state=1)\r\nprint('  Test 1 result: len(X)={}, len(y)={}'.format(len(X),len(y)))\r\n\r\nw = np.array([0.25, 0.75]) \r\nprint('  Test 2: weights as np.array {}'.format(w))\r\nX, y = make_classification(weights=w, random_state=1)\r\nprint('  Test 2 result: len(X)={}, len(y)={}, '.format(len(X),len(y)))\r\n```\r\n#### Expected Results:\r\nShould not fail: np.array as valid as a list:\r\n```\r\nTesting weights type in `make_classification`:\r\n  Test 1: weights as List [0.25, 0.75]\r\n  Test 1 result: len(X)=100, len(y)=100\r\n  Test 2: weights as np.array [0.25, 0.75]\r\n  Test 2 result: len(X)=100, len(y)=100\r\n```\r\n\r\n#### Actual Results\r\n```\r\nTesting weights type in `make_classification`:\r\n  Test 1: weights as List [0.25, 0.75]\r\n  Test 1 result: len(X)=100, len(y)=100\r\n  Test 2: weights as np.array [0.25, 0.75]\r\n```\r\n```error\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-2-c297f465db24> in <module>\r\n     13 print('  Test 2: weights as np.array {}'.format(w))\r\n     14 X, y = make_classification(weights=w,\r\n---> 15                            random_state=1)\r\n     16 print('  Test 2 result: len(X)={}, len(y)={}, '.format(len(X),len(y)))\r\n\r\n~\\Anaconda3\\envs\\dsml\\lib\\site-packages\\sklearn\\datasets\\samples_generator.py in make_classification(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state)\r\n    163         raise ValueError(\"n_classes * n_clusters_per_class must\"\r\n    164                          \" be smaller or equal 2 ** n_informative\")\r\n--> 165     if weights and len(weights) not in [n_classes, n_classes - 1]:\r\n    166         raise ValueError(\"Weights specified but incompatible with number \"\r\n    167                          \"of classes.\")\r\n\r\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\r\n```\r\n\r\n#### Corrections needed (fix ready):\r\n```\r\n165     if all(weights) and (len(weights) not in [n_classes, n_classes - 1]):\r\n\r\n171     if all(weights) and len(weights) == (n_classes - 1):\r\n```\r\n\r\n#### Versions:\r\n```  \r\n    System:\r\n    python: 3.6.7 (default, Feb 28 2019, 07:28:18) [MSC v.1900 64 bit (AMD64)]\r\nexecutable: C:\\<conda env path>\\python.exe\r\n   machine: Windows-10-10.0.18362-SP0 [same outcome with Windows-10-10.0.17134-SP0]\r\n\r\nPython deps:\r\n       pip: 19.1.1\r\nsetuptools: 41.0.1\r\n   sklearn: 0.21.3\r\n     numpy: 1.16.4\r\n     scipy: 1.3.0\r\n    Cython: None\r\n    pandas: 0.24.2\r\n```\r\n#wimlds\n[MRG] Added an example to the sklearn.feature_extraction.image.PatchExtractor\nâ€¦or class\r\n\r\n<!--\r\nThanks for contributing a pull request! Please ensure you have taken a look at\r\nthe contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist\r\n-->\r\n\r\n#### Reference Issues/PRs\r\n<!--\r\nContributes to #3846.\r\n\r\n-->\r\n\r\n\r\n#### What does this implement/fix? Explain your changes.\r\nI added an example to the sklearn.feature_extraction.image.PatchExtractor (#3846)\r\n\r\n#### Any other comments?\r\n\r\n\r\n<!--\r\nPlease be aware that we are a loose team of volunteers so patience is\r\nnecessary; assistance handling other issues is very welcome. We value\r\nall user contributions, no matter how minor they are. If we are slow to\r\nreview, either the pull request needs some benchmarking, tinkering,\r\nconvincing, etc. or more likely the reviewers are simply busy. In either\r\ncase, we ask for your understanding during the review process.\r\nFor more information, see our FAQ on this topic:\r\nhttp://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.\r\n\r\nThanks for contributing!\r\n-->\r\n\n",
  "hints_text": "\ntests are failing. Fit returns self, so you have to add that output. Also there's a pep8 error.",
  "created_at": "2019-08-24T17:02:34Z",
  "version": "0.22",
  "FAIL_TO_PASS": "[\"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_weights_type[weights0-ValueError-Weights\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_weights_type[weights2-ValueError-Weights\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_weights_type[weights3-ValueError-Weights\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_weights_type[weights4-ValueError-Weights\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_weights_array_or_list_ok[kwargs0]\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_weights_array_or_list_ok[kwargs1]\"]",
  "PASS_TO_PASS": "[\"sklearn/datasets/tests/test_samples_generator.py::test_make_classification\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_informative_features\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_classification_weights_type[weights1-ValueError-Weights\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_multilabel_classification_return_sequences\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_multilabel_classification_return_indicator\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_multilabel_classification_return_indicator_sparse\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_hastie_10_2\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_regression\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_regression_multitarget\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_blobs\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_blobs_n_samples_list\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_blobs_n_samples_list_with_centers\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_blobs_n_samples_centers_none[n_samples0]\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_blobs_n_samples_centers_none[n_samples1]\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_blobs_n_samples_centers_none[n_samples2]\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_blobs_error\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_friedman1\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_friedman2\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_friedman3\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_low_rank_matrix\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_sparse_coded_signal\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_sparse_uncorrelated\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_spd_matrix\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_swiss_roll\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_s_curve\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_biclusters\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_checkerboard\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_moons\", \"sklearn/datasets/tests/test_samples_generator.py::test_make_circles\"]",
  "environment_setup_commit": "7e85a6d1f038bbb932b36f18d75df6be937ed00d",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.007710",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}