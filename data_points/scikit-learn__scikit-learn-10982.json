{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-10982",
  "base_commit": "ca436e7017ae069a29de19caf71689e9b9b9c452",
  "patch": "diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -242,13 +242,16 @@ def __iter__(self):\n             # look up sampled parameter settings in parameter grid\n             param_grid = ParameterGrid(self.param_distributions)\n             grid_size = len(param_grid)\n-\n-            if grid_size < self.n_iter:\n-                raise ValueError(\n-                    \"The total space of parameters %d is smaller \"\n-                    \"than n_iter=%d. For exhaustive searches, use \"\n-                    \"GridSearchCV.\" % (grid_size, self.n_iter))\n-            for i in sample_without_replacement(grid_size, self.n_iter,\n+            n_iter = self.n_iter\n+\n+            if grid_size < n_iter:\n+                warnings.warn(\n+                    'The total space of parameters %d is smaller '\n+                    'than n_iter=%d. Running %d iterations. For exhaustive '\n+                    'searches, use GridSearchCV.'\n+                    % (grid_size, self.n_iter, grid_size), UserWarning)\n+                n_iter = grid_size\n+            for i in sample_without_replacement(grid_size, n_iter,\n                                                 random_state=rnd):\n                 yield param_grid[i]\n \n",
  "test_patch": "diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py\n--- a/sklearn/model_selection/tests/test_search.py\n+++ b/sklearn/model_selection/tests/test_search.py\n@@ -1385,10 +1385,18 @@ def test_grid_search_failing_classifier_raise():\n \n \n def test_parameters_sampler_replacement():\n-    # raise error if n_iter too large\n+    # raise warning if n_iter is bigger than total parameter space\n     params = {'first': [0, 1], 'second': ['a', 'b', 'c']}\n     sampler = ParameterSampler(params, n_iter=7)\n-    assert_raises(ValueError, list, sampler)\n+    n_iter = 7\n+    grid_size = 6\n+    expected_warning = ('The total space of parameters %d is smaller '\n+                        'than n_iter=%d. Running %d iterations. For '\n+                        'exhaustive searches, use GridSearchCV.'\n+                        % (grid_size, n_iter, grid_size))\n+    assert_warns_message(UserWarning, expected_warning,\n+                         list, sampler)\n+\n     # degenerates to GridSearchCV if n_iter the same as grid_size\n     sampler = ParameterSampler(params, n_iter=6)\n     samples = list(sampler)\n",
  "problem_statement": "[RandomizedSearchCV] Do not enforce that n_iter is less than or equal to size of search space\n#### Description\r\n\r\nInstantiating `RandomizedSearchCV` with `n_iter` greater than the size of `param_distributions` (i.e. the product of the length of each distribution/array in the grid) will fail with an exception at [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py#L247). This is a bit annoying for me because I have an app where I'm letting the user specify the number of iterations to run from the command line, also I've been fiddling around with the param grid so `grid_size` keeps changing. I don't want to have to work out the exact grid size when it goes below, say, 50; if I specify `--n-iter 50` that should be interpreted as an upper bound on the number of iterations.\r\n\r\nWould it be possible to add an option (off by default) to the constructor specifying whether to throw in such cases? e.g. By passing `allow_smaller_grid=True` (the option would default to `False`)\r\n\n",
  "hints_text": "I think it's safe enough to change this to a warning without a parameter.\nThere are too many parameters in any case, and the warning can be turned\ninto an error if the user wishes.\n\nOn 1 April 2018 at 16:34, James Ko <notifications@github.com> wrote:\n\n> Description\n>\n> Instantiating RandomizedSearchCV with n_iter greater than the size of\n> param_distributions (i.e. the product of the length of each\n> distribution/array in the grid) will fail with an exception at this line\n> <https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py#L247>.\n> This is a bit annoying for me because I have an app where I'm letting the\n> user specify the number of iterations to run from the command line, also\n> I've been fiddling around with the param grid so grid_size keeps\n> changing. I don't want to have to work out the exact grid size when it goes\n> below, say, 50; if I specify --n-iter 50 that should be interpreted as an\n> upper bound on the number of iterations.\n>\n> Would it be possible to add an option (off by default) to the constructor\n> specifying whether to throw in such cases? e.g. By passing\n> allow_smaller_grid=True (the option would default to False)\n>\n> â€”\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/10900>, or mute the\n> thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz61unGMXrvJKZzsBUkx1jDwB_J7Ywks5tkHTYgaJpZM4TCu3C>\n> .\n>\n\nPR welcome.â€‹\n\nHi, I would like to claim this as my first issue. Do you have any advice on how to start/things to avoid?\nWe have contributor guidelines on our website. \r\nUnderstand the warnings module. Look for places in our test suite where we check that warnings are raised, and employ a similar idiom\n@julietcl are you working on this PR or can I take it?\n@maskani-moh I am working on it.\n@julietcl It's all yours then! ðŸ˜‰ \nI have replaced the relevant ValueError in _search.py with a warning, but when I test an example where grid_size < self.n_iter I get:\r\n  File \"sklearn/utils/_random.pyx\", line 226, in sklearn.utils._random.sample_without_replacement\r\n    \r\n  File \"sklearn/utils/_random.pyx\", line 279, in sklearn.utils._random.sample_without_replacement\r\n    not be randomized, see the method argument.\r\n  File \"sklearn/utils/_random.pyx\", line 35, in sklearn.utils._random._sample_without_replacement_check_input\r\n    \r\nValueError: n_population should be greater or equal than n_samples, got n_samples > n_population (6 > 4)\r\n\r\nShould I change [this](https://github.com/scikit-learn/scikit-learn/blob/1de5b1ced23ad6a6e8e2d7bb1c50d36220bfa2d2/sklearn/utils/_random.pyx#L35) to a warning as well?\nyou should probably not change that, just change when/how you call it.â€‹\n\nWould something like this work?\r\n```\r\nif grid_size < self.n_iter:\r\n       warnings.warn(\r\n             'The total space of parameters %d is smaller '\r\n             'than n_iter=%d. For exhaustive searches, use '\r\n             'GridSearchCV.' % (grid_size, self.n_iter), RuntimeWarning)\r\n       self.n_iter = grid_size\r\n```\r\nSo that way for the use case described by op, if the grid size falls below the number of iterations a warning is issued and the number of iterations acts as an upper bound.\nI think that is consistent with the current code for randomized search,\ngiven its sampling without replacement approach.\n\nOn 16 April 2018 at 01:28, julietcl <notifications@github.com> wrote:\n\n> Would something like this work?\n> if grid_size < self.n_iter:\n> warnings.warn(\n> 'The total space of parameters %d is smaller '\n> 'than n_iter=%d. For exhaustive searches, use '\n> 'GridSearchCV.' % (grid_size, self.n_iter), RuntimeWarning)\n> self.n_iter = grid_size\n> So that way for the use case described by op, if the grid size falls below\n> the number of iterations a warning is issued and the number of iterations\n> acts as an upper bound.\n>\n> â€”\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/10900#issuecomment-381414923>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz6x_w_JEZU_uBwE5nydkSFCP74hGSks5to2cvgaJpZM4TCu3C>\n> .\n>\n",
  "created_at": "2018-04-15T23:28:27Z",
  "version": "0.20",
  "FAIL_TO_PASS": "[\"sklearn/model_selection/tests/test_search.py::test_parameters_sampler_replacement\"]",
  "PASS_TO_PASS": "[\"sklearn/model_selection/tests/test_search.py::test_parameter_grid\", \"sklearn/model_selection/tests/test_search.py::test_grid_search\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_with_fit_params\", \"sklearn/model_selection/tests/test_search.py::test_random_search_with_fit_params\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_fit_params_deprecation\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_fit_params_two_places\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_no_score\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_score_method\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_groups\", \"sklearn/model_selection/tests/test_search.py::test_return_train_score_warn\", \"sklearn/model_selection/tests/test_search.py::test_classes__property\", \"sklearn/model_selection/tests/test_search.py::test_trivial_cv_results_attr\", \"sklearn/model_selection/tests/test_search.py::test_no_refit\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_error\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_one_grid_point\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_when_param_grid_includes_range\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_bad_param_grid\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_sparse\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_sparse_scoring\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_precomputed_kernel\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_precomputed_kernel_error_nonsquare\", \"sklearn/model_selection/tests/test_search.py::test_refit\", \"sklearn/model_selection/tests/test_search.py::test_gridsearch_nd\", \"sklearn/model_selection/tests/test_search.py::test_X_as_list\", \"sklearn/model_selection/tests/test_search.py::test_y_as_list\", \"sklearn/model_selection/tests/test_search.py::test_pandas_input\", \"sklearn/model_selection/tests/test_search.py::test_unsupervised_grid_search\", \"sklearn/model_selection/tests/test_search.py::test_gridsearch_no_predict\", \"sklearn/model_selection/tests/test_search.py::test_param_sampler\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_cv_results\", \"sklearn/model_selection/tests/test_search.py::test_random_search_cv_results\", \"sklearn/model_selection/tests/test_search.py::test_search_iid_param\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_cv_results_multimetric\", \"sklearn/model_selection/tests/test_search.py::test_random_search_cv_results_multimetric\", \"sklearn/model_selection/tests/test_search.py::test_search_cv_results_rank_tie_breaking\", \"sklearn/model_selection/tests/test_search.py::test_search_cv_results_none_param\", \"sklearn/model_selection/tests/test_search.py::test_search_cv_timing\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_correct_score_results\", \"sklearn/model_selection/tests/test_search.py::test_fit_grid_point\", \"sklearn/model_selection/tests/test_search.py::test_pickle\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_with_multioutput_data\", \"sklearn/model_selection/tests/test_search.py::test_predict_proba_disabled\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_allows_nans\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier_raise\", \"sklearn/model_selection/tests/test_search.py::test_stochastic_gradient_loss_param\", \"sklearn/model_selection/tests/test_search.py::test_search_train_scores_set_to_false\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_cv_splits_consistency\", \"sklearn/model_selection/tests/test_search.py::test_transform_inverse_transform_round_trip\", \"sklearn/model_selection/tests/test_search.py::test_deprecated_grid_search_iid\"]",
  "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.956661",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}