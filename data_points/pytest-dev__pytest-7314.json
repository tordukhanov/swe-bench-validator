{
  "repo": "pytest-dev/pytest",
  "instance_id": "pytest-dev__pytest-7314",
  "base_commit": "d5843f89d3c008ddcb431adbc335b080a79e617e",
  "patch": "diff --git a/src/_pytest/terminal.py b/src/_pytest/terminal.py\n--- a/src/_pytest/terminal.py\n+++ b/src/_pytest/terminal.py\n@@ -166,7 +166,11 @@ def getreportopt(config):\n         reportchars += \"w\"\n     elif config.option.disable_warnings and \"w\" in reportchars:\n         reportchars = reportchars.replace(\"w\", \"\")\n+    aliases = {\"F\", \"S\"}\n     for char in reportchars:\n+        # handle old aliases\n+        if char in aliases:\n+            char = char.lower()\n         if char == \"a\":\n             reportopts = \"sxXwEf\"\n         elif char == \"A\":\n@@ -179,15 +183,18 @@ def getreportopt(config):\n \n @pytest.hookimpl(trylast=True)  # after _pytest.runner\n def pytest_report_teststatus(report):\n+    letter = \"F\"\n     if report.passed:\n         letter = \".\"\n     elif report.skipped:\n         letter = \"s\"\n-    elif report.failed:\n-        letter = \"F\"\n-        if report.when != \"call\":\n-            letter = \"f\"\n-    return report.outcome, letter, report.outcome.upper()\n+\n+    outcome = report.outcome\n+    if report.when in (\"collect\", \"setup\", \"teardown\") and outcome == \"failed\":\n+        outcome = \"error\"\n+        letter = \"E\"\n+\n+    return outcome, letter, outcome.upper()\n \n \n @attr.s\n@@ -935,9 +942,7 @@ def show_skipped(lines):\n             \"x\": show_xfailed,\n             \"X\": show_xpassed,\n             \"f\": partial(show_simple, \"failed\"),\n-            \"F\": partial(show_simple, \"failed\"),\n             \"s\": show_skipped,\n-            \"S\": show_skipped,\n             \"p\": partial(show_simple, \"passed\"),\n             \"E\": partial(show_simple, \"error\"),\n         }\n",
  "test_patch": "diff --git a/testing/test_terminal.py b/testing/test_terminal.py\n--- a/testing/test_terminal.py\n+++ b/testing/test_terminal.py\n@@ -759,6 +759,35 @@ def test(i):\n         result = testdir.runpytest(*params)\n         result.stdout.fnmatch_lines([\"collected 3 items\", \"hello from hook: 3 items\"])\n \n+    def test_summary_f_alias(self, testdir):\n+        \"\"\"Test that 'f' and 'F' report chars are aliases and don't show up twice in the summary (#6334)\"\"\"\n+        testdir.makepyfile(\n+            \"\"\"\n+            def test():\n+                assert False\n+            \"\"\"\n+        )\n+        result = testdir.runpytest(\"-rfF\")\n+        expected = \"FAILED test_summary_f_alias.py::test - assert False\"\n+        result.stdout.fnmatch_lines([expected])\n+        assert result.stdout.lines.count(expected) == 1\n+\n+    def test_summary_s_alias(self, testdir):\n+        \"\"\"Test that 's' and 'S' report chars are aliases and don't show up twice in the summary\"\"\"\n+        testdir.makepyfile(\n+            \"\"\"\n+            import pytest\n+\n+            @pytest.mark.skip\n+            def test():\n+                pass\n+            \"\"\"\n+        )\n+        result = testdir.runpytest(\"-rsS\")\n+        expected = \"SKIPPED [1] test_summary_s_alias.py:3: unconditional skip\"\n+        result.stdout.fnmatch_lines([expected])\n+        assert result.stdout.lines.count(expected) == 1\n+\n \n def test_fail_extra_reporting(testdir, monkeypatch):\n     monkeypatch.setenv(\"COLUMNS\", \"80\")\n@@ -1551,12 +1580,16 @@ def test_teardown_with_test_also_failing(\n         testdir.makepyfile(\n             \"\"\"\n             def test_foo(fail_teardown):\n-                assert False\n+                assert 0\n         \"\"\"\n         )\n-        output = testdir.runpytest()\n+        output = testdir.runpytest(\"-rfE\")\n         output.stdout.re_match_lines(\n-            [r\"test_teardown_with_test_also_failing.py FE\\s+\\[100%\\]\"]\n+            [\n+                r\"test_teardown_with_test_also_failing.py FE\\s+\\[100%\\]\",\n+                \"FAILED test_teardown_with_test_also_failing.py::test_foo - assert 0\",\n+                \"ERROR test_teardown_with_test_also_failing.py::test_foo - assert False\",\n+            ]\n         )\n \n     def test_teardown_many(self, testdir, many_files):\n",
  "problem_statement": "pytest~=4.6: `UnboundLocalError: local variable 'letter' referenced before assignment`\nWhile implementing a test for https://github.com/pytest-dev/pytest-forked/issues/33 I've hit this:\r\n```python\r\nINTERNALERROR>   File \"~/src/github/pytest-dev/pytest-forked/.tox/py27-pytest46/lib/python2.7/site-packages/_pytest/terminal.py\", line 190, in pytest_report_teststatus\r\nINTERNALERROR>     return report.outcome, letter, report.outcome.upper()\r\nINTERNALERROR> UnboundLocalError: local variable 'letter' referenced before assignment\r\n```\r\n\r\nLooking at the repo, it seems to have been fixed on master by @nicoddemus as a part of https://github.com/pytest-dev/pytest/pull/6337. But it still persists in the `4.6.x` branch.\r\n\r\nThe fix should be trivial: just add a fallback variable value before if-blocks. No need to backport that whole PR (unless somebody thinks that it should be done, of course).\r\n\r\nRef: https://github.com/pytest-dev/pytest/pull/7311.\n[4.6.x] Add a fallback for the term report letter\nWhen plugins return report objects in an unconventional state,\r\n`_pytest.terminal.pytest_report_teststatus()` may skip\r\nentering if-block branches that declare the `letter` variable.\r\nIt would lead to `UnboundLocalError: local variable 'letter'\r\nreferenced before assignment` being raised.\r\n\r\nThis change fixes this by setting the initial value of the\r\n`letter` before the if-block cascade so that it always has\r\na value.\r\n\r\nFixes #7310\r\n\r\n- [ ] Include documentation when adding new features.\r\n- [ ] Include new tests or update existing tests when applicable.\r\n- [ ] Allow maintainers to push and squash when merging my commits. Please uncheck this if you prefer to squash the commits yourself.\r\n\r\nUnless your change is trivial or a small documentation fix (e.g., a typo or reword of a small section) please:\r\n\r\n- [ ] Create a new changelog file in the `changelog` folder, with a name like `<ISSUE NUMBER>.<TYPE>.rst`. See [changelog/README.rst](https://github.com/pytest-dev/pytest/blob/master/changelog/README.rst) for details.\r\n\r\n  Write sentences in the **past or present tense**, examples:\r\n\r\n  * *Improved verbose diff output with sequences.*\r\n  * *Terminal summary statistics now use multiple colors.*\r\n\r\n  Also make sure to end the sentence with a `.`.\r\n\r\n- [ ] Add yourself to `AUTHORS` in alphabetical order.\n",
  "hints_text": "\n",
  "created_at": "2020-06-03T15:00:51Z",
  "version": "4.6",
  "FAIL_TO_PASS": "[\"testing/test_terminal.py::TestTerminalFunctional::test_summary_f_alias\", \"testing/test_terminal.py::TestTerminalFunctional::test_summary_s_alias\"]",
  "PASS_TO_PASS": "[\"test_pass_extra_reporting.py::test_this\", \"test_pass_output_reporting.py::test_pass_has_output\", \"test_pass_output_reporting.py::test_pass_no_output\", \"testing/test_terminal.py::test_plugin_nameversion[normal]\", \"testing/test_terminal.py::test_plugin_nameversion[prefix-strip]\", \"testing/test_terminal.py::test_plugin_nameversion[deduplicate]\", \"testing/test_terminal.py::test_getreportopt\", \"testing/test_terminal.py::test_summary_stats[red-1\", \"testing/test_terminal.py::test_summary_stats[yellow-1\", \"testing/test_terminal.py::test_summary_stats[green-5\", \"testing/test_terminal.py::test_summary_stats[green-1\", \"testing/test_terminal.py::test_summary_stats[yellow-no\", \"testing/test_terminal.py::test_skip_counting_towards_summary\", \"testing/test_terminal.py::test_skip_reasons_folding\", \"testing/test_terminal.py::test_line_with_reprcrash\", \"testing/test_terminal.py::TestTerminal::test_pass_skip_fail[default]\", \"testing/test_terminal.py::TestTerminal::test_pass_skip_fail[verbose]\", \"testing/test_terminal.py::TestTerminal::test_pass_skip_fail[quiet]\", \"testing/test_terminal.py::TestTerminal::test_pass_skip_fail[fulltrace]\", \"testing/test_terminal.py::TestTerminal::test_internalerror\", \"testing/test_terminal.py::TestTerminal::test_writeline\", \"testing/test_terminal.py::TestTerminal::test_show_runtest_logstart\", \"testing/test_terminal.py::TestTerminal::test_itemreport_subclasses_show_subclassed_file\", \"testing/test_terminal.py::TestTerminal::test_itemreport_directclasses_not_shown_as_subclasses\", \"testing/test_terminal.py::TestTerminal::test_keyboard_interrupt[default]\", \"testing/test_terminal.py::TestTerminal::test_keyboard_interrupt[verbose]\", \"testing/test_terminal.py::TestTerminal::test_keyboard_interrupt[quiet]\", \"testing/test_terminal.py::TestTerminal::test_keyboard_interrupt[fulltrace]\", \"testing/test_terminal.py::TestTerminal::test_keyboard_in_sessionstart\", \"testing/test_terminal.py::TestTerminal::test_collect_single_item\", \"testing/test_terminal.py::TestTerminal::test_rewrite\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_basic\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_skipped_module\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_display_test_description\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_failed_module\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_fatal\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_simple\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_error\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_missing_path\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_quiet\", \"testing/test_terminal.py::TestCollectonly::test_collectonly_more_quiet\", \"testing/test_terminal.py::TestFixtureReporting::test_setup_fixture_error\", \"testing/test_terminal.py::TestFixtureReporting::test_teardown_fixture_error\", \"testing/test_terminal.py::TestFixtureReporting::test_teardown_fixture_error_and_test_failure\", \"testing/test_terminal.py::TestFixtureReporting::test_setup_teardown_output_and_test_failure\", \"testing/test_terminal.py::TestTerminalFunctional::test_deselected\", \"testing/test_terminal.py::TestTerminalFunctional::test_deselected_with_hookwrapper\", \"testing/test_terminal.py::TestTerminalFunctional::test_show_deselected_items_using_markexpr_before_test_execution\", \"testing/test_terminal.py::TestTerminalFunctional::test_no_skip_summary_if_failure\", \"testing/test_terminal.py::TestTerminalFunctional::test_passes\", \"testing/test_terminal.py::TestTerminalFunctional::test_header_trailer_info\", \"testing/test_terminal.py::TestTerminalFunctional::test_header\", \"testing/test_terminal.py::TestTerminalFunctional::test_showlocals\", \"testing/test_terminal.py::TestTerminalFunctional::test_verbose_reporting\", \"testing/test_terminal.py::TestTerminalFunctional::test_quiet_reporting\", \"testing/test_terminal.py::TestTerminalFunctional::test_more_quiet_reporting\", \"testing/test_terminal.py::TestTerminalFunctional::test_report_collectionfinish_hook[no-params]\", \"testing/test_terminal.py::TestTerminalFunctional::test_report_collectionfinish_hook[collect-only]\", \"testing/test_terminal.py::test_fail_extra_reporting\", \"testing/test_terminal.py::test_fail_reporting_on_pass\", \"testing/test_terminal.py::test_pass_extra_reporting\", \"testing/test_terminal.py::test_pass_reporting_on_fail\", \"testing/test_terminal.py::test_pass_output_reporting\", \"testing/test_terminal.py::test_color_yes\", \"testing/test_terminal.py::test_color_no\", \"testing/test_terminal.py::test_color_yes_collection_on_non_atty[True]\", \"testing/test_terminal.py::test_color_yes_collection_on_non_atty[False]\", \"testing/test_terminal.py::test_terminalreporter_reportopt_addopts\", \"testing/test_terminal.py::test_tbstyle_short\", \"testing/test_terminal.py::test_traceconfig\", \"testing/test_terminal.py::TestGenericReporting::test_collect_fail[default]\", \"testing/test_terminal.py::TestGenericReporting::test_collect_fail[verbose]\", \"testing/test_terminal.py::TestGenericReporting::test_collect_fail[quiet]\", \"testing/test_terminal.py::TestGenericReporting::test_collect_fail[fulltrace]\", \"testing/test_terminal.py::TestGenericReporting::test_maxfailures[default]\", \"testing/test_terminal.py::TestGenericReporting::test_maxfailures[verbose]\", \"testing/test_terminal.py::TestGenericReporting::test_maxfailures[quiet]\", \"testing/test_terminal.py::TestGenericReporting::test_maxfailures[fulltrace]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_option[default]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_option[verbose]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_option[quiet]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_option[fulltrace]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_crashline[default]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_crashline[verbose]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_crashline[quiet]\", \"testing/test_terminal.py::TestGenericReporting::test_tb_crashline[fulltrace]\", \"testing/test_terminal.py::TestGenericReporting::test_pytest_report_header[default]\", \"testing/test_terminal.py::TestGenericReporting::test_pytest_report_header[verbose]\", \"testing/test_terminal.py::TestGenericReporting::test_pytest_report_header[quiet]\", \"testing/test_terminal.py::TestGenericReporting::test_pytest_report_header[fulltrace]\", \"testing/test_terminal.py::TestGenericReporting::test_show_capture\", \"testing/test_terminal.py::TestGenericReporting::test_show_capture_with_teardown_logs\", \"testing/test_terminal.py::test_fdopen_kept_alive_issue124\", \"testing/test_terminal.py::test_tbstyle_native_setup_error\", \"testing/test_terminal.py::test_terminal_summary\", \"testing/test_terminal.py::test_terminal_summary_warnings_are_displayed\", \"testing/test_terminal.py::test_terminal_summary_warnings_header_once\", \"testing/test_terminal.py::TestClassicOutputStyle::test_normal_verbosity\", \"testing/test_terminal.py::TestClassicOutputStyle::test_verbose\", \"testing/test_terminal.py::TestClassicOutputStyle::test_quiet\", \"testing/test_terminal.py::TestProgressOutputStyle::test_zero_tests_collected\", \"testing/test_terminal.py::TestProgressOutputStyle::test_normal\", \"testing/test_terminal.py::TestProgressOutputStyle::test_count\", \"testing/test_terminal.py::TestProgressOutputStyle::test_verbose\", \"testing/test_terminal.py::TestProgressOutputStyle::test_verbose_count\", \"testing/test_terminal.py::TestProgressOutputStyle::test_capture_no\", \"testing/test_terminal.py::TestProgressWithTeardown::test_teardown_simple\", \"testing/test_terminal.py::TestProgressWithTeardown::test_teardown_with_test_also_failing\", \"testing/test_terminal.py::TestProgressWithTeardown::test_teardown_many\", \"testing/test_terminal.py::TestProgressWithTeardown::test_teardown_many_verbose\"]",
  "environment_setup_commit": "d5843f89d3c008ddcb431adbc335b080a79e617e",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.935799",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}