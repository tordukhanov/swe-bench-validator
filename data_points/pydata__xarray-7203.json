{
  "repo": "pydata/xarray",
  "instance_id": "pydata__xarray-7203",
  "base_commit": "9951491e0b849834c369de522de2df8172a2e298",
  "patch": "diff --git a/xarray/core/formatting.py b/xarray/core/formatting.py\n--- a/xarray/core/formatting.py\n+++ b/xarray/core/formatting.py\n@@ -579,7 +579,7 @@ def short_data_repr(array):\n         return short_numpy_repr(array)\n     elif is_duck_array(internal_data):\n         return limit_lines(repr(array.data), limit=40)\n-    elif array._in_memory or array.size < 1e5:\n+    elif array._in_memory:\n         return short_numpy_repr(array)\n     else:\n         # internal xarray array type\n",
  "test_patch": "diff --git a/xarray/tests/test_formatting.py b/xarray/tests/test_formatting.py\n--- a/xarray/tests/test_formatting.py\n+++ b/xarray/tests/test_formatting.py\n@@ -575,17 +575,28 @@ def test_large_array_repr_length() -> None:\n \n @requires_netCDF4\n def test_repr_file_collapsed(tmp_path) -> None:\n-    arr = xr.DataArray(np.arange(300), dims=\"test\")\n-    arr.to_netcdf(tmp_path / \"test.nc\", engine=\"netcdf4\")\n+    arr_to_store = xr.DataArray(np.arange(300, dtype=np.int64), dims=\"test\")\n+    arr_to_store.to_netcdf(tmp_path / \"test.nc\", engine=\"netcdf4\")\n \n     with xr.open_dataarray(tmp_path / \"test.nc\") as arr, xr.set_options(\n         display_expand_data=False\n     ):\n-        actual = formatting.array_repr(arr)\n+        actual = repr(arr)\n         expected = dedent(\n             \"\"\"\\\n         <xarray.DataArray (test: 300)>\n-        array([  0,   1,   2, ..., 297, 298, 299])\n+        [300 values with dtype=int64]\n+        Dimensions without coordinates: test\"\"\"\n+        )\n+\n+        assert actual == expected\n+\n+        arr_loaded = arr.compute()\n+        actual = arr_loaded.__repr__()\n+        expected = dedent(\n+            \"\"\"\\\n+        <xarray.DataArray (test: 300)>\n+        0 1 2 3 4 5 6 7 8 9 10 11 12 ... 288 289 290 291 292 293 294 295 296 297 298 299\n         Dimensions without coordinates: test\"\"\"\n         )\n \n@@ -699,3 +710,18 @@ def test__element_formatter(n_elements: int = 100) -> None:\n     )\n     actual = intro + values\n     assert expected == actual\n+\n+\n+def test_lazy_array_wont_compute() -> None:\n+    from xarray.core.indexing import LazilyIndexedArray\n+\n+    class LazilyIndexedArrayNotComputable(LazilyIndexedArray):\n+        def __array__(self, dtype=None):\n+            raise NotImplementedError(\"Computing this array is not possible.\")\n+\n+    arr = LazilyIndexedArrayNotComputable(np.array([1, 2]))\n+    var = xr.DataArray(arr)\n+\n+    # These will crash if var.data are converted to numpy arrays:\n+    var.__repr__()\n+    var._repr_html_()\n",
  "problem_statement": "Avoid loading any data for reprs\n### What happened?\r\n\r\nFor \"small\" datasets, we load in to memory when displaying the repr. For cloud backed datasets with large number of \"small\" variables, this can use a lot of time sequentially loading O(100) variables just for a repr.\r\n\r\nhttps://github.com/pydata/xarray/blob/6c8db5ed005e000b35ad8b6ea9080105e608e976/xarray/core/formatting.py#L548-L549\r\n\r\n### What did you expect to happen?\r\n\r\nFast reprs!\r\n\r\n### Minimal Complete Verifiable Example\r\n\r\nThis dataset has 48 \"small\" variables\r\n```Python\r\nimport xarray as xr\r\n\r\ndc1 = xr.open_dataset('s3://its-live-data/datacubes/v02/N40E080/ITS_LIVE_vel_EPSG32645_G0120_X250000_Y4750000.zarr', engine= 'zarr', storage_options = {'anon':True})\r\ndc1._repr_html_()\r\n```\r\n\r\nOn `2022.03.0` this repr takes 36.4s\r\nIf I comment the `array.size` condition I get 6μs.\r\n\r\n\r\n### MVCE confirmation\r\n\r\n- [x] Minimal example — the example is as focused as reasonably possible to demonstrate the underlying issue in xarray.\r\n- [x] Complete example — the example is self-contained, including all data and the text of any traceback.\r\n- [x] Verifiable example — the example copy & pastes into an IPython prompt or [Binder notebook](https://mybinder.org/v2/gh/pydata/xarray/main?urlpath=lab/tree/doc/examples/blank_template.ipynb), returning the result.\r\n- [x] New issue — a search of GitHub Issues suggests this is not a duplicate.\r\n\r\n### Relevant log output\r\n\r\n_No response_\r\n\r\n### Anything else we need to know?\r\n\r\n_No response_\r\n\r\n### Environment\r\n\r\n<details>\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:43:32) [Clang 12.0.1 ]\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 21.5.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: ('en_US', 'UTF-8')\r\nlibhdf5: None\r\nlibnetcdf: None\r\n\r\nxarray: 2022.3.0\r\npandas: 1.4.2\r\nnumpy: 1.22.4\r\nscipy: 1.8.1\r\nnetCDF4: None\r\npydap: None\r\nh5netcdf: None\r\nh5py: None\r\nNio: None\r\nzarr: 2.11.3\r\ncftime: None\r\nnc_time_axis: None\r\nPseudoNetCDF: None\r\nrasterio: 1.2.10\r\ncfgrib: None\r\niris: None\r\nbottleneck: None\r\ndask: 2022.05.2\r\ndistributed: None\r\nmatplotlib: 3.5.2\r\ncartopy: 0.20.2\r\nseaborn: 0.11.2\r\nnumbagg: None\r\nfsspec: 2022.5.0\r\ncupy: None\r\npint: None\r\nsparse: None\r\nsetuptools: 62.3.2\r\npip: 22.1.2\r\nconda: None\r\npytest: None\r\nIPython: 8.4.0\r\nsphinx: 4.5.0\r\n\r\n\r\n</details>\r\n\n",
  "hints_text": "cc @e-marshall @scottyhq \nSo what's the solution here? Add another condition checking for more than a certain number of variables? Somehow check whether a dataset is cloud-backed?\nI think the best thing to do is to not load anything unless asked to. So delete the `array.size < 1e5` condition.\nThis would be a pretty small change and only applies for loading data into numpy arrays, for example current repr for a variable followed by modified for the example dataset above (which already happens for large arrays):\r\n\r\n<img width=\"711\" alt=\"Screen Shot 2022-06-24 at 4 38 19 PM\" src=\"https://user-images.githubusercontent.com/3924836/175749415-04154ad2-a456-4698-9e2c-f8f4d2ec3e1e.png\">\r\n\r\n---\r\n\r\n<img width=\"715\" alt=\"Screen Shot 2022-06-24 at 4 37 26 PM\" src=\"https://user-images.githubusercontent.com/3924836/175749402-dd465f42-f13d-4801-a287-ddef68a173d2.png\">\r\n\r\nSeeing a few values at the edges can be nice, so this makes me realize how data summaries in the metadata (Zarr or STAC) is great for large datasets on cloud storage.  \r\n\nIs the print still slow if somewhere just before the load the array was masked to only show a few start and end elements, `array[[0, 1, -2, -1]]`?",
  "created_at": "2022-10-24T05:12:40Z",
  "version": "2022.09",
  "FAIL_TO_PASS": "[\"xarray/tests/test_formatting.py::test_lazy_array_wont_compute\"]",
  "PASS_TO_PASS": "[\"xarray/tests/test_formatting.py::TestFormatting::test_get_indexer_at_least_n_items\", \"xarray/tests/test_formatting.py::TestFormatting::test_first_n_items\", \"xarray/tests/test_formatting.py::TestFormatting::test_last_n_items\", \"xarray/tests/test_formatting.py::TestFormatting::test_last_item\", \"xarray/tests/test_formatting.py::TestFormatting::test_format_item\", \"xarray/tests/test_formatting.py::TestFormatting::test_format_items\", \"xarray/tests/test_formatting.py::TestFormatting::test_format_array_flat\", \"xarray/tests/test_formatting.py::TestFormatting::test_pretty_print\", \"xarray/tests/test_formatting.py::TestFormatting::test_maybe_truncate\", \"xarray/tests/test_formatting.py::TestFormatting::test_format_timestamp_invalid_pandas_format\", \"xarray/tests/test_formatting.py::TestFormatting::test_format_timestamp_out_of_bounds\", \"xarray/tests/test_formatting.py::TestFormatting::test_attribute_repr\", \"xarray/tests/test_formatting.py::TestFormatting::test_index_repr\", \"xarray/tests/test_formatting.py::TestFormatting::test_diff_array_repr\", \"xarray/tests/test_formatting.py::TestFormatting::test_diff_attrs_repr_with_array\", \"xarray/tests/test_formatting.py::TestFormatting::test_diff_dataset_repr\", \"xarray/tests/test_formatting.py::TestFormatting::test_array_repr\", \"xarray/tests/test_formatting.py::TestFormatting::test_array_repr_variable\", \"xarray/tests/test_formatting.py::TestFormatting::test_array_repr_recursive\", \"xarray/tests/test_formatting.py::TestFormatting::test_array_scalar_format\", \"xarray/tests/test_formatting.py::test_inline_variable_array_repr_custom_repr\", \"xarray/tests/test_formatting.py::test_set_numpy_options\", \"xarray/tests/test_formatting.py::test_short_numpy_repr\", \"xarray/tests/test_formatting.py::test_large_array_repr_length\", \"xarray/tests/test_formatting.py::test_repr_file_collapsed\", \"xarray/tests/test_formatting.py::test__mapping_repr[50-40-30]\", \"xarray/tests/test_formatting.py::test__mapping_repr[35-40-30]\", \"xarray/tests/test_formatting.py::test__mapping_repr[11-40-30]\", \"xarray/tests/test_formatting.py::test__mapping_repr[1-40-30]\", \"xarray/tests/test_formatting.py::test__mapping_repr_recursive\", \"xarray/tests/test_formatting.py::test__element_formatter\"]",
  "environment_setup_commit": "087ebbb78668bdf5d2d41c3b2553e3f29ce75be1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.904779",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}