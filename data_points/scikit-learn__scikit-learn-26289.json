{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-26289",
  "base_commit": "8521819eecbacb93deb87fce28842680ab1a5301",
  "patch": "diff --git a/sklearn/tree/_export.py b/sklearn/tree/_export.py\n--- a/sklearn/tree/_export.py\n+++ b/sklearn/tree/_export.py\n@@ -16,7 +16,7 @@\n \n import numpy as np\n \n-from ..utils.validation import check_is_fitted\n+from ..utils.validation import check_is_fitted, check_array\n from ..utils._param_validation import Interval, validate_params, StrOptions\n \n from ..base import is_classifier\n@@ -788,11 +788,11 @@ def export_graphviz(\n         The maximum depth of the representation. If None, the tree is fully\n         generated.\n \n-    feature_names : list of str, default=None\n-        Names of each of the features.\n+    feature_names : array-like of shape (n_features,), default=None\n+        An array containing the feature names.\n         If None, generic names will be used (\"x[0]\", \"x[1]\", ...).\n \n-    class_names : list of str or bool, default=None\n+    class_names : array-like of shape (n_classes,) or bool, default=None\n         Names of each of the target classes in ascending numerical order.\n         Only relevant for classification and not supported for multi-output.\n         If ``True``, shows a symbolic representation of the class name.\n@@ -857,6 +857,14 @@ def export_graphviz(\n     >>> tree.export_graphviz(clf)\n     'digraph Tree {...\n     \"\"\"\n+    if feature_names is not None:\n+        feature_names = check_array(\n+            feature_names, ensure_2d=False, dtype=None, ensure_min_samples=0\n+        )\n+    if class_names is not None and not isinstance(class_names, bool):\n+        class_names = check_array(\n+            class_names, ensure_2d=False, dtype=None, ensure_min_samples=0\n+        )\n \n     check_is_fitted(decision_tree)\n     own_file = False\n@@ -924,8 +932,8 @@ def compute_depth_(\n @validate_params(\n     {\n         \"decision_tree\": [DecisionTreeClassifier, DecisionTreeRegressor],\n-        \"feature_names\": [list, None],\n-        \"class_names\": [list, None],\n+        \"feature_names\": [\"array-like\", None],\n+        \"class_names\": [\"array-like\", None],\n         \"max_depth\": [Interval(Integral, 0, None, closed=\"left\"), None],\n         \"spacing\": [Interval(Integral, 1, None, closed=\"left\"), None],\n         \"decimals\": [Interval(Integral, 0, None, closed=\"left\"), None],\n@@ -953,17 +961,17 @@ def export_text(\n         It can be an instance of\n         DecisionTreeClassifier or DecisionTreeRegressor.\n \n-    feature_names : list of str, default=None\n-        A list of length n_features containing the feature names.\n+    feature_names : array-like of shape (n_features,), default=None\n+        An array containing the feature names.\n         If None generic names will be used (\"feature_0\", \"feature_1\", ...).\n \n-    class_names : list or None, default=None\n+    class_names : array-like of shape (n_classes,), default=None\n         Names of each of the target classes in ascending numerical order.\n         Only relevant for classification and not supported for multi-output.\n \n         - if `None`, the class names are delegated to `decision_tree.classes_`;\n-        - if a list, then `class_names` will be used as class names instead\n-          of `decision_tree.classes_`. The length of `class_names` must match\n+        - otherwise, `class_names` will be used as class names instead of\n+          `decision_tree.classes_`. The length of `class_names` must match\n           the length of `decision_tree.classes_`.\n \n         .. versionadded:: 1.3\n@@ -1008,6 +1016,15 @@ def export_text(\n     |   |--- petal width (cm) >  1.75\n     |   |   |--- class: 2\n     \"\"\"\n+    if feature_names is not None:\n+        feature_names = check_array(\n+            feature_names, ensure_2d=False, dtype=None, ensure_min_samples=0\n+        )\n+    if class_names is not None:\n+        class_names = check_array(\n+            class_names, ensure_2d=False, dtype=None, ensure_min_samples=0\n+        )\n+\n     check_is_fitted(decision_tree)\n     tree_ = decision_tree.tree_\n     if is_classifier(decision_tree):\n@@ -1015,7 +1032,7 @@ def export_text(\n             class_names = decision_tree.classes_\n         elif len(class_names) != len(decision_tree.classes_):\n             raise ValueError(\n-                \"When `class_names` is a list, it should contain as\"\n+                \"When `class_names` is an array, it should contain as\"\n                 \" many items as `decision_tree.classes_`. Got\"\n                 f\" {len(class_names)} while the tree was fitted with\"\n                 f\" {len(decision_tree.classes_)} classes.\"\n@@ -1037,7 +1054,7 @@ def export_text(\n     else:\n         value_fmt = \"{}{} value: {}\\n\"\n \n-    if feature_names:\n+    if feature_names is not None:\n         feature_names_ = [\n             feature_names[i] if i != _tree.TREE_UNDEFINED else None\n             for i in tree_.feature\n",
  "test_patch": "diff --git a/sklearn/tree/tests/test_export.py b/sklearn/tree/tests/test_export.py\n--- a/sklearn/tree/tests/test_export.py\n+++ b/sklearn/tree/tests/test_export.py\n@@ -4,6 +4,7 @@\n from re import finditer, search\n from textwrap import dedent\n \n+import numpy as np\n from numpy.random import RandomState\n import pytest\n \n@@ -48,48 +49,6 @@ def test_graphviz_toy():\n \n     assert contents1 == contents2\n \n-    # Test with feature_names\n-    contents1 = export_graphviz(\n-        clf, feature_names=[\"feature0\", \"feature1\"], out_file=None\n-    )\n-    contents2 = (\n-        \"digraph Tree {\\n\"\n-        'node [shape=box, fontname=\"helvetica\"] ;\\n'\n-        'edge [fontname=\"helvetica\"] ;\\n'\n-        '0 [label=\"feature0 <= 0.0\\\\ngini = 0.5\\\\nsamples = 6\\\\n'\n-        'value = [3, 3]\"] ;\\n'\n-        '1 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [3, 0]\"] ;\\n'\n-        \"0 -> 1 [labeldistance=2.5, labelangle=45, \"\n-        'headlabel=\"True\"] ;\\n'\n-        '2 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [0, 3]\"] ;\\n'\n-        \"0 -> 2 [labeldistance=2.5, labelangle=-45, \"\n-        'headlabel=\"False\"] ;\\n'\n-        \"}\"\n-    )\n-\n-    assert contents1 == contents2\n-\n-    # Test with class_names\n-    contents1 = export_graphviz(clf, class_names=[\"yes\", \"no\"], out_file=None)\n-    contents2 = (\n-        \"digraph Tree {\\n\"\n-        'node [shape=box, fontname=\"helvetica\"] ;\\n'\n-        'edge [fontname=\"helvetica\"] ;\\n'\n-        '0 [label=\"x[0] <= 0.0\\\\ngini = 0.5\\\\nsamples = 6\\\\n'\n-        'value = [3, 3]\\\\nclass = yes\"] ;\\n'\n-        '1 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [3, 0]\\\\n'\n-        'class = yes\"] ;\\n'\n-        \"0 -> 1 [labeldistance=2.5, labelangle=45, \"\n-        'headlabel=\"True\"] ;\\n'\n-        '2 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [0, 3]\\\\n'\n-        'class = no\"] ;\\n'\n-        \"0 -> 2 [labeldistance=2.5, labelangle=-45, \"\n-        'headlabel=\"False\"] ;\\n'\n-        \"}\"\n-    )\n-\n-    assert contents1 == contents2\n-\n     # Test plot_options\n     contents1 = export_graphviz(\n         clf,\n@@ -249,6 +208,60 @@ def test_graphviz_toy():\n     )\n \n \n+@pytest.mark.parametrize(\"constructor\", [list, np.array])\n+def test_graphviz_feature_class_names_array_support(constructor):\n+    # Check that export_graphviz treats feature names\n+    # and class names correctly and supports arrays\n+    clf = DecisionTreeClassifier(\n+        max_depth=3, min_samples_split=2, criterion=\"gini\", random_state=2\n+    )\n+    clf.fit(X, y)\n+\n+    # Test with feature_names\n+    contents1 = export_graphviz(\n+        clf, feature_names=constructor([\"feature0\", \"feature1\"]), out_file=None\n+    )\n+    contents2 = (\n+        \"digraph Tree {\\n\"\n+        'node [shape=box, fontname=\"helvetica\"] ;\\n'\n+        'edge [fontname=\"helvetica\"] ;\\n'\n+        '0 [label=\"feature0 <= 0.0\\\\ngini = 0.5\\\\nsamples = 6\\\\n'\n+        'value = [3, 3]\"] ;\\n'\n+        '1 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [3, 0]\"] ;\\n'\n+        \"0 -> 1 [labeldistance=2.5, labelangle=45, \"\n+        'headlabel=\"True\"] ;\\n'\n+        '2 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [0, 3]\"] ;\\n'\n+        \"0 -> 2 [labeldistance=2.5, labelangle=-45, \"\n+        'headlabel=\"False\"] ;\\n'\n+        \"}\"\n+    )\n+\n+    assert contents1 == contents2\n+\n+    # Test with class_names\n+    contents1 = export_graphviz(\n+        clf, class_names=constructor([\"yes\", \"no\"]), out_file=None\n+    )\n+    contents2 = (\n+        \"digraph Tree {\\n\"\n+        'node [shape=box, fontname=\"helvetica\"] ;\\n'\n+        'edge [fontname=\"helvetica\"] ;\\n'\n+        '0 [label=\"x[0] <= 0.0\\\\ngini = 0.5\\\\nsamples = 6\\\\n'\n+        'value = [3, 3]\\\\nclass = yes\"] ;\\n'\n+        '1 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [3, 0]\\\\n'\n+        'class = yes\"] ;\\n'\n+        \"0 -> 1 [labeldistance=2.5, labelangle=45, \"\n+        'headlabel=\"True\"] ;\\n'\n+        '2 [label=\"gini = 0.0\\\\nsamples = 3\\\\nvalue = [0, 3]\\\\n'\n+        'class = no\"] ;\\n'\n+        \"0 -> 2 [labeldistance=2.5, labelangle=-45, \"\n+        'headlabel=\"False\"] ;\\n'\n+        \"}\"\n+    )\n+\n+    assert contents1 == contents2\n+\n+\n def test_graphviz_errors():\n     # Check for errors of export_graphviz\n     clf = DecisionTreeClassifier(max_depth=3, min_samples_split=2)\n@@ -352,7 +365,7 @@ def test_export_text_errors():\n     with pytest.raises(ValueError, match=err_msg):\n         export_text(clf, feature_names=[\"a\"])\n     err_msg = (\n-        \"When `class_names` is a list, it should contain as\"\n+        \"When `class_names` is an array, it should contain as\"\n         \" many items as `decision_tree.classes_`. Got 1 while\"\n         \" the tree was fitted with 2 classes.\"\n     )\n@@ -377,22 +390,6 @@ def test_export_text():\n     # testing that the rest of the tree is truncated\n     assert export_text(clf, max_depth=10) == expected_report\n \n-    expected_report = dedent(\"\"\"\n-    |--- b <= 0.00\n-    |   |--- class: -1\n-    |--- b >  0.00\n-    |   |--- class: 1\n-    \"\"\").lstrip()\n-    assert export_text(clf, feature_names=[\"a\", \"b\"]) == expected_report\n-\n-    expected_report = dedent(\"\"\"\n-    |--- feature_1 <= 0.00\n-    |   |--- class: cat\n-    |--- feature_1 >  0.00\n-    |   |--- class: dog\n-    \"\"\").lstrip()\n-    assert export_text(clf, class_names=[\"cat\", \"dog\"]) == expected_report\n-\n     expected_report = dedent(\"\"\"\n     |--- feature_1 <= 0.00\n     |   |--- weights: [3.00, 0.00] class: -1\n@@ -453,6 +450,30 @@ def test_export_text():\n     )\n \n \n+@pytest.mark.parametrize(\"constructor\", [list, np.array])\n+def test_export_text_feature_class_names_array_support(constructor):\n+    # Check that export_graphviz treats feature names\n+    # and class names correctly and supports arrays\n+    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n+    clf.fit(X, y)\n+\n+    expected_report = dedent(\"\"\"\n+    |--- b <= 0.00\n+    |   |--- class: -1\n+    |--- b >  0.00\n+    |   |--- class: 1\n+    \"\"\").lstrip()\n+    assert export_text(clf, feature_names=constructor([\"a\", \"b\"])) == expected_report\n+\n+    expected_report = dedent(\"\"\"\n+    |--- feature_1 <= 0.00\n+    |   |--- class: cat\n+    |--- feature_1 >  0.00\n+    |   |--- class: dog\n+    \"\"\").lstrip()\n+    assert export_text(clf, class_names=constructor([\"cat\", \"dog\"])) == expected_report\n+\n+\n def test_plot_tree_entropy(pyplot):\n     # mostly smoke tests\n     # Check correctness of export_graphviz for criterion = entropy\n",
  "problem_statement": "sklearn.tree.export_text failing when feature_names supplied\nfolks, I'm not sure why this works for\r\n```py\r\nimport sklearn.tree\r\nprint(my_feature_names)\r\n['0' '0 trump' '0 trump versus' ... 'zur' 'zur ckhalten' 'zur ckhalten muss']\r\n\r\ntree.export_graphviz(clf, out_file=None, max_depth=4, feature_names=my_feature_names)\r\n```\r\nbut not for \r\n\r\n```py\r\nimport sklearn.tree\r\nprint(my_feature_names)\r\n['0' '0 trump' '0 trump versus' ... 'zur' 'zur ckhalten' 'zur ckhalten muss']\r\n\r\ntree.export_text(clf, max_depth=4, feature_names=my_feature_names)\r\n\r\nTraceback (most recent call last):\r\n  File \"./sample-python-projects/machine-learning/HW1_Q2a.py\", line 72, in <module>\r\n    print(tree.export_text(clf, max_depth=4, feature_names=my_feature_names))\r\n  File \"C:\\Users\\sam\\python\\lib\\site-packages\\sklearn\\tree\\_export.py\", line 1016, in export_text\r\n    if feature_names:\r\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\r\n```\r\n\r\nCan anyone help?\n",
  "hints_text": "Could you please post a minimal reproducible? (something we can copy paste in its entirety to produce the issue).\n@NickKanellos From the error message, it seems that the feature names you passed in is an array, but as [documented](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html), `feature_names` must either be a list of strings or `None`.\r\n\r\n> feature_nameslist of str, default=None\r\nNames of each of the features. If None, generic names will be used (“x[0]”, “x[1]”, …).",
  "created_at": "2023-04-27T13:39:27Z",
  "version": "1.3",
  "FAIL_TO_PASS": "[\"sklearn/tree/tests/test_export.py::test_export_text_errors\", \"sklearn/tree/tests/test_export.py::test_export_text_feature_class_names_array_support[array]\"]",
  "PASS_TO_PASS": "[\"sklearn/tree/tests/test_export.py::test_graphviz_toy\", \"sklearn/tree/tests/test_export.py::test_graphviz_feature_class_names_array_support[list]\", \"sklearn/tree/tests/test_export.py::test_graphviz_feature_class_names_array_support[array]\", \"sklearn/tree/tests/test_export.py::test_graphviz_errors\", \"sklearn/tree/tests/test_export.py::test_friedman_mse_in_graphviz\", \"sklearn/tree/tests/test_export.py::test_precision\", \"sklearn/tree/tests/test_export.py::test_export_text\", \"sklearn/tree/tests/test_export.py::test_export_text_feature_class_names_array_support[list]\", \"sklearn/tree/tests/test_export.py::test_plot_tree_entropy\", \"sklearn/tree/tests/test_export.py::test_plot_tree_gini\", \"sklearn/tree/tests/test_export.py::test_not_fitted_tree\"]",
  "environment_setup_commit": "1e8a5b833d1b58f3ab84099c4582239af854b23a",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.025088",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}