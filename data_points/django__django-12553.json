{
  "repo": "django/django",
  "instance_id": "django__django-12553",
  "base_commit": "7072bff1fd13ea706b2dc0ca10feef755872eb68",
  "patch": "diff --git a/django/contrib/auth/hashers.py b/django/contrib/auth/hashers.py\n--- a/django/contrib/auth/hashers.py\n+++ b/django/contrib/auth/hashers.py\n@@ -3,6 +3,7 @@\n import functools\n import hashlib\n import importlib\n+import math\n import warnings\n \n from django.conf import settings\n@@ -161,6 +162,11 @@ def mask_hash(hash, show=6, char=\"*\"):\n     return masked\n \n \n+def must_update_salt(salt, expected_entropy):\n+    # Each character in the salt provides log_2(len(alphabet)) bits of entropy.\n+    return len(salt) * math.log2(len(RANDOM_STRING_CHARS)) < expected_entropy\n+\n+\n class BasePasswordHasher:\n     \"\"\"\n     Abstract base class for password hashers\n@@ -172,6 +178,7 @@ class BasePasswordHasher:\n     \"\"\"\n     algorithm = None\n     library = None\n+    salt_entropy = 128\n \n     def _load_library(self):\n         if self.library is not None:\n@@ -189,9 +196,14 @@ def _load_library(self):\n                          self.__class__.__name__)\n \n     def salt(self):\n-        \"\"\"Generate a cryptographically secure nonce salt in ASCII.\"\"\"\n-        # 12 returns a 71-bit value, log_2(len(RANDOM_STRING_CHARS)^12) =~ 71 bits\n-        return get_random_string(12, RANDOM_STRING_CHARS)\n+        \"\"\"\n+        Generate a cryptographically secure nonce salt in ASCII with an entropy\n+        of at least `salt_entropy` bits.\n+        \"\"\"\n+        # Each character in the salt provides\n+        # log_2(len(alphabet)) bits of entropy.\n+        char_count = math.ceil(self.salt_entropy / math.log2(len(RANDOM_STRING_CHARS)))\n+        return get_random_string(char_count, allowed_chars=RANDOM_STRING_CHARS)\n \n     def verify(self, password, encoded):\n         \"\"\"Check if the given password is correct.\"\"\"\n@@ -290,7 +302,8 @@ def safe_summary(self, encoded):\n \n     def must_update(self, encoded):\n         decoded = self.decode(encoded)\n-        return decoded['iterations'] != self.iterations\n+        update_salt = must_update_salt(decoded['salt'], self.salt_entropy)\n+        return (decoded['iterations'] != self.iterations) or update_salt\n \n     def harden_runtime(self, password, encoded):\n         decoded = self.decode(encoded)\n@@ -383,12 +396,14 @@ def safe_summary(self, encoded):\n         }\n \n     def must_update(self, encoded):\n-        current_params = self.decode(encoded)['params']\n+        decoded = self.decode(encoded)\n+        current_params = decoded['params']\n         new_params = self.params()\n         # Set salt_len to the salt_len of the current parameters because salt\n         # is explicitly passed to argon2.\n         new_params.salt_len = current_params.salt_len\n-        return current_params != new_params\n+        update_salt = must_update_salt(decoded['salt'], self.salt_entropy)\n+        return (current_params != new_params) or update_salt\n \n     def harden_runtime(self, password, encoded):\n         # The runtime for Argon2 is too complicated to implement a sensible\n@@ -531,6 +546,10 @@ def safe_summary(self, encoded):\n             _('hash'): mask_hash(decoded['hash']),\n         }\n \n+    def must_update(self, encoded):\n+        decoded = self.decode(encoded)\n+        return must_update_salt(decoded['salt'], self.salt_entropy)\n+\n     def harden_runtime(self, password, encoded):\n         pass\n \n@@ -569,6 +588,10 @@ def safe_summary(self, encoded):\n             _('hash'): mask_hash(decoded['hash']),\n         }\n \n+    def must_update(self, encoded):\n+        decoded = self.decode(encoded)\n+        return must_update_salt(decoded['salt'], self.salt_entropy)\n+\n     def harden_runtime(self, password, encoded):\n         pass\n \n",
  "test_patch": "diff --git a/tests/auth_tests/test_hashers.py b/tests/auth_tests/test_hashers.py\n--- a/tests/auth_tests/test_hashers.py\n+++ b/tests/auth_tests/test_hashers.py\n@@ -3,9 +3,9 @@\n from django.conf.global_settings import PASSWORD_HASHERS\n from django.contrib.auth.hashers import (\n     UNUSABLE_PASSWORD_PREFIX, UNUSABLE_PASSWORD_SUFFIX_LENGTH,\n-    BasePasswordHasher, PBKDF2PasswordHasher, PBKDF2SHA1PasswordHasher,\n-    check_password, get_hasher, identify_hasher, is_password_usable,\n-    make_password,\n+    BasePasswordHasher, BCryptPasswordHasher, BCryptSHA256PasswordHasher,\n+    PBKDF2PasswordHasher, PBKDF2SHA1PasswordHasher, check_password, get_hasher,\n+    identify_hasher, is_password_usable, make_password,\n )\n from django.test import SimpleTestCase\n from django.test.utils import override_settings\n@@ -74,6 +74,12 @@ def test_pbkdf2(self):\n         self.assertTrue(is_password_usable(blank_encoded))\n         self.assertTrue(check_password('', blank_encoded))\n         self.assertFalse(check_password(' ', blank_encoded))\n+        # Salt entropy check.\n+        hasher = get_hasher('pbkdf2_sha256')\n+        encoded_weak_salt = make_password('lètmein', 'iodizedsalt', 'pbkdf2_sha256')\n+        encoded_strong_salt = make_password('lètmein', hasher.salt(), 'pbkdf2_sha256')\n+        self.assertIs(hasher.must_update(encoded_weak_salt), True)\n+        self.assertIs(hasher.must_update(encoded_strong_salt), False)\n \n     @override_settings(PASSWORD_HASHERS=['django.contrib.auth.hashers.SHA1PasswordHasher'])\n     def test_sha1(self):\n@@ -89,6 +95,12 @@ def test_sha1(self):\n         self.assertTrue(is_password_usable(blank_encoded))\n         self.assertTrue(check_password('', blank_encoded))\n         self.assertFalse(check_password(' ', blank_encoded))\n+        # Salt entropy check.\n+        hasher = get_hasher('sha1')\n+        encoded_weak_salt = make_password('lètmein', 'iodizedsalt', 'sha1')\n+        encoded_strong_salt = make_password('lètmein', hasher.salt(), 'sha1')\n+        self.assertIs(hasher.must_update(encoded_weak_salt), True)\n+        self.assertIs(hasher.must_update(encoded_strong_salt), False)\n \n     @override_settings(PASSWORD_HASHERS=['django.contrib.auth.hashers.MD5PasswordHasher'])\n     def test_md5(self):\n@@ -104,6 +116,12 @@ def test_md5(self):\n         self.assertTrue(is_password_usable(blank_encoded))\n         self.assertTrue(check_password('', blank_encoded))\n         self.assertFalse(check_password(' ', blank_encoded))\n+        # Salt entropy check.\n+        hasher = get_hasher('md5')\n+        encoded_weak_salt = make_password('lètmein', 'iodizedsalt', 'md5')\n+        encoded_strong_salt = make_password('lètmein', hasher.salt(), 'md5')\n+        self.assertIs(hasher.must_update(encoded_weak_salt), True)\n+        self.assertIs(hasher.must_update(encoded_strong_salt), False)\n \n     @override_settings(PASSWORD_HASHERS=['django.contrib.auth.hashers.UnsaltedMD5PasswordHasher'])\n     def test_unsalted_md5(self):\n@@ -305,6 +323,18 @@ def test_low_level_pbkdf2_sha1(self):\n         self.assertEqual(encoded, 'pbkdf2_sha1$260000$seasalt2$wAibXvW6jgvatCdONi6SMJ6q7mI=')\n         self.assertTrue(hasher.verify('lètmein', encoded))\n \n+    @skipUnless(bcrypt, 'bcrypt not installed')\n+    def test_bcrypt_salt_check(self):\n+        hasher = BCryptPasswordHasher()\n+        encoded = hasher.encode('lètmein', hasher.salt())\n+        self.assertIs(hasher.must_update(encoded), False)\n+\n+    @skipUnless(bcrypt, 'bcrypt not installed')\n+    def test_bcryptsha256_salt_check(self):\n+        hasher = BCryptSHA256PasswordHasher()\n+        encoded = hasher.encode('lètmein', hasher.salt())\n+        self.assertIs(hasher.must_update(encoded), False)\n+\n     @override_settings(\n         PASSWORD_HASHERS=[\n             'django.contrib.auth.hashers.PBKDF2PasswordHasher',\n@@ -525,6 +555,12 @@ def test_argon2(self):\n         )\n         self.assertIs(check_password('secret', encoded), True)\n         self.assertIs(check_password('wrong', encoded), False)\n+        # Salt entropy check.\n+        hasher = get_hasher('argon2')\n+        encoded_weak_salt = make_password('lètmein', 'iodizedsalt', 'argon2')\n+        encoded_strong_salt = make_password('lètmein', hasher.salt(), 'argon2')\n+        self.assertIs(hasher.must_update(encoded_weak_salt), True)\n+        self.assertIs(hasher.must_update(encoded_strong_salt), False)\n \n     def test_argon2_decode(self):\n         salt = 'abcdefghijk'\ndiff --git a/tests/auth_tests/test_views.py b/tests/auth_tests/test_views.py\n--- a/tests/auth_tests/test_views.py\n+++ b/tests/auth_tests/test_views.py\n@@ -1269,7 +1269,7 @@ def test_view_user_password_is_readonly(self):\n         self.assertContains(\n             response,\n             '<strong>algorithm</strong>: %s\\n\\n'\n-            '<strong>salt</strong>: %s**********\\n\\n'\n+            '<strong>salt</strong>: %s********************\\n\\n'\n             '<strong>hash</strong>: %s**************************\\n\\n' % (\n                 algo, salt[:2], hash_string[:6],\n             ),\n",
  "problem_statement": "Increase default password salt size in BasePasswordHasher.\nDescription\n\t \n\t\t(last modified by Jon Moroney)\n\t \nI've made a patch for this here\n​https://github.com/django/django/pull/12553\nWhich changes the default salt size from ~71 bits to ~131 bits\nThe rational is that modern guidance suggests a 128 bit minimum on salt sizes\nOWASP: ​https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Password_Storage_Cheat_Sheet.md#salting\nPython: ​https://docs.python.org/3/library/hashlib.html#hashlib.pbkdf2_hmac\nNIST: ​https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-132.pdf\nIn the case of NIST this is technically a hard requirement.\n",
  "hints_text": "I'm not sure.This method is not strictly to generate a salt. I would rather change a BasePasswordHasher.salt() to return get_random_string(22).\nIn general I like the idea of just increasing get_random_string and not doing it in X locations as needed. But I fear that a subtle change like this might break quite a few systems, so I am with Mariusz to do it just for the hasher (not every usage of get_random_string has the same security requirements). I didn't check, but do we have tests for changing salt lengths and how the update works?\nBTW, I think we should deprecate calling get_random_string without a length argument, but this may be the subject of a separate ticket?\nFlorian, it seems that it's tested only in ​auth_tests.test_views.ChangelistTests. Claude, yes a separate ticket.\nThanks for the comments all. I've rebased on the current master and changed the return of BasePasswordHasher.salt as suggested.\nAs an aside, would it be possible to get this back ported to the django 2.2.x branch once it's merged?\nReplying to felixxm: Florian, it seems that it's tested only in ​auth_tests.test_views.ChangelistTests. Mhm, what does this mean for existing password hashes, will they get updated to the new salt length? I get the feeling that the module level constant CRYPTO_SALT_LENGTH should be an attribute salt_length on BasePasswordHasher and must_update should take this into account.\nReplying to Florian Apolloner: Replying to felixxm: Florian, it seems that it's tested only in ​auth_tests.test_views.ChangelistTests. Mhm, what does this mean for existing password hashes, will they get updated to the new salt length? I get the feeling that the module level constant CRYPTO_SALT_LENGTH should be an attribute salt_length on BasePasswordHasher and must_update should take this into account. Would that change must_update at the BasePasswordHasher level to something like def must_update(self, encoded): return self.salt_length != len(encoded.salt) ? If so, would that first require an update to go out with the attribute set to 12? Or would this be on a case by case basis for each hasher? If the later case would it not make sense to simply add a length check on each of the relevant hashers? eg. for pbkdf2 def must_update(self, encoded): algorithm, iterations, salt, hash = encoded.split('$', 3) return int(iterations) != self.iterations || len(salt) != self.salt_length Another edit (sorry): I've added a commit to my PR which adds what I think the former logic should look like. Please let me know if that's the route you'd like to take and/or if the specific logic needs an update.\nFlorian, I checked builtin hashers: BCryptSHA256PasswordHasher, BCryptPasswordHasher, UnsaltedSHA1PasswordHasher, UnsaltedMD5PasswordHasher, CryptPasswordHasher are not affected because they override salt(), PBKDF2PasswordHasher, PBKDF2SHA1PasswordHasher, Argon2PasswordHasher, SHA1PasswordHasher, and MD5PasswordHasher use BasePasswordHasher.salt(). We should introduce salt_length attribute in a separate PR/commit and take it into account in must_update() for affected hashers. I'm not sure how to set salt_length for hashers that override salt().\nReplying to felixxm: We should introduce salt_length attribute in a separate PR/commit and take it into account in must_update() for affected hashers. Ok, I am fine with that approach too. I'm not sure how to set salt_length for hashers that override salt(). That is a good question indeed. For the unsalted variants we can set it to zero just fine and afaik bcrypt also defines it with a fixed length: ​https://github.com/pyca/bcrypt/blob/master/src/bcrypt/__init__.py#L50 and is unlikely to change. So we could set salt_length everywhere and update the hashers to use the builtin must_update in addition to their own.\nActually handling in must_update of the base hasher might be hard, because the salt format is specific to the hasher, so we might need to add a decode function? *yikes*\nI think we can assume that safe_summary() returns salt and if not then salt's length is equal to 0.\nReplying to felixxm: I think we can assume that safe_summary() returns salt and if not then salt's length is equal to 0. I agree. Though I think it's better to assume that salt's length is undefined if the safe_summary dict has no entry. Assuming zero will result in 0 != self.salt_length and that will always trigger. On my branch I've had to account for two cases to pass the tests def must_update(self, encoded): try: return len(self.safe_summary(encoded)['salt']) != self.salt_length except (KeyError, NotImplementedError): return False One is just the lack of a salt in the dict, but the second is that not all derived classes implement safe_summary. I think it would be useful to enforce an implementation if possible, but I'm not certain that's possible in python and that's probably a separate PR anyway.\nReplying to felixxm: I think we can assume that safe_summary() returns salt and if not then salt's length is equal to 0. Yes but if it does return a salt it doesn't neccessarily tell you anything about the length. (It wouldn't be unheard off if a hasher were to return a truncated salt there…)\nReplying to Florian Apolloner: Yes but if it does return a salt it doesn't neccessarily tell you anything about the length. (It wouldn't be unheard off if a hasher were to return a truncated salt there…) So then is it better to force each hasher to implement it's own must_update and move the salt_length? Variable to the hashers?\nThat is the million dollar question :) Salt is common enough through all hashers (compared to something like memory requirements) that it is something that could be in the base hasher.\nLet me ask the question a different way then; which route should I implement in my pr? :p\nReplying to Jon Moroney: Let me ask the question a different way then; which route should I implement in my pr? :p Ha, sorry for not being clearer. What I wanted to say is that I don't have a good answer for you. In a perfect world (ie if you are up to the challenge :D) I would suggest adding a decode function to the hashers that basically does the reverse of encode. safe_summary could then use the decoded values and mask them as needed. Adding a decode function seems to make sense since Argon2PasswordHasher already has a _decode and others manually repeat (the simpler logic) ala algorithm, empty, algostr, rounds, data = encoded.split('$', 4) over multiple functions. This new decode functionality could be in a new PR and your current PR would be blocked by it and the use that. Interested to hear your and Mariusz' thoughts\nReplying to Florian Apolloner: Ha, sorry for not being clearer. What I wanted to say is that I don't have a good answer for you. In a perfect world (ie if you are up to the challenge :D) I would suggest adding a decode function to the hashers that basically does the reverse of encode. safe_summary could then use the decoded values and mask them as needed. Adding a decode function seems to make sense since Argon2PasswordHasher already has a _decode and others manually repeat (the simpler logic) ala algorithm, empty, algostr, rounds, data = encoded.split('$', 4) over multiple functions. I'm not opposed to implementing a decode function, but I'm not sure I understand how it would differ from the safe_summary function. Further if decode functionality is require/desired then is the scope of concern just for the hashers shipped with django or do we need to consider third party hashers? I have a preference for not considering them and creating a clear breaking change (but I'm also lazy :p). On a potential decode function; This comment on the encode function worries me a bit The result is normally formatted as \"algorithm$salt$hash\" and must be fewer than 128 characters. It makes me think that the encoded result could be truncated and if we consider third party hashers then we must consider truncated DB entries. I'm not sure if this is a real issue or not, but the 128 character limit does raise an eye brow to me. This new decode functionality could be in a new PR and your current PR would be blocked by it and the use that. Interested to hear your and Mariusz' thoughts Sounds reasonable, but what does the decode function look like? It it a stub in the BasePasswordHasher which requires that derived classes implement it with an implementation for each of the included hashers? Let me know if that sounds good and I can make a second PR to implement that. Else lets keep this conversation going :) Edit: For clarity my mind's eye see's the decode function as def decode(self) -> Dict[str, str] Where the key is in the set {\"algo\", \"salt\", \"hash\"} and the values are the string encoded versions (base64 for hash?).\nHey, just wanted to drop by and check up on this.\nHi, sorry for the late reply but I am swamped with work recently and lost track of this. I'll try to answer the questions as good as possible. I'm not opposed to implementing a decode function, but I'm not sure I understand how it would differ from the safe_summary function. The intention is simple, safe_summary is ment for display, ie it calls mask_hash and similar functions which make it look like a5bcd********** (literally). A custom password hasher might even go as far as actually truncating the hash that is shown, so the data you get back from safe_summary as of now would not contain the actual decoded data. But due to backwards concerns we cannot change that function. clear breaking change Yes, they will have to add this new function unless we can come up with a better idea (ie if decode is not implemented the default salt size will not increase but start raising warnings) It makes me think that the encoded result could be truncated and if we consider third party hashers then we must consider truncated DB entries. I'm not sure if this is a real issue or not, but the 128 character limit does raise an eye brow to me. The 128 character limit comes from the size of the database column in the db, if needed we could increase that. That said the database should not have truncated entries because any non-broken database will throw an error if you insert >128 characters into a 128 char field. Sounds reasonable, but what does the decode function look like? A stub (or probably not implemented at all in the base hasher for the transition period) which returns dict[str, any]. Ie the iteration count would be an integer. Good question regarding bytes vs base64, but I think it should be okay if we return the base64 values here instead of going back to the raw bytes.\nNo worries on the late reply. I know the world is a bit hectic right now :) I've gone ahead and made a PR which adds an empty decode function to the base password hasher as well as a simple implementation to the pbkdf2 hasher. ​https://github.com/django/django/pull/12675 I think it's probably better to require the decode function rather than having to deal with if it exists or not and update salt lengths only if the function does exist. I feel that having this be optional will only lead to more headaches down the line. Let me know how you feel about this and I can update the PR to include similar decode()s for the other hashers included.\nReplying to Jon Moroney: I think it's probably better to require the decode function rather than having to deal with if it exists or not and update salt lengths only if the function does exist. I feel that having this be optional will only lead to more headaches down the line. I am not sure it is that hard, it would also help with backwards compat. Ie have a default decode method in BaseHasher which return an empty dict and then: When it is time to check the salt length (ie in must_update), call decode and if there is no salt in it raise a PendingDeprecationWarning (and then DeprecationWarning followed by an error in subsequent Django versions [ie change the method to NotImplemented]). We can immediately update builtin hashers with a new decode method that gets used as needed (safe_summary and whereever decoding is needed). This should also allow me to finally easily upgrade Argon hashing to the \"new\" variant. This way 3rd party authors get the old salt for a while being able to update as needed. This is probably necessary since we do not can argue the salt change important enough to throw all backwards concerns over board. Let me know how you feel about this and I can update the PR to include similar decode()s for the other hashers included. Generally good, but I do not think that a decode as used here should have translations for dictionary keys, that is solely for use in safe_summary imo. Edit:// Afaik we do not use typing in Django yet, so the function shouldn't have type annotations.\nJust pushed an update for the points you've mentioned. One bit that jumps out at me is that I'm changing the behavior of must_update by raising an exception def must_update(self, encoded): decoded = self.decode() if 'salt' not in decoded: raise PendingDeprecationWarning('Decode not fully implemented. Decode will be required in future releases.') return False Also out of curiosity. Why no typing?\nReplying to Jon Moroney: Just pushed an update for the points you've mentioned. Great, will look at it this week. One bit that jumps out at me is that I'm changing the behavior of must_update by raising an exception Don't raise it but use warnings.warn in conjunction with RemovedInDjango40Warning (see the existing deprecation warnings in Django). Also out of curiosity. Why no typing? Because we don't have any yet. As for why that is the case please look into the existing mailing list threads :)\nI've looked at the updates in your PR, and yes that is pretty much what I had in mind.\nUpdated again to change the raise to a usage of the warning function and to add decode to the remaining hashers. Because we don't have any yet. As for why that is the case please look into the existing mailing list threads :) That's beyond the scope of what I'm trying to get done :p It would be nice to see you guys adopt typing at some point though :) Edit: No idea what's up with the doc test failing.\nThe doc test failing was temporary, unlinked to your patch and should now be solved.\nUpdated again to change the raise to a usage of the warning function and to add decode to the remaining hashers. Ok, next step would be to use those new decode methods in the existing cases where manual decoding happens (to reduce the duplication added by this method). Then the next step would be to look into where and how we can implement the update of the salt. Preferably without adding it to the must_update individually. We could add a salt_length attribute and then adjust based on that (which could be None for the unsalted variants).\nOk, next step would be to use those new decode methods in the existing cases where manual decoding happens (to reduce the duplication added by this method). I've updated the PR with what I think you mean. Let me know if that's what you're thinking and I'll do the rest, else let me know what I misunderstood :) Then the next step would be to look into where and how we can implement the update of the salt. Preferably without adding it to the must_update individually. We could add a salt_length attribute and then adjust based on that (which could be None for the unsalted variants). I think this can be handled in the BasePasswordHasher unless a hasher implements its own must_update logic and in that case it must be on a case by case basis. As for the salt length do you propose adding a salt_length field to the return from decode? I think it may just be easier to use len(salt) and handle the case where salt is None.\nI've updated the PR with what I think you mean. Let me know if that's what you're thinking and I'll do the rest, else let me know what I misunderstood :) Yes that is what I ment. I think this can be handled in the BasePasswordHasher unless a hasher implements its own must_update logic and in that case it must be on a case by case basis. Well the must_update methods in the hashers could call the base method were appropriate. Ie instead of returning False when the hash thinks it doesn't need an update it can call super().must_update I think it may just be easier to use len(salt) and handle the case where salt is None. Yes\nWell the must_update methods in the hashers could call the base method were appropriate. Ie instead of returning False when the hash thinks it doesn't need an update it can call super().must_update In essence that makes for a two stage check I think. Should it just be convention for a hasher to return super().must_update rather than ever returning false? After a bit of a struggle with the bcrypt hasher I've squashed the PR down. It looks like bcrypt is using more than just the salt stored data as a salt in hash verification. I've added a bit more logic to handle matching what was used, but if you wouldn't mind giving it a second look that would be helpful :) I've left the relevant changes in the most recent commit on the PR.\nChecking in again just to make sure this doesn't get lost.\nAny updates?\nHi Jon. There are more than 200 open PRs. We'll get to this, but I'm afraid you need to be patient. Constant pings just add noise. A quick look at the PR suggests going over the ​Patch review checklist would save time later. Please uncheck Patch needs improvement when that's done. Thanks for your input!\nSorry about the noise. I took a look through the checklist and it seems good.\nSorry to bug again, but it's been nearly 2 months since I last had any feedback on this ticket. I'd like to get this through and I believe that the first of the two PRs ​https://github.com/django/django/pull/12675 is ready to go. If you guys disagree I'm happy to change anything, but I need feedback for that.\nGiven that ​https://github.com/django/django/pull/12675 is nearing completion (I expect it to get merged soon), it is time to think about this again. I had time to refresh my memory on how the salts work for the algos in question. I think it would be a good idea to define the salt_length in actual terms of entropy and not the length of the resulting string. To that extend I think the default salt function should change to something along the lines of: salt_len = 71 # information entropy in bits def salt(self): \"\"\"Generate a cryptographically secure nonce salt in ASCII.\"\"\" char_count = math.ceil(math.log10(math.pow(2, self.salt_len)) / math.log10(62)) return get_random_string(char_count) At this point I'd probably change the encode() function to accept an empty salt and let the hashers generate the salt themselves if needed (argon2 for instance could do well like this and passing a salt to bcrypt makes no sense either). This way we would also get rid of the weirdness of bytes vs ASCII in the salt string and could pass the output of os.urandom(some_length) to the algorithms directly -- although that will probably be not as easy since we do have to be able to translate the existing salt strings *scratches head*.\nI agree with the idea of having the salt function view the salt_len in terms of bits of entropy, but I'm unclear on the encoding idea. Aren't the password entries stored as long strings and wouldn't that force any bytes to be coerced back into ascii least we break decoding of entries on retrieval?\nThe problem is that bytes don't map to ASCII (if we are talking about the output of os.urandom(some_length) at least), so we need to define some \"encoding\" -- base64 is probably something that would make sense but not really compatible with what we have now :/\nAhh sorry. I read this At this point I'd probably change the encode() function to... as this At this point I'd probably change the salt() function to... That's what I get for not having my coffee before getting to work :( Replying to Florian Apolloner: base64 is probably something that would make sense but not really compatible with what we have now :/ Certainly something for the future :) So, the easy next step is to change salt to work in terms of bits rather than in terms of number of characters which returns a string of some length. On the encoding function. How much flexibility is there in terms of hash storage? Can a given hasher define a binary encoding for instance?\nIn 136ec9b6: Refs #31358 -- Added decode() to password hashers. By convention a hasher which does not use a salt should populate the decode dict with None rather than omit the dict key. Co-Authored-By: Florian Apolloner <apollo13@…>\nI've made a new PR to convert the salt function to work in bits rather than in character length. I've also set the entropy value to 128 bits. ​https://github.com/django/django/pull/13107 Edit: As per PR comments the above PR has been scrapped with the work from it moved to ​https://github.com/django/django/pull/12553\nTo circle back on this and to document the state of things for future readers. The current PR here ​https://github.com/django/django/pull/12553 Changes the measure of salt from characters to bits and from ~71 bits to 128 bits. The PR is ready but is hinging on the question of updating prior database entries which have a smaller salt than the 128bit value.\nUpdated flags based on PR comment ​https://github.com/django/django/pull/12553#pullrequestreview-520869817\nIs there any desire to move this issue forward?\nIn 1b7086b: Refs #31358 -- Simplified Argon2PasswordHasher.must_update() by using decode().\nIn c76d51b3: Refs #31358 -- Fixed decoding salt in Argon2PasswordHasher. Argon2 encodes the salt as base64 for representation in the final hash output. To be able to accurately return the used salt from decode(), add padding, b64decode, and decode from latin1 (for the remote possibility that someone supplied a custom hash consisting solely of bytes -- this would require a manual construction of the hash though, Django's interface does not allow for that).\nIn 64cc9dc: Refs #31358 -- Added constant for get_random_string()'s default alphabet.",
  "created_at": "2020-03-10T21:55:27Z",
  "version": "3.2",
  "FAIL_TO_PASS": "[\"test_view_user_password_is_readonly (auth_tests.test_views.ChangelistTests)\", \"test_argon2 (auth_tests.test_hashers.TestUtilsHashPassArgon2)\", \"test_md5 (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_pbkdf2 (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_sha1 (auth_tests.test_hashers.TestUtilsHashPass)\"]",
  "PASS_TO_PASS": "[\"test_attributes (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_decode (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_encode (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_harden_runtime (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_load_library_importerror (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_load_library_no_algorithm (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_must_update (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_safe_summary (auth_tests.test_hashers.BasePasswordHasherTests)\", \"test_verify (auth_tests.test_hashers.BasePasswordHasherTests)\", \"Named URLs should be reversible\", \"test_redirect_to_login_with_lazy (auth_tests.test_views.RedirectToLoginTests)\", \"test_redirect_to_login_with_lazy_and_unicode (auth_tests.test_views.RedirectToLoginTests)\", \"test_default_logout_then_login (auth_tests.test_views.LogoutThenLoginTests)\", \"test_logout_then_login_with_custom_login (auth_tests.test_views.LogoutThenLoginTests)\", \"test_https_login_url (auth_tests.test_views.LoginURLSettings)\", \"test_lazy_login_url (auth_tests.test_views.LoginURLSettings)\", \"test_login_url_with_querystring (auth_tests.test_views.LoginURLSettings)\", \"test_named_login_url (auth_tests.test_views.LoginURLSettings)\", \"test_remote_login_url (auth_tests.test_views.LoginURLSettings)\", \"test_remote_login_url_with_next_querystring (auth_tests.test_views.LoginURLSettings)\", \"test_standard_login_url (auth_tests.test_views.LoginURLSettings)\", \"test_custom (auth_tests.test_views.LoginRedirectUrlTest)\", \"test_default (auth_tests.test_views.LoginRedirectUrlTest)\", \"test_named (auth_tests.test_views.LoginRedirectUrlTest)\", \"test_remote (auth_tests.test_views.LoginRedirectUrlTest)\", \"test_success_url_allowed_hosts_safe_host (auth_tests.test_views.LoginSuccessURLAllowedHostsTest)\", \"test_success_url_allowed_hosts_same_host (auth_tests.test_views.LoginSuccessURLAllowedHostsTest)\", \"test_success_url_allowed_hosts_unsafe_host (auth_tests.test_views.LoginSuccessURLAllowedHostsTest)\", \"test_confirm_valid_custom_user (auth_tests.test_views.CustomUserPasswordResetTest)\", \"A uidb64 that decodes to a non-UUID doesn't crash.\", \"test_confirm_valid_custom_user (auth_tests.test_views.UUIDUserPasswordResetTest)\", \"test_password_change_done_fails (auth_tests.test_views.ChangePasswordTest)\", \"test_password_change_done_succeeds (auth_tests.test_views.ChangePasswordTest)\", \"test_password_change_fails_with_invalid_old_password (auth_tests.test_views.ChangePasswordTest)\", \"test_password_change_fails_with_mismatched_passwords (auth_tests.test_views.ChangePasswordTest)\", \"test_password_change_redirect_custom (auth_tests.test_views.ChangePasswordTest)\", \"test_password_change_redirect_custom_named (auth_tests.test_views.ChangePasswordTest)\", \"test_password_change_redirect_default (auth_tests.test_views.ChangePasswordTest)\", \"test_password_change_succeeds (auth_tests.test_views.ChangePasswordTest)\", \"test_current_site_in_context_after_login (auth_tests.test_views.LoginTest)\", \"test_legacy_session_key_flushed_on_login (auth_tests.test_views.LoginTest)\", \"test_login_csrf_rotate (auth_tests.test_views.LoginTest)\", \"test_login_form_contains_request (auth_tests.test_views.LoginTest)\", \"test_login_session_without_hash_session_key (auth_tests.test_views.LoginTest)\", \"test_security_check (auth_tests.test_views.LoginTest)\", \"test_security_check_https (auth_tests.test_views.LoginTest)\", \"test_session_key_flushed_on_login (auth_tests.test_views.LoginTest)\", \"test_session_key_flushed_on_login_after_password_change (auth_tests.test_views.LoginTest)\", \"test_user_password_change_updates_session (auth_tests.test_views.SessionAuthenticationTests)\", \"test_confirm_complete (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_custom_reset_url_token (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_custom_reset_url_token_link_redirects_to_set_password_page (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_different_passwords (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_display_user_from_form (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_invalid (auth_tests.test_views.PasswordResetTest)\", \"A POST with an invalid token is rejected.\", \"test_confirm_invalid_post (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_invalid_user (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_link_redirects_to_set_password_page (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_login_post_reset (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_login_post_reset_already_logged_in (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_login_post_reset_custom_backend (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_overflow_user (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_redirect_custom (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_redirect_custom_named (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_redirect_default (auth_tests.test_views.PasswordResetTest)\", \"test_confirm_valid (auth_tests.test_views.PasswordResetTest)\", \"Email is sent if a valid email address is provided for password reset\", \"Email is sent if a valid email address is provided for password reset when a custom from_email is provided.\", \"If the provided email is not registered, don't raise any error but\", \"test_extra_email_context (auth_tests.test_views.PasswordResetTest)\", \"test_html_mail_template (auth_tests.test_views.PasswordResetTest)\", \"test_invalid_link_if_going_directly_to_the_final_reset_password_url (auth_tests.test_views.PasswordResetTest)\", \"Poisoned HTTP_HOST headers can't be used for reset emails\", \"Poisoned HTTP_HOST headers can't be used for reset emails on admin views\", \"test_reset_custom_redirect (auth_tests.test_views.PasswordResetTest)\", \"test_reset_custom_redirect_named (auth_tests.test_views.PasswordResetTest)\", \"test_reset_redirect_default (auth_tests.test_views.PasswordResetTest)\", \"Stay on the login page by default.\", \"If not logged in, stay on the same page.\", \"test_permission_required_logged_in (auth_tests.test_views.LoginRedirectAuthenticatedUser)\", \"test_permission_required_not_logged_in (auth_tests.test_views.LoginRedirectAuthenticatedUser)\", \"If logged in, go to default redirected URL.\", \"test_redirect_loop (auth_tests.test_views.LoginRedirectAuthenticatedUser)\", \"If next is specified as a GET parameter, go there.\", \"If logged in, go to custom redirected URL.\", \"test_14377 (auth_tests.test_views.LogoutTest)\", \"Logout without next_page option renders the default template\", \"test_logout_doesnt_cache (auth_tests.test_views.LogoutTest)\", \"Language is preserved after logout.\", \"test_logout_redirect_url_named_setting (auth_tests.test_views.LogoutTest)\", \"test_logout_redirect_url_setting (auth_tests.test_views.LogoutTest)\", \"Logout with custom query string redirects to specified resource\", \"Logout resolves names or URLs passed as next_page.\", \"Logout with next_page option given redirects to specified resource\", \"test_logout_with_overridden_redirect_url (auth_tests.test_views.LogoutTest)\", \"test_logout_with_post (auth_tests.test_views.LogoutTest)\", \"Logout with query string redirects to specified resource\", \"test_security_check (auth_tests.test_views.LogoutTest)\", \"test_security_check_https (auth_tests.test_views.LogoutTest)\", \"test_success_url_allowed_hosts_safe_host (auth_tests.test_views.LogoutTest)\", \"test_success_url_allowed_hosts_same_host (auth_tests.test_views.LogoutTest)\", \"test_success_url_allowed_hosts_unsafe_host (auth_tests.test_views.LogoutTest)\", \"test_admin_password_change (auth_tests.test_views.UUIDUserTests)\", \"test_changelist_disallows_password_lookups (auth_tests.test_views.ChangelistTests)\", \"test_password_change_bad_url (auth_tests.test_views.ChangelistTests)\", \"test_user_change_different_user_password (auth_tests.test_views.ChangelistTests)\", \"test_user_change_email (auth_tests.test_views.ChangelistTests)\", \"test_user_change_password (auth_tests.test_views.ChangelistTests)\", \"test_user_change_password_passes_user_to_has_change_permission (auth_tests.test_views.ChangelistTests)\", \"test_user_not_change (auth_tests.test_views.ChangelistTests)\", \"test_argon2_decode (auth_tests.test_hashers.TestUtilsHashPassArgon2)\", \"test_argon2_upgrade (auth_tests.test_hashers.TestUtilsHashPassArgon2)\", \"test_argon2_version_upgrade (auth_tests.test_hashers.TestUtilsHashPassArgon2)\", \"test_bad_algorithm (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_bcrypt (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_bcrypt_harden_runtime (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_bcrypt_salt_check (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_bcrypt_sha256 (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_bcrypt_upgrade (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_bcryptsha256_salt_check (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_bytes (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_check_password_calls_harden_runtime (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_crypt (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_invalid_password (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_is_password_usable (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_low_level_pbkdf2 (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_low_level_pbkdf2_sha1 (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_no_upgrade (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_no_upgrade_on_incorrect_pass (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_pbkdf2_harden_runtime (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_pbkdf2_upgrade (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_pbkdf2_upgrade_new_hasher (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_simple (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_unsalted_md5 (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_unsalted_sha1 (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_unspecified_password (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_unusable (auth_tests.test_hashers.TestUtilsHashPass)\", \"test_upgrade (auth_tests.test_hashers.TestUtilsHashPass)\"]",
  "environment_setup_commit": "65dfb06a1ab56c238cc80f5e1c31f61210c4577d",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.630170",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}