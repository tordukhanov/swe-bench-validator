{
  "repo": "pytest-dev/pytest",
  "instance_id": "pytest-dev__pytest-8124",
  "base_commit": "902739cfc3bbc3379e6ef99c8e250de35f52ecde",
  "patch": "diff --git a/src/_pytest/hookspec.py b/src/_pytest/hookspec.py\n--- a/src/_pytest/hookspec.py\n+++ b/src/_pytest/hookspec.py\n@@ -808,6 +808,27 @@ def pytest_warning_recorded(\n     \"\"\"\n \n \n+# -------------------------------------------------------------------------\n+# Hooks for influencing skipping\n+# -------------------------------------------------------------------------\n+\n+\n+def pytest_markeval_namespace(config: \"Config\") -> Dict[str, Any]:\n+    \"\"\"Called when constructing the globals dictionary used for\n+    evaluating string conditions in xfail/skipif markers.\n+\n+    This is useful when the condition for a marker requires\n+    objects that are expensive or impossible to obtain during\n+    collection time, which is required by normal boolean\n+    conditions.\n+\n+    .. versionadded:: 6.2\n+\n+    :param _pytest.config.Config config: The pytest config object.\n+    :returns: A dictionary of additional globals to add.\n+    \"\"\"\n+\n+\n # -------------------------------------------------------------------------\n # error handling and internal debugging hooks\n # -------------------------------------------------------------------------\ndiff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -3,6 +3,7 @@\n import platform\n import sys\n import traceback\n+from collections.abc import Mapping\n from typing import Generator\n from typing import Optional\n from typing import Tuple\n@@ -98,6 +99,16 @@ def evaluate_condition(item: Item, mark: Mark, condition: object) -> Tuple[bool,\n             \"platform\": platform,\n             \"config\": item.config,\n         }\n+        for dictionary in reversed(\n+            item.ihook.pytest_markeval_namespace(config=item.config)\n+        ):\n+            if not isinstance(dictionary, Mapping):\n+                raise ValueError(\n+                    \"pytest_markeval_namespace() needs to return a dict, got {!r}\".format(\n+                        dictionary\n+                    )\n+                )\n+            globals_.update(dictionary)\n         if hasattr(item, \"obj\"):\n             globals_.update(item.obj.__globals__)  # type: ignore[attr-defined]\n         try:\n",
  "test_patch": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -1,4 +1,5 @@\n import sys\n+import textwrap\n \n import pytest\n from _pytest.pytester import Pytester\n@@ -155,6 +156,136 @@ def test_func(self):\n         assert skipped\n         assert skipped.reason == \"condition: config._hackxyz\"\n \n+    def test_skipif_markeval_namespace(self, pytester: Pytester) -> None:\n+        pytester.makeconftest(\n+            \"\"\"\n+            import pytest\n+\n+            def pytest_markeval_namespace():\n+                return {\"color\": \"green\"}\n+            \"\"\"\n+        )\n+        p = pytester.makepyfile(\n+            \"\"\"\n+            import pytest\n+\n+            @pytest.mark.skipif(\"color == 'green'\")\n+            def test_1():\n+                assert True\n+\n+            @pytest.mark.skipif(\"color == 'red'\")\n+            def test_2():\n+                assert True\n+        \"\"\"\n+        )\n+        res = pytester.runpytest(p)\n+        assert res.ret == 0\n+        res.stdout.fnmatch_lines([\"*1 skipped*\"])\n+        res.stdout.fnmatch_lines([\"*1 passed*\"])\n+\n+    def test_skipif_markeval_namespace_multiple(self, pytester: Pytester) -> None:\n+        \"\"\"Keys defined by ``pytest_markeval_namespace()`` in nested plugins override top-level ones.\"\"\"\n+        root = pytester.mkdir(\"root\")\n+        root.joinpath(\"__init__.py\").touch()\n+        root.joinpath(\"conftest.py\").write_text(\n+            textwrap.dedent(\n+                \"\"\"\\\n+            import pytest\n+\n+            def pytest_markeval_namespace():\n+                return {\"arg\": \"root\"}\n+            \"\"\"\n+            )\n+        )\n+        root.joinpath(\"test_root.py\").write_text(\n+            textwrap.dedent(\n+                \"\"\"\\\n+            import pytest\n+\n+            @pytest.mark.skipif(\"arg == 'root'\")\n+            def test_root():\n+                assert False\n+            \"\"\"\n+            )\n+        )\n+        foo = root.joinpath(\"foo\")\n+        foo.mkdir()\n+        foo.joinpath(\"__init__.py\").touch()\n+        foo.joinpath(\"conftest.py\").write_text(\n+            textwrap.dedent(\n+                \"\"\"\\\n+            import pytest\n+\n+            def pytest_markeval_namespace():\n+                return {\"arg\": \"foo\"}\n+            \"\"\"\n+            )\n+        )\n+        foo.joinpath(\"test_foo.py\").write_text(\n+            textwrap.dedent(\n+                \"\"\"\\\n+            import pytest\n+\n+            @pytest.mark.skipif(\"arg == 'foo'\")\n+            def test_foo():\n+                assert False\n+            \"\"\"\n+            )\n+        )\n+        bar = root.joinpath(\"bar\")\n+        bar.mkdir()\n+        bar.joinpath(\"__init__.py\").touch()\n+        bar.joinpath(\"conftest.py\").write_text(\n+            textwrap.dedent(\n+                \"\"\"\\\n+            import pytest\n+\n+            def pytest_markeval_namespace():\n+                return {\"arg\": \"bar\"}\n+            \"\"\"\n+            )\n+        )\n+        bar.joinpath(\"test_bar.py\").write_text(\n+            textwrap.dedent(\n+                \"\"\"\\\n+            import pytest\n+\n+            @pytest.mark.skipif(\"arg == 'bar'\")\n+            def test_bar():\n+                assert False\n+            \"\"\"\n+            )\n+        )\n+\n+        reprec = pytester.inline_run(\"-vs\", \"--capture=no\")\n+        reprec.assertoutcome(skipped=3)\n+\n+    def test_skipif_markeval_namespace_ValueError(self, pytester: Pytester) -> None:\n+        pytester.makeconftest(\n+            \"\"\"\n+            import pytest\n+\n+            def pytest_markeval_namespace():\n+                return True\n+            \"\"\"\n+        )\n+        p = pytester.makepyfile(\n+            \"\"\"\n+            import pytest\n+\n+            @pytest.mark.skipif(\"color == 'green'\")\n+            def test_1():\n+                assert True\n+        \"\"\"\n+        )\n+        res = pytester.runpytest(p)\n+        assert res.ret == 1\n+        res.stdout.fnmatch_lines(\n+            [\n+                \"*ValueError: pytest_markeval_namespace() needs to return a dict, got True*\"\n+            ]\n+        )\n+\n \n class TestXFail:\n     @pytest.mark.parametrize(\"strict\", [True, False])\n@@ -577,6 +708,33 @@ def test_foo():\n         result.stdout.fnmatch_lines([\"*1 failed*\" if strict else \"*1 xpassed*\"])\n         assert result.ret == (1 if strict else 0)\n \n+    def test_xfail_markeval_namespace(self, pytester: Pytester) -> None:\n+        pytester.makeconftest(\n+            \"\"\"\n+            import pytest\n+\n+            def pytest_markeval_namespace():\n+                return {\"color\": \"green\"}\n+            \"\"\"\n+        )\n+        p = pytester.makepyfile(\n+            \"\"\"\n+            import pytest\n+\n+            @pytest.mark.xfail(\"color == 'green'\")\n+            def test_1():\n+                assert False\n+\n+            @pytest.mark.xfail(\"color == 'red'\")\n+            def test_2():\n+                assert False\n+        \"\"\"\n+        )\n+        res = pytester.runpytest(p)\n+        assert res.ret == 1\n+        res.stdout.fnmatch_lines([\"*1 failed*\"])\n+        res.stdout.fnmatch_lines([\"*1 xfailed*\"])\n+\n \n class TestXFailwithSetupTeardown:\n     def test_failing_setup_issue9(self, pytester: Pytester) -> None:\n",
  "problem_statement": "Allow contibuting additional global variables for skipif/xfail\n- [ ] Include documentation when adding new features.\r\n- [x] Include new tests or update existing tests when applicable.\r\n- [X] Allow maintainers to push and squash when merging my commits. Please uncheck this if you prefer to squash the commits yourself.\r\n- [x] Create a new changelog file in the `changelog` folder, with a name like `<ISSUE NUMBER>.<TYPE>.rst`. See [changelog/README.rst](https://github.com/pytest-dev/pytest/blob/master/changelog/README.rst) for details.\r\n\n",
  "hints_text": "",
  "created_at": "2020-12-12T15:51:43Z",
  "version": "6.2",
  "FAIL_TO_PASS": "[\"testing/test_skipping.py::TestEvaluation::test_skipif_markeval_namespace\", \"testing/test_skipping.py::TestEvaluation::test_skipif_markeval_namespace_multiple\", \"testing/test_skipping.py::TestEvaluation::test_skipif_markeval_namespace_ValueError\", \"testing/test_skipping.py::TestXFail::test_xfail_markeval_namespace\"]",
  "PASS_TO_PASS": "[\"testing/test_skipping.py::test_importorskip\", \"testing/test_skipping.py::TestEvaluation::test_no_marker\", \"testing/test_skipping.py::TestEvaluation::test_marked_xfail_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_no_args\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_with_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice\", \"testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice2\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_boolean_without_reason\", \"testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_invalid_boolean\", \"testing/test_skipping.py::TestEvaluation::test_skipif_class\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_simple[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed\", \"testing/test_skipping.py::TestXFail::test_xfail_using_platform\", \"testing/test_skipping.py::TestXFail::test_xfail_xpassed_strict\", \"testing/test_skipping.py::TestXFail::test_xfail_run_anyway\", \"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input0-expected0]\", \"testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input1-expected1]\", \"testing/test_skipping.py::TestXFail::test_xfail_evalfalse_but_fails\", \"testing/test_skipping.py::TestXFail::test_xfail_not_report_default\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_xfail_reporting\", \"testing/test_skipping.py::TestXFail::test_xfail_not_run_no_setup_run\", \"testing/test_skipping.py::TestXFail::test_xfail_xpass\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative\", \"testing/test_skipping.py::TestXFail::test_xfail_imperative_in_setup_function\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_no_run\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_funcarg_setup\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_runtest_failed\", \"testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_runtest_passed_strict\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-TypeError-*1\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[(AttributeError,\", \"testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-IndexError-*1\", \"testing/test_skipping.py::TestXFail::test_strict_sanity\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[True]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_condition[False]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[True]\", \"testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[False]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true]\", \"testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false]\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9\", \"testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9\", \"testing/test_skipping.py::TestSkip::test_skip_class\", \"testing/test_skipping.py::TestSkip::test_skips_on_false_string\", \"testing/test_skipping.py::TestSkip::test_arg_as_reason\", \"testing/test_skipping.py::TestSkip::test_skip_no_reason\", \"testing/test_skipping.py::TestSkip::test_skip_with_reason\", \"testing/test_skipping.py::TestSkip::test_only_skips_marked_test\", \"testing/test_skipping.py::TestSkip::test_strict_and_skip\", \"testing/test_skipping.py::TestSkipif::test_skipif_conditional\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[\\\"hasattr(sys,\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting[True,\", \"testing/test_skipping.py::TestSkipif::test_skipif_using_platform\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped]\", \"testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed]\", \"testing/test_skipping.py::test_skip_not_report_default\", \"testing/test_skipping.py::test_skipif_class\", \"testing/test_skipping.py::test_skipped_reasons_functional\", \"testing/test_skipping.py::test_skipped_folding\", \"testing/test_skipping.py::test_reportchars\", \"testing/test_skipping.py::test_reportchars_error\", \"testing/test_skipping.py::test_reportchars_all\", \"testing/test_skipping.py::test_reportchars_all_error\", \"testing/test_skipping.py::test_errors_in_xfail_skip_expressions\", \"testing/test_skipping.py::test_xfail_skipif_with_globals\", \"testing/test_skipping.py::test_default_markers\", \"testing/test_skipping.py::test_xfail_test_setup_exception\", \"testing/test_skipping.py::test_imperativeskip_on_xfail_test\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif\", \"testing/test_skipping.py::TestBooleanCondition::test_skipif_noreason\", \"testing/test_skipping.py::TestBooleanCondition::test_xfail\", \"testing/test_skipping.py::test_xfail_item\", \"testing/test_skipping.py::test_module_level_skip_error\", \"testing/test_skipping.py::test_module_level_skip_with_allow_module_level\", \"testing/test_skipping.py::test_invalid_skip_keyword_parameter\", \"testing/test_skipping.py::test_mark_xfail_item\", \"testing/test_skipping.py::test_summary_list_after_errors\", \"testing/test_skipping.py::test_relpath_rootdir\"]",
  "environment_setup_commit": "902739cfc3bbc3379e6ef99c8e250de35f52ecde",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.941539",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}