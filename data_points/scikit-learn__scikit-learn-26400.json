{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-26400",
  "base_commit": "1e8a5b833d1b58f3ab84099c4582239af854b23a",
  "patch": "diff --git a/sklearn/preprocessing/_data.py b/sklearn/preprocessing/_data.py\n--- a/sklearn/preprocessing/_data.py\n+++ b/sklearn/preprocessing/_data.py\n@@ -3311,9 +3311,13 @@ def _box_cox_optimize(self, x):\n \n         We here use scipy builtins which uses the brent optimizer.\n         \"\"\"\n+        mask = np.isnan(x)\n+        if np.all(mask):\n+            raise ValueError(\"Column must not be all nan.\")\n+\n         # the computation of lambda is influenced by NaNs so we need to\n         # get rid of them\n-        _, lmbda = stats.boxcox(x[~np.isnan(x)], lmbda=None)\n+        _, lmbda = stats.boxcox(x[~mask], lmbda=None)\n \n         return lmbda\n \n",
  "test_patch": "diff --git a/sklearn/preprocessing/tests/test_data.py b/sklearn/preprocessing/tests/test_data.py\n--- a/sklearn/preprocessing/tests/test_data.py\n+++ b/sklearn/preprocessing/tests/test_data.py\n@@ -2527,6 +2527,21 @@ def test_power_transformer_copy_False(method, standardize):\n     assert X_trans is X_inv_trans\n \n \n+def test_power_transformer_box_cox_raise_all_nans_col():\n+    \"\"\"Check that box-cox raises informative when a column contains all nans.\n+\n+    Non-regression test for gh-26303\n+    \"\"\"\n+    X = rng.random_sample((4, 5))\n+    X[:, 0] = np.nan\n+\n+    err_msg = \"Column must not be all nan.\"\n+\n+    pt = PowerTransformer(method=\"box-cox\")\n+    with pytest.raises(ValueError, match=err_msg):\n+        pt.fit_transform(X)\n+\n+\n @pytest.mark.parametrize(\n     \"X_2\",\n     [\n",
  "problem_statement": "PowerTransformer fails with unhelpful stack trace with all-nan feature and method='box-cox'\n### Describe the bug\r\n\r\n`PowerTransformer(\"box-cox\").fit(x)` throws a difficult-to-debug error if x contains an all-nan column. \r\n\r\n### Steps/Code to Reproduce\r\n\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\r\n\r\nx = np.ones((20, 5))\r\ny = np.ones((20, 1))\r\n\r\nx[:, 0] = np.nan\r\n\r\nPowerTransformer().fit_transform(x)  # preserves all-nan column\r\nPowerTransformer('box-cox').fit_transform(x)  # Throws an error when calling stats.boxcox\r\n```\r\n\r\n### Expected Results\r\n\r\nEither no error is thrown and the all-nan column is preserved, or a descriptive error is thrown indicating that there is an unfittable column \r\n\r\n### Actual Results\r\n\r\n```\r\nValueError                                Traceback (most recent call last)\r\n\r\n[<ipython-input-12-563273596add>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 PowerTransformer('box-cox').fit_transform(x)\r\n\r\n4 frames\r\n\r\n[/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py](https://localhost:8080/#) in wrapped(self, X, *args, **kwargs)\r\n    138     @wraps(f)\r\n    139     def wrapped(self, X, *args, **kwargs):\r\n--> 140         data_to_wrap = f(self, X, *args, **kwargs)\r\n    141         if isinstance(data_to_wrap, tuple):\r\n    142             # only wrap the first output for cross decomposition\r\n\r\n[/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py](https://localhost:8080/#) in fit_transform(self, X, y)\r\n   3101         \"\"\"\r\n   3102         self._validate_params()\r\n-> 3103         return self._fit(X, y, force_transform=True)\r\n   3104 \r\n   3105     def _fit(self, X, y=None, force_transform=False):\r\n\r\n[/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py](https://localhost:8080/#) in _fit(self, X, y, force_transform)\r\n   3114         }[self.method]\r\n   3115         with np.errstate(invalid=\"ignore\"):  # hide NaN warnings\r\n-> 3116             self.lambdas_ = np.array([optim_function(col) for col in X.T])\r\n   3117 \r\n   3118         if self.standardize or force_transform:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py](https://localhost:8080/#) in <listcomp>(.0)\r\n   3114         }[self.method]\r\n   3115         with np.errstate(invalid=\"ignore\"):  # hide NaN warnings\r\n-> 3116             self.lambdas_ = np.array([optim_function(col) for col in X.T])\r\n   3117 \r\n   3118         if self.standardize or force_transform:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py](https://localhost:8080/#) in _box_cox_optimize(self, x)\r\n   3272         # the computation of lambda is influenced by NaNs so we need to\r\n   3273         # get rid of them\r\n-> 3274         _, lmbda = stats.boxcox(x[~np.isnan(x)], lmbda=None)\r\n   3275 \r\n   3276         return lmbda\r\n\r\nValueError: not enough values to unpack (expected 2, got 0)\r\n```\r\n\r\n### Versions\r\n\r\n```shell\r\nSystem:\r\n    python: 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\r\nexecutable: /usr/bin/python3\r\n   machine: Linux-5.10.147+-x86_64-with-glibc2.31\r\n\r\nPython dependencies:\r\n      sklearn: 1.2.2\r\n          pip: 23.0.1\r\n   setuptools: 67.7.2\r\n        numpy: 1.22.4\r\n        scipy: 1.10.1\r\n       Cython: 0.29.34\r\n       pandas: 1.5.3\r\n   matplotlib: 3.7.1\r\n       joblib: 1.2.0\r\nthreadpoolctl: 3.1.0\r\n```\r\n```\r\n\n",
  "hints_text": "Thank you for opening the issue. I agree this is a bug. It is reasonable to return all nans to be consistent with `yeo-johnson`.\nWould the following approach be neat enough?\r\n\r\n```python\r\ndef _box_cox_optimize(self, x):\r\n    # The computation of lambda is influenced by NaNs so we need to\r\n    # get rid of them\r\n    x = x[~np.isnan(x)]\r\n        \r\n    # if the whole column is nan, we do not care about lambda\r\n    if len(x) == 0:\r\n        return 0\r\n        \r\n    _, lmbda = stats.boxcox(x, lmbda=None)\r\n    return lmbda\r\n\r\n```\r\nIf this is okay, I can open a PR for this.\nOn second thought, `box-cox` does not work when the data is constant:\r\n\r\n```python\r\nfrom sklearn.preprocessing import PowerTransformer\r\n\r\nx = [[1], [1], [1], [1]]\r\n\r\npt = PowerTransformer(method=\"box-cox\")\r\npt.fit_transform(x)\r\n# ValueError: Data must not be constant.\r\n```\r\n\r\nA feature that is all `np.nan` can be considered constant. If we want to stay consistent, then we raise a similar error for all `np.nan`.\r\n\r\nWith that in mind, I'm in favor of raising an informative error.\n@thomasjpfan That's indeed reasonable. I have two proposed solutions:\r\n\r\n1. Let scipy raise the error, so that the message will be consistent with scipy:\r\n\r\n```python\r\ndef _box_cox_optimize(self, x):\r\n    if not np.all(np.isnan(x)):\r\n        x = x[~np.isnan(x)]\r\n\r\n    _, lmbda = stats.boxcox(x, lmbda=None)\r\n    return lmbda\r\n```\r\n\r\n2. Raise our own error, specifically claiming that column cannot be all nan (rather than cannot be constant):\r\n\r\n```python\r\ndef _box_cox_optimize(self, x):\r\n    if np.all(np.isnan(x)):\r\n        raise ValueError(\"Column must not be all nan.\")\r\n\r\n    _, lmbda = stats.boxcox(x[~np.isnan(x)], lmbda=None)\r\n    return lmbda\r\n```\r\n\r\nWhich one would you prefer, our do you have any other recommended solution? (I'm thinking that maybe my proposed solutions are not efficient enough.)\nSince there is no reply, I'm going to open a PR that takes the second approach. The reason is that the second approach is clearer IMO and the first approach seems to trigger some unexpected behavior.\nI like the second approach in https://github.com/scikit-learn/scikit-learn/issues/26303#issuecomment-1536899848, but store the `np.isnan(x)` as a variable so it is not computed twice.\nI see, thanks for the comment!",
  "created_at": "2023-05-19T00:35:48Z",
  "version": "1.3",
  "FAIL_TO_PASS": "[\"sklearn/preprocessing/tests/test_data.py::test_power_transformer_box_cox_raise_all_nans_col\"]",
  "PASS_TO_PASS": "[\"sklearn/preprocessing/tests/test_data.py::test_raises_value_error_if_sample_weights_greater_than_1d\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[array-Xw0-X0-sample_weight0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[array-Xw1-X1-sample_weight1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[array-Xw2-X2-sample_weight2]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[sparse_csr-Xw0-X0-sample_weight0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[sparse_csr-Xw1-X1-sample_weight1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[sparse_csr-Xw2-X2-sample_weight2]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[sparse_csc-Xw0-X0-sample_weight0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[sparse_csc-Xw1-X1-sample_weight1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sample_weight[sparse_csc-Xw2-X2-sample_weight2]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_dtype[False-None]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_dtype[True-None]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-asarray-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-asarray-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-asarray-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-asarray-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-asarray-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-asarray-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-asarray-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler0]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-1e-10-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-1e-10-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-1e-10-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-1-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-1-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-1-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-10000000000.0-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-10000000000.0-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float32-10000000000.0-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-1e-10-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-1e-10-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-1e-10-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-1-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-1-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-1-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-10000000000.0-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-10000000000.0-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[asarray-float64-10000000000.0-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-1e-10-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-1e-10-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-1e-10-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-1-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-1-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-1-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-10000000000.0-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-10000000000.0-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float32-10000000000.0-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-1e-10-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-1e-10-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-1e-10-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-1-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-1-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-1-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-10000000000.0-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-10000000000.0-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csc_matrix-float64-10000000000.0-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-1e-10-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-1e-10-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-1e-10-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-1-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-1-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-1-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-10000000000.0-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-10000000000.0-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float32-10000000000.0-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-1e-10-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-1e-10-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-1e-10-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-1-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-1-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-1-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-10000000000.0-10]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-10000000000.0-100]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_near_constant_features[csr_matrix-float64-10000000000.0-10000]\", \"sklearn/preprocessing/tests/test_data.py::test_scale_1d\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_numerical_stability\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_2d_arrays\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_float16_overflow\", \"sklearn/preprocessing/tests/test_data.py::test_handle_zeros_in_scale\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_partial_fit_numerical_stability\", \"sklearn/preprocessing/tests/test_data.py::test_partial_fit_sparse_input[True]\", \"sklearn/preprocessing/tests/test_data.py::test_partial_fit_sparse_input[None]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_trasform_with_partial_fit[True]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_trasform_with_partial_fit[None]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_check_array_of_inverse_transform\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_iris\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scale_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_without_centering[True]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_without_centering[None]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[asarray-True-True]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[asarray-True-False]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[asarray-False-True]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[asarray-False-False]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[csc_matrix-True-False]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[csc_matrix-False-False]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[csr_matrix-True-False]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_n_samples_seen_with_nan[csr_matrix-False-False]\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_return_identity\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_int\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_without_copy\", \"sklearn/preprocessing/tests/test_data.py::test_scale_sparse_with_mean_raise_exception\", \"sklearn/preprocessing/tests/test_data.py::test_scale_input_finiteness_validation\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_error_sparse\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_attributes[X0-True-True]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_attributes[X0-True-False]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_attributes[X0-False-True]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_attributes[X0-False-False]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_attributes[X1-True-False]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_attributes[X1-False-False]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_col_zero_sparse\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_2d_arrays\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[positive-0]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[positive-0.05]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[positive-0.1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[positive-0.5]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[positive-1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[negative-0]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[negative-0.05]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[negative-0.1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[negative-0.5]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[negative-1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[zeros-0]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[zeros-0.05]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[zeros-0.1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[zeros-0.5]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[zeros-1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[None-0]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[None-0.05]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[None-0.1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[None-0.5]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_equivalence_dense_sparse[None-1]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_transform_one_row_csr\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_iris\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_iris_quantiles\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_iris\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_check_error\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_sparse_ignore_zeros\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_dense_toy\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_subsampling\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_sparse_toy\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_bounds\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_and_inverse\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_nan\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transformer_sorted_quantiles[array]\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transformer_sorted_quantiles[sparse]\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_invalid_range\", \"sklearn/preprocessing/tests/test_data.py::test_scale_function_without_centering\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scale_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scale_1d_array\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_unit_variance\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_large_negative_value\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_transform_one_row_csr\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_l1\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_l2\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_max\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_max_sign\", \"sklearn/preprocessing/tests/test_data.py::test_normalize\", \"sklearn/preprocessing/tests/test_data.py::test_binarizer\", \"sklearn/preprocessing/tests/test_data.py::test_center_kernel\", \"sklearn/preprocessing/tests/test_data.py::test_kernelcenterer_non_linear_kernel\", \"sklearn/preprocessing/tests/test_data.py::test_cv_pipeline_precomputed\", \"sklearn/preprocessing/tests/test_data.py::test_fit_transform\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_coo\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_csc\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_csr\", \"sklearn/preprocessing/tests/test_data.py::test_fit_cold_start\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_notfitted[box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_notfitted[yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X0-True-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X0-True-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X0-False-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X0-False-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X1-True-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X1-True-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X1-False-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_inverse[X1-False-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_1d\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_2d\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_boxcox_strictly_positive_exception\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_yeojohnson_any_input[X0]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_yeojohnson_any_input[X1]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_yeojohnson_any_input[X2]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_shape_exception[box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_shape_exception[yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_lambda_zero\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_lambda_one\", \"sklearn/preprocessing/tests/test_data.py::test_optimization_power_transformer[box-cox-0.1]\", \"sklearn/preprocessing/tests/test_data.py::test_optimization_power_transformer[box-cox-0.5]\", \"sklearn/preprocessing/tests/test_data.py::test_optimization_power_transformer[yeo-johnson-0.1]\", \"sklearn/preprocessing/tests/test_data.py::test_optimization_power_transformer[yeo-johnson-0.5]\", \"sklearn/preprocessing/tests/test_data.py::test_optimization_power_transformer[yeo-johnson-1.0]\", \"sklearn/preprocessing/tests/test_data.py::test_yeo_johnson_darwin_example\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_nans[box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_nans[yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_fit_transform[True-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_fit_transform[True-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_fit_transform[False-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_fit_transform[False-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_True[True-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_True[True-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_True[False-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_True[False-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_False[True-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_False[True-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_False[False-box-cox]\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_copy_False[False-yeo-johnson]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sparse_partial_fit_finite_variance[X_20]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_sparse_partial_fit_finite_variance[X_21]\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scaler_clip[feature_range0]\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scaler_clip[feature_range1]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_raise_error_for_1d_input\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_significantly_non_gaussian\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features[MinMaxScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features[MaxAbsScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features[RobustScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features[StandardScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features[QuantileTransformer]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features[PowerTransformer]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[MinMaxScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[MaxAbsScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[RobustScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[StandardScaler]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[QuantileTransformer]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[PowerTransformer]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[Normalizer]\", \"sklearn/preprocessing/tests/test_data.py::test_one_to_one_features_pandas[Binarizer]\", \"sklearn/preprocessing/tests/test_data.py::test_kernel_centerer_feature_names_out\"]",
  "environment_setup_commit": "1e8a5b833d1b58f3ab84099c4582239af854b23a",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.025933",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}