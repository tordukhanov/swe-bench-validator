{
  "repo": "pytest-dev/pytest",
  "instance_id": "pytest-dev__pytest-7939",
  "base_commit": "65e6e39b76c236999fc53823892c26367a85a8f8",
  "patch": "diff --git a/src/_pytest/stepwise.py b/src/_pytest/stepwise.py\n--- a/src/_pytest/stepwise.py\n+++ b/src/_pytest/stepwise.py\n@@ -1,5 +1,6 @@\n from typing import List\n from typing import Optional\n+from typing import TYPE_CHECKING\n \n import pytest\n from _pytest import nodes\n@@ -8,6 +9,11 @@\n from _pytest.main import Session\n from _pytest.reports import TestReport\n \n+if TYPE_CHECKING:\n+    from _pytest.cacheprovider import Cache\n+\n+STEPWISE_CACHE_DIR = \"cache/stepwise\"\n+\n \n def pytest_addoption(parser: Parser) -> None:\n     group = parser.getgroup(\"general\")\n@@ -15,12 +21,15 @@ def pytest_addoption(parser: Parser) -> None:\n         \"--sw\",\n         \"--stepwise\",\n         action=\"store_true\",\n+        default=False,\n         dest=\"stepwise\",\n         help=\"exit on test failure and continue from last failing test next time\",\n     )\n     group.addoption(\n+        \"--sw-skip\",\n         \"--stepwise-skip\",\n         action=\"store_true\",\n+        default=False,\n         dest=\"stepwise_skip\",\n         help=\"ignore the first failing test but stop on the next failing test\",\n     )\n@@ -28,63 +37,56 @@ def pytest_addoption(parser: Parser) -> None:\n \n @pytest.hookimpl\n def pytest_configure(config: Config) -> None:\n-    config.pluginmanager.register(StepwisePlugin(config), \"stepwiseplugin\")\n+    # We should always have a cache as cache provider plugin uses tryfirst=True\n+    if config.getoption(\"stepwise\"):\n+        config.pluginmanager.register(StepwisePlugin(config), \"stepwiseplugin\")\n+\n+\n+def pytest_sessionfinish(session: Session) -> None:\n+    if not session.config.getoption(\"stepwise\"):\n+        assert session.config.cache is not None\n+        # Clear the list of failing tests if the plugin is not active.\n+        session.config.cache.set(STEPWISE_CACHE_DIR, [])\n \n \n class StepwisePlugin:\n     def __init__(self, config: Config) -> None:\n         self.config = config\n-        self.active = config.getvalue(\"stepwise\")\n         self.session: Optional[Session] = None\n         self.report_status = \"\"\n-\n-        if self.active:\n-            assert config.cache is not None\n-            self.lastfailed = config.cache.get(\"cache/stepwise\", None)\n-            self.skip = config.getvalue(\"stepwise_skip\")\n+        assert config.cache is not None\n+        self.cache: Cache = config.cache\n+        self.lastfailed: Optional[str] = self.cache.get(STEPWISE_CACHE_DIR, None)\n+        self.skip: bool = config.getoption(\"stepwise_skip\")\n \n     def pytest_sessionstart(self, session: Session) -> None:\n         self.session = session\n \n     def pytest_collection_modifyitems(\n-        self, session: Session, config: Config, items: List[nodes.Item]\n+        self, config: Config, items: List[nodes.Item]\n     ) -> None:\n-        if not self.active:\n-            return\n         if not self.lastfailed:\n             self.report_status = \"no previously failed tests, not skipping.\"\n             return\n \n-        already_passed = []\n-        found = False\n-\n-        # Make a list of all tests that have been run before the last failing one.\n-        for item in items:\n+        # check all item nodes until we find a match on last failed\n+        failed_index = None\n+        for index, item in enumerate(items):\n             if item.nodeid == self.lastfailed:\n-                found = True\n+                failed_index = index\n                 break\n-            else:\n-                already_passed.append(item)\n \n         # If the previously failed test was not found among the test items,\n         # do not skip any tests.\n-        if not found:\n+        if failed_index is None:\n             self.report_status = \"previously failed test not found, not skipping.\"\n-            already_passed = []\n         else:\n-            self.report_status = \"skipping {} already passed items.\".format(\n-                len(already_passed)\n-            )\n-\n-        for item in already_passed:\n-            items.remove(item)\n-\n-        config.hook.pytest_deselected(items=already_passed)\n+            self.report_status = f\"skipping {failed_index} already passed items.\"\n+            deselected = items[:failed_index]\n+            del items[:failed_index]\n+            config.hook.pytest_deselected(items=deselected)\n \n     def pytest_runtest_logreport(self, report: TestReport) -> None:\n-        if not self.active:\n-            return\n-\n         if report.failed:\n             if self.skip:\n                 # Remove test from the failed ones (if it exists) and unset the skip option\n@@ -109,14 +111,9 @@ def pytest_runtest_logreport(self, report: TestReport) -> None:\n                     self.lastfailed = None\n \n     def pytest_report_collectionfinish(self) -> Optional[str]:\n-        if self.active and self.config.getoption(\"verbose\") >= 0 and self.report_status:\n-            return \"stepwise: %s\" % self.report_status\n+        if self.config.getoption(\"verbose\") >= 0 and self.report_status:\n+            return f\"stepwise: {self.report_status}\"\n         return None\n \n-    def pytest_sessionfinish(self, session: Session) -> None:\n-        assert self.config.cache is not None\n-        if self.active:\n-            self.config.cache.set(\"cache/stepwise\", self.lastfailed)\n-        else:\n-            # Clear the list of failing tests if the plugin is not active.\n-            self.config.cache.set(\"cache/stepwise\", [])\n+    def pytest_sessionfinish(self) -> None:\n+        self.cache.set(STEPWISE_CACHE_DIR, self.lastfailed)\n",
  "test_patch": "diff --git a/testing/test_stepwise.py b/testing/test_stepwise.py\n--- a/testing/test_stepwise.py\n+++ b/testing/test_stepwise.py\n@@ -93,6 +93,23 @@ def test_run_without_stepwise(stepwise_testdir):\n     result.stdout.fnmatch_lines([\"*test_success_after_fail PASSED*\"])\n \n \n+def test_stepwise_output_summary(testdir):\n+    testdir.makepyfile(\n+        \"\"\"\n+        import pytest\n+        @pytest.mark.parametrize(\"expected\", [True, True, True, True, False])\n+        def test_data(expected):\n+            assert expected\n+        \"\"\"\n+    )\n+    result = testdir.runpytest(\"-v\", \"--stepwise\")\n+    result.stdout.fnmatch_lines([\"stepwise: no previously failed tests, not skipping.\"])\n+    result = testdir.runpytest(\"-v\", \"--stepwise\")\n+    result.stdout.fnmatch_lines(\n+        [\"stepwise: skipping 4 already passed items.\", \"*1 failed, 4 deselected*\"]\n+    )\n+\n+\n def test_fail_and_continue_with_stepwise(stepwise_testdir):\n     # Run the tests with a failing second test.\n     result = stepwise_testdir.runpytest(\n@@ -117,14 +134,10 @@ def test_fail_and_continue_with_stepwise(stepwise_testdir):\n     assert \"test_success_after_fail PASSED\" in stdout\n \n \n-def test_run_with_skip_option(stepwise_testdir):\n+@pytest.mark.parametrize(\"stepwise_skip\", [\"--stepwise-skip\", \"--sw-skip\"])\n+def test_run_with_skip_option(stepwise_testdir, stepwise_skip):\n     result = stepwise_testdir.runpytest(\n-        \"-v\",\n-        \"--strict-markers\",\n-        \"--stepwise\",\n-        \"--stepwise-skip\",\n-        \"--fail\",\n-        \"--fail-last\",\n+        \"-v\", \"--strict-markers\", \"--stepwise\", stepwise_skip, \"--fail\", \"--fail-last\",\n     )\n     assert _strip_resource_warnings(result.stderr.lines) == []\n \n",
  "problem_statement": "[Feature] Allow a --sw-skip shorthand cli arg like --sw itself permits\nThe stepwise plugin exposes a shorthand option for the stepwise itself, however it requires a longer arg only for skip, I think these should be consistent and should offer shorthand versions for both.\r\n\r\n```python\r\ndef pytest_addoption(parser: Parser) -> None:\r\n    group = parser.getgroup(\"general\")\r\n    group.addoption(\r\n        \"--sw\",\r\n        \"--stepwise\",\r\n        action=\"store_true\",\r\n        dest=\"stepwise\",\r\n        help=\"exit on test failure and continue from last failing test next time\",\r\n    )\r\n    group.addoption(\r\n        \"--stepwise-skip\",\r\n        action=\"store_true\",\r\n        dest=\"stepwise_skip\",\r\n        help=\"ignore the first failing test but stop on the next failing test\",\r\n    )\r\n```\r\n\r\nExpected:\r\n`pytest --sw-skip`\n",
  "hints_text": "",
  "created_at": "2020-10-25T11:04:34Z",
  "version": "6.2",
  "FAIL_TO_PASS": "[\"testing/test_stepwise.py::test_run_with_skip_option[--sw-skip]\"]",
  "PASS_TO_PASS": "[\"testing/test_stepwise.py::test_run_without_stepwise\", \"testing/test_stepwise.py::test_stepwise_output_summary\", \"testing/test_stepwise.py::test_fail_and_continue_with_stepwise\", \"testing/test_stepwise.py::test_run_with_skip_option[--stepwise-skip]\", \"testing/test_stepwise.py::test_fail_on_errors\", \"testing/test_stepwise.py::test_change_testfile\", \"testing/test_stepwise.py::test_stop_on_collection_errors[True]\", \"testing/test_stepwise.py::test_stop_on_collection_errors[False]\", \"testing/test_stepwise.py::test_xfail_handling\"]",
  "environment_setup_commit": "902739cfc3bbc3379e6ef99c8e250de35f52ecde",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.940059",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}