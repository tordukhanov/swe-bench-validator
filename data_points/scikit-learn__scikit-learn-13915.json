{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-13915",
  "base_commit": "b7b4d3e2f1a65bcb6d40431d3b61ed1d563c9dab",
  "patch": "diff --git a/sklearn/__init__.py b/sklearn/__init__.py\n--- a/sklearn/__init__.py\n+++ b/sklearn/__init__.py\n@@ -45,7 +45,7 @@\n # Dev branch marker is: 'X.Y.dev' or 'X.Y.devN' where N is an integer.\n # 'X.Y.dev0' is the canonical version of 'X.Y.dev'\n #\n-__version__ = '0.21.1'\n+__version__ = '0.21.2'\n \n \n # On OSX, we can get a runtime error due to multiple OpenMP libraries loaded\ndiff --git a/sklearn/cross_decomposition/pls_.py b/sklearn/cross_decomposition/pls_.py\n--- a/sklearn/cross_decomposition/pls_.py\n+++ b/sklearn/cross_decomposition/pls_.py\n@@ -285,6 +285,7 @@ def fit(self, X, Y):\n         self.n_iter_ = []\n \n         # NIPALS algo: outer loop, over components\n+        Y_eps = np.finfo(Yk.dtype).eps\n         for k in range(self.n_components):\n             if np.all(np.dot(Yk.T, Yk) < np.finfo(np.double).eps):\n                 # Yk constant\n@@ -293,6 +294,10 @@ def fit(self, X, Y):\n             # 1) weights estimation (inner loop)\n             # -----------------------------------\n             if self.algorithm == \"nipals\":\n+                # Replace columns that are all close to zero with zeros\n+                Yk_mask = np.all(np.abs(Yk) < 10 * Y_eps, axis=0)\n+                Yk[:, Yk_mask] = 0.0\n+\n                 x_weights, y_weights, n_iter_ = \\\n                     _nipals_twoblocks_inner_loop(\n                         X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,\ndiff --git a/sklearn/experimental/enable_iterative_imputer.py b/sklearn/experimental/enable_iterative_imputer.py\n--- a/sklearn/experimental/enable_iterative_imputer.py\n+++ b/sklearn/experimental/enable_iterative_imputer.py\n@@ -1,6 +1,6 @@\n \"\"\"Enables IterativeImputer\n \n-The API and results of this estimators might change without any deprecation\n+The API and results of this estimator might change without any deprecation\n cycle.\n \n Importing this file dynamically sets :class:`sklearn.impute.IterativeImputer`\ndiff --git a/sklearn/metrics/classification.py b/sklearn/metrics/classification.py\n--- a/sklearn/metrics/classification.py\n+++ b/sklearn/metrics/classification.py\n@@ -1066,7 +1066,7 @@ def fbeta_score(y_true, y_pred, beta, labels=None, pos_label=1,\n     The F-beta score is the weighted harmonic mean of precision and recall,\n     reaching its optimal value at 1 and its worst value at 0.\n \n-    The `beta` parameter determines the weight of precision in the combined\n+    The `beta` parameter determines the weight of recall in the combined\n     score. ``beta < 1`` lends more weight to precision, while ``beta > 1``\n     favors recall (``beta -> 0`` considers only precision, ``beta -> inf``\n     only recall).\ndiff --git a/sklearn/metrics/pairwise.py b/sklearn/metrics/pairwise.py\n--- a/sklearn/metrics/pairwise.py\n+++ b/sklearn/metrics/pairwise.py\n@@ -283,7 +283,7 @@ def euclidean_distances(X, Y=None, Y_norm_squared=None, squared=False,\n     return distances if squared else np.sqrt(distances, out=distances)\n \n \n-def _euclidean_distances_upcast(X, XX=None, Y=None, YY=None):\n+def _euclidean_distances_upcast(X, XX=None, Y=None, YY=None, batch_size=None):\n     \"\"\"Euclidean distances between X and Y\n \n     Assumes X and Y have float32 dtype.\n@@ -298,28 +298,28 @@ def _euclidean_distances_upcast(X, XX=None, Y=None, YY=None):\n \n     distances = np.empty((n_samples_X, n_samples_Y), dtype=np.float32)\n \n-    x_density = X.nnz / np.prod(X.shape) if issparse(X) else 1\n-    y_density = Y.nnz / np.prod(Y.shape) if issparse(Y) else 1\n-\n-    # Allow 10% more memory than X, Y and the distance matrix take (at least\n-    # 10MiB)\n-    maxmem = max(\n-        ((x_density * n_samples_X + y_density * n_samples_Y) * n_features\n-         + (x_density * n_samples_X * y_density * n_samples_Y)) / 10,\n-        10 * 2 ** 17)\n-\n-    # The increase amount of memory in 8-byte blocks is:\n-    # - x_density * batch_size * n_features (copy of chunk of X)\n-    # - y_density * batch_size * n_features (copy of chunk of Y)\n-    # - batch_size * batch_size (chunk of distance matrix)\n-    # Hence x² + (xd+yd)kx = M, where x=batch_size, k=n_features, M=maxmem\n-    #                                 xd=x_density and yd=y_density\n-    tmp = (x_density + y_density) * n_features\n-    batch_size = (-tmp + np.sqrt(tmp ** 2 + 4 * maxmem)) / 2\n-    batch_size = max(int(batch_size), 1)\n-\n-    x_batches = gen_batches(X.shape[0], batch_size)\n-    y_batches = gen_batches(Y.shape[0], batch_size)\n+    if batch_size is None:\n+        x_density = X.nnz / np.prod(X.shape) if issparse(X) else 1\n+        y_density = Y.nnz / np.prod(Y.shape) if issparse(Y) else 1\n+\n+        # Allow 10% more memory than X, Y and the distance matrix take (at\n+        # least 10MiB)\n+        maxmem = max(\n+            ((x_density * n_samples_X + y_density * n_samples_Y) * n_features\n+             + (x_density * n_samples_X * y_density * n_samples_Y)) / 10,\n+            10 * 2 ** 17)\n+\n+        # The increase amount of memory in 8-byte blocks is:\n+        # - x_density * batch_size * n_features (copy of chunk of X)\n+        # - y_density * batch_size * n_features (copy of chunk of Y)\n+        # - batch_size * batch_size (chunk of distance matrix)\n+        # Hence x² + (xd+yd)kx = M, where x=batch_size, k=n_features, M=maxmem\n+        #                                 xd=x_density and yd=y_density\n+        tmp = (x_density + y_density) * n_features\n+        batch_size = (-tmp + np.sqrt(tmp ** 2 + 4 * maxmem)) / 2\n+        batch_size = max(int(batch_size), 1)\n+\n+    x_batches = gen_batches(n_samples_X, batch_size)\n \n     for i, x_slice in enumerate(x_batches):\n         X_chunk = X[x_slice].astype(np.float64)\n@@ -328,6 +328,8 @@ def _euclidean_distances_upcast(X, XX=None, Y=None, YY=None):\n         else:\n             XX_chunk = XX[x_slice]\n \n+        y_batches = gen_batches(n_samples_Y, batch_size)\n+\n         for j, y_slice in enumerate(y_batches):\n             if X is Y and j < i:\n                 # when X is Y the distance matrix is symmetric so we only need\ndiff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -367,7 +367,8 @@ def _handle_deprecations(self, X):\n             msg = (\n                 \"Passing 'n_values' is deprecated in version 0.20 and will be \"\n                 \"removed in 0.22. You can use the 'categories' keyword \"\n-                \"instead. 'n_values=n' corresponds to 'categories=[range(n)]'.\"\n+                \"instead. 'n_values=n' corresponds to \"\n+                \"'categories=[range(n)] * n_features'.\"\n             )\n             warnings.warn(msg, DeprecationWarning)\n             self._legacy_mode = True\n@@ -847,6 +848,8 @@ def get_feature_names(self, input_features=None):\n         for i in range(len(cats)):\n             names = [\n                 input_features[i] + '_' + str(t) for t in cats[i]]\n+            if self.drop is not None:\n+                names.pop(self.drop_idx_[i])\n             feature_names.extend(names)\n \n         return np.array(feature_names, dtype=object)\ndiff --git a/sklearn/utils/sparsefuncs.py b/sklearn/utils/sparsefuncs.py\n--- a/sklearn/utils/sparsefuncs.py\n+++ b/sklearn/utils/sparsefuncs.py\n@@ -341,6 +341,11 @@ def inplace_swap_column(X, m, n):\n \n def _minor_reduce(X, ufunc):\n     major_index = np.flatnonzero(np.diff(X.indptr))\n+\n+    # reduceat tries casts X.indptr to intp, which errors\n+    # if it is int64 on a 32 bit system.\n+    # Reinitializing prevents this where possible, see #13737\n+    X = type(X)((X.data, X.indices, X.indptr), shape=X.shape)\n     value = ufunc.reduceat(X.data, X.indptr[major_index])\n     return major_index, value\n \n",
  "test_patch": "diff --git a/sklearn/cross_decomposition/tests/test_pls.py b/sklearn/cross_decomposition/tests/test_pls.py\n--- a/sklearn/cross_decomposition/tests/test_pls.py\n+++ b/sklearn/cross_decomposition/tests/test_pls.py\n@@ -358,13 +358,13 @@ def test_scale_and_stability():\n             X_score, Y_score = clf.fit_transform(X, Y)\n             clf.set_params(scale=False)\n             X_s_score, Y_s_score = clf.fit_transform(X_s, Y_s)\n-            assert_array_almost_equal(X_s_score, X_score)\n-            assert_array_almost_equal(Y_s_score, Y_score)\n+            assert_array_almost_equal(X_s_score, X_score, decimal=4)\n+            assert_array_almost_equal(Y_s_score, Y_score, decimal=4)\n             # Scaling should be idempotent\n             clf.set_params(scale=True)\n             X_score, Y_score = clf.fit_transform(X_s, Y_s)\n-            assert_array_almost_equal(X_s_score, X_score)\n-            assert_array_almost_equal(Y_s_score, Y_score)\n+            assert_array_almost_equal(X_s_score, X_score, decimal=4)\n+            assert_array_almost_equal(Y_s_score, Y_score, decimal=4)\n \n \n def test_pls_errors():\ndiff --git a/sklearn/decomposition/tests/test_fastica.py b/sklearn/decomposition/tests/test_fastica.py\n--- a/sklearn/decomposition/tests/test_fastica.py\n+++ b/sklearn/decomposition/tests/test_fastica.py\n@@ -3,6 +3,7 @@\n \"\"\"\n import itertools\n import warnings\n+import pytest\n \n import numpy as np\n from scipy import stats\n@@ -50,9 +51,11 @@ def test_gs():\n     assert_less((tmp[:5] ** 2).sum(), 1.e-10)\n \n \n-def test_fastica_simple(add_noise=False):\n+@pytest.mark.parametrize(\"add_noise\", [True, False])\n+@pytest.mark.parametrize(\"seed\", range(1))\n+def test_fastica_simple(add_noise, seed):\n     # Test the FastICA algorithm on very simple data.\n-    rng = np.random.RandomState(0)\n+    rng = np.random.RandomState(seed)\n     # scipy.stats uses the global RNG:\n     n_samples = 1000\n     # Generate two sources:\n@@ -82,12 +85,15 @@ def g_test(x):\n     whitening = [True, False]\n     for algo, nl, whiten in itertools.product(algos, nls, whitening):\n         if whiten:\n-            k_, mixing_, s_ = fastica(m.T, fun=nl, algorithm=algo)\n+            k_, mixing_, s_ = fastica(m.T, fun=nl, algorithm=algo,\n+                                      random_state=rng)\n             assert_raises(ValueError, fastica, m.T, fun=np.tanh,\n                           algorithm=algo)\n         else:\n-            X = PCA(n_components=2, whiten=True).fit_transform(m.T)\n-            k_, mixing_, s_ = fastica(X, fun=nl, algorithm=algo, whiten=False)\n+            pca = PCA(n_components=2, whiten=True, random_state=rng)\n+            X = pca.fit_transform(m.T)\n+            k_, mixing_, s_ = fastica(X, fun=nl, algorithm=algo, whiten=False,\n+                                      random_state=rng)\n             assert_raises(ValueError, fastica, X, fun=np.tanh,\n                           algorithm=algo)\n         s_ = s_.T\n@@ -113,8 +119,9 @@ def g_test(x):\n             assert_almost_equal(np.dot(s2_, s2) / n_samples, 1, decimal=1)\n \n     # Test FastICA class\n-    _, _, sources_fun = fastica(m.T, fun=nl, algorithm=algo, random_state=0)\n-    ica = FastICA(fun=nl, algorithm=algo, random_state=0)\n+    _, _, sources_fun = fastica(m.T, fun=nl, algorithm=algo,\n+                                random_state=seed)\n+    ica = FastICA(fun=nl, algorithm=algo, random_state=seed)\n     sources = ica.fit_transform(m.T)\n     assert_equal(ica.components_.shape, (2, 2))\n     assert_equal(sources.shape, (1000, 2))\n@@ -125,7 +132,7 @@ def g_test(x):\n     assert_equal(ica.mixing_.shape, (2, 2))\n \n     for fn in [np.tanh, \"exp(-.5(x^2))\"]:\n-        ica = FastICA(fun=fn, algorithm=algo, random_state=0)\n+        ica = FastICA(fun=fn, algorithm=algo)\n         assert_raises(ValueError, ica.fit, m.T)\n \n     assert_raises(TypeError, FastICA(fun=range(10)).fit, m.T)\ndiff --git a/sklearn/linear_model/tests/test_least_angle.py b/sklearn/linear_model/tests/test_least_angle.py\n--- a/sklearn/linear_model/tests/test_least_angle.py\n+++ b/sklearn/linear_model/tests/test_least_angle.py\n@@ -451,16 +451,23 @@ def test_lars_cv():\n     assert not hasattr(lars_cv, 'n_nonzero_coefs')\n \n \n-@pytest.mark.filterwarnings('ignore::FutureWarning')\n-def test_lars_cv_max_iter():\n-    with warnings.catch_warnings(record=True) as w:\n+def test_lars_cv_max_iter(recwarn):\n+    warnings.simplefilter('always')\n+    with np.errstate(divide='raise', invalid='raise'):\n+        X = diabetes.data\n+        y = diabetes.target\n         rng = np.random.RandomState(42)\n         x = rng.randn(len(y))\n         X = diabetes.data\n         X = np.c_[X, x, x]  # add correlated features\n-        lars_cv = linear_model.LassoLarsCV(max_iter=5)\n+        lars_cv = linear_model.LassoLarsCV(max_iter=5, cv=5)\n         lars_cv.fit(X, y)\n-    assert len(w) == 0\n+    # Check that there is no warning in general and no ConvergenceWarning\n+    # in particular.\n+    # Materialize the string representation of the warning to get a more\n+    # informative error message in case of AssertionError.\n+    recorded_warnings = [str(w) for w in recwarn]\n+    assert recorded_warnings == []\n \n \n def test_lasso_lars_ic():\ndiff --git a/sklearn/metrics/tests/test_pairwise.py b/sklearn/metrics/tests/test_pairwise.py\n--- a/sklearn/metrics/tests/test_pairwise.py\n+++ b/sklearn/metrics/tests/test_pairwise.py\n@@ -48,6 +48,7 @@\n from sklearn.metrics.pairwise import paired_distances\n from sklearn.metrics.pairwise import paired_euclidean_distances\n from sklearn.metrics.pairwise import paired_manhattan_distances\n+from sklearn.metrics.pairwise import _euclidean_distances_upcast\n from sklearn.preprocessing import normalize\n from sklearn.exceptions import DataConversionWarning\n \n@@ -692,6 +693,52 @@ def test_euclidean_distances_sym(dtype, x_array_constr):\n     assert distances.dtype == dtype\n \n \n+@pytest.mark.parametrize(\"batch_size\", [None, 5, 7, 101])\n+@pytest.mark.parametrize(\"x_array_constr\", [np.array, csr_matrix],\n+                         ids=[\"dense\", \"sparse\"])\n+@pytest.mark.parametrize(\"y_array_constr\", [np.array, csr_matrix],\n+                         ids=[\"dense\", \"sparse\"])\n+def test_euclidean_distances_upcast(batch_size, x_array_constr,\n+                                    y_array_constr):\n+    # check batches handling when Y != X (#13910)\n+    rng = np.random.RandomState(0)\n+    X = rng.random_sample((100, 10)).astype(np.float32)\n+    X[X < 0.8] = 0\n+    Y = rng.random_sample((10, 10)).astype(np.float32)\n+    Y[Y < 0.8] = 0\n+\n+    expected = cdist(X, Y)\n+\n+    X = x_array_constr(X)\n+    Y = y_array_constr(Y)\n+    distances = _euclidean_distances_upcast(X, Y=Y, batch_size=batch_size)\n+    distances = np.sqrt(np.maximum(distances, 0))\n+\n+    # the default rtol=1e-7 is too close to the float32 precision\n+    # and fails due too rounding errors.\n+    assert_allclose(distances, expected, rtol=1e-6)\n+\n+\n+@pytest.mark.parametrize(\"batch_size\", [None, 5, 7, 101])\n+@pytest.mark.parametrize(\"x_array_constr\", [np.array, csr_matrix],\n+                         ids=[\"dense\", \"sparse\"])\n+def test_euclidean_distances_upcast_sym(batch_size, x_array_constr):\n+    # check batches handling when X is Y (#13910)\n+    rng = np.random.RandomState(0)\n+    X = rng.random_sample((100, 10)).astype(np.float32)\n+    X[X < 0.8] = 0\n+\n+    expected = squareform(pdist(X))\n+\n+    X = x_array_constr(X)\n+    distances = _euclidean_distances_upcast(X, Y=X, batch_size=batch_size)\n+    distances = np.sqrt(np.maximum(distances, 0))\n+\n+    # the default rtol=1e-7 is too close to the float32 precision\n+    # and fails due too rounding errors.\n+    assert_allclose(distances, expected, rtol=1e-6)\n+\n+\n @pytest.mark.parametrize(\n     \"dtype, eps, rtol\",\n     [(np.float32, 1e-4, 1e-5),\ndiff --git a/sklearn/preprocessing/tests/test_encoders.py b/sklearn/preprocessing/tests/test_encoders.py\n--- a/sklearn/preprocessing/tests/test_encoders.py\n+++ b/sklearn/preprocessing/tests/test_encoders.py\n@@ -590,6 +590,21 @@ def test_one_hot_encoder_feature_names_unicode():\n     assert_array_equal(['n👍me_c❤t1', 'n👍me_dat2'], feature_names)\n \n \n+@pytest.mark.parametrize(\"drop, expected_names\",\n+                         [('first', ['x0_c', 'x2_b']),\n+                          (['c', 2, 'b'], ['x0_b', 'x2_a'])],\n+                         ids=['first', 'manual'])\n+def test_one_hot_encoder_feature_names_drop(drop, expected_names):\n+    X = [['c', 2, 'a'],\n+         ['b', 2, 'b']]\n+\n+    ohe = OneHotEncoder(drop=drop)\n+    ohe.fit(X)\n+    feature_names = ohe.get_feature_names()\n+    assert isinstance(feature_names, np.ndarray)\n+    assert_array_equal(expected_names, feature_names)\n+\n+\n @pytest.mark.parametrize(\"X\", [np.array([[1, np.nan]]).T,\n                                np.array([['a', np.nan]], dtype=object).T],\n                          ids=['numeric', 'object'])\ndiff --git a/sklearn/utils/tests/test_sparsefuncs.py b/sklearn/utils/tests/test_sparsefuncs.py\n--- a/sklearn/utils/tests/test_sparsefuncs.py\n+++ b/sklearn/utils/tests/test_sparsefuncs.py\n@@ -393,14 +393,18 @@ def test_inplace_swap_column():\n     [(0, np.min, np.max, False),\n      (np.nan, np.nanmin, np.nanmax, True)]\n )\n+@pytest.mark.parametrize(\"large_indices\", [True, False])\n def test_min_max(dtype, axis, sparse_format, missing_values, min_func,\n-                 max_func, ignore_nan):\n+                 max_func, ignore_nan, large_indices):\n     X = np.array([[0, 3, 0],\n                   [2, -1, missing_values],\n                   [0, 0, 0],\n                   [9, missing_values, 7],\n                   [4, 0, 5]], dtype=dtype)\n     X_sparse = sparse_format(X)\n+    if large_indices:\n+        X_sparse.indices = X_sparse.indices.astype('int64')\n+        X_sparse.indptr = X_sparse.indptr.astype('int64')\n \n     mins_sparse, maxs_sparse = min_max_axis(X_sparse, axis=axis,\n                                             ignore_nan=ignore_nan)\n",
  "problem_statement": "utils.sparsefuncs.min_max_axis gives TypeError when input is large csc matrix when OS is 32 bit Windows\n#### Description\r\nOn 32 bit versions of Windows, when `min_max_axis` is called on a csc matrix where `indptr.dtype` is int64, an error is produced. This prevents [this](https://github.com/scikit-learn/scikit-learn/pull/13704/) pull request passing tests (see [here](https://github.com/scikit-learn/scikit-learn/pull/13704/checks?check_run_id=109958355)).\r\n\r\n#### Steps/Code to Reproduce\r\n```python\r\nimport scipy.sparse as sp\r\nfrom sklearn.utils.sparsefuncs import min_max_axis\r\n\r\nX = sp.csc_matrix([[1,2],[3,4]])\r\nX.indptr = X.indptr.astype('int64')\r\n\r\nY = sp.csr_matrix([[1,2],[3,4]])\r\nY.indptr = Y.indptr.astype('int64')\r\n\r\nprint(min_max_axis(Y, 0))\r\nprint(min_max_axis(X, 0))\r\n```\r\n\r\n#### Expected Results\r\n```\r\n(array([1, 2], dtype=int32), array([3, 4], dtype=int32))\r\n(array([1, 2], dtype=int32), array([3, 4], dtype=int32))\r\n```\r\n\r\n#### Actual Results\r\n```\r\n(array([1, 2], dtype=int32), array([3, 4], dtype=int32))\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\rod\\bug.py\", line 12, in <module>\r\n    print(min_max_axis(X, 0))\r\n  File \"C:\\Users\\rod\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py\", line 434, in min_max_axis\r\n    return _sparse_min_max(X, axis=axis)\r\n  File \"C:\\Users\\rod\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py\", line 395, in _sparse_min_max\r\n    return (_sparse_min_or_max(X, axis, np.minimum),\r\n  File \"C:\\Users\\rod\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py\", line 389, in _sparse_min_or_max\r\n    return _min_or_max_axis(X, axis, min_or_max)\r\n  File \"C:\\Users\\rod\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py\", line 359, in _min_or_max_axis\r\n    major_index, value = _minor_reduce(mat, min_or_max)\r\n  File \"C:\\Users\\rod\\AppData\\Local\\Programs\\Python\\Python35-32\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py\", line 344, in _minor_reduce\r\n    value = ufunc.reduceat(X.data, X.indptr[major_index])\r\nTypeError: Cannot cast array data from dtype('int64') to dtype('int32') according to the rule 'safe'\r\n```\r\n\r\n#### Versions\r\nSystem:\r\n    python: 3.5.4 (v3.5.4:3f56838, Aug  8 2017, 02:07:06) [MSC v.1900 32 bit (Intel)]\r\n   machine: Windows-10-10.0.17763-SP0\r\nexecutable: C:\\Users\\rod\\AppData\\Local\\Programs\\Python\\Python35-32\\pythonw.exe\r\n\r\nBLAS:\r\n    macros: \r\ncblas_libs: cblas\r\n  lib_dirs: \r\n\r\nPython deps:\r\n    Cython: 0.29.7\r\n     scipy: 1.2.1\r\nsetuptools: 28.8.0\r\n     numpy: 1.16.3\r\n       pip: 19.1\r\n    pandas: None\r\n   sklearn: 0.20.3\r\n\n",
  "hints_text": "Proposed fix:\r\nAdd \r\n```python\r\nif mat.indptr.dtype == np.int64:\r\n        mat.indptr = mat.indptr.astype('int32')\r\n```\r\nbelow `mat = X.tocsc() if axis == 0 else X.tocsr()` in `utils.sparsefuncs._min_or_max_axis`.\r\n\r\nWhen `tocsc` is called for a csr matrix with indptr dtype int64, it returns a csc matrix with indptr dtype int32, but when it's called for a csc matrix that conversion doesn't happen (I assume the original matrix is returned). It's the lack of this conversion that causes the error, and it seems logical to fix it at this point.\nProposed fixes are best shared by opening a pull request.\n\nBut downcasting the indices dtype when your matrix is too big to fit into\nint32 is not a valid solution, even if it will pass the current tests.\n\nSure; this is a tentative suggestion. Looking into it a bit more I agree it's wrong, but downcasting is still necessary.\r\n\r\nThe problem here is that there are two kinds of casting going on. The `ufunc.reduceat` line casts `X.indptr` to `np.intp` using numpy safety rules, where casting _any_ value from 64 bits to 32 is unsafe. But when the input is a csr matrix, the line `mat = X.tocsc()` is willing to cast `X.indptr` from 64 bits to 32 provided that the values in it all fit in an int32. Since `X.tocsc()` doesn't do anything when `X` is already a csc matrix, we don't get this more precise behaviour. Doing `astype('int32')` as I originally suggested wouldn't give it either; I think the easiest way to get it is to add `mat = type(mat)((mat.data, mat.indices, mat.indptr), shape=mat.shape)` after `mat = X.tocsc() if axis == 0 else X.tocsr()`. The `reduceat` line will still give an error on 32 bit systems if there are values in `X.indptr` that don't fit into an int32, but I think that's what should happen (and what does happen now with large csr matrices).",
  "created_at": "2019-05-21T08:19:34Z",
  "version": "0.21",
  "FAIL_TO_PASS": "[\"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-dense-None]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-dense-5]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-dense-7]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-dense-101]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-sparse-None]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-sparse-5]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-sparse-7]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[dense-sparse-101]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-dense-None]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-dense-5]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-dense-7]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-dense-101]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-sparse-None]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-sparse-5]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-sparse-7]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast[sparse-sparse-101]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[dense-None]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[dense-5]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[dense-7]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[dense-101]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[sparse-None]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[sparse-5]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[sparse-7]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_upcast_sym[sparse-101]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_drop[first]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_drop[manual]\"]",
  "PASS_TO_PASS": "[\"sklearn/cross_decomposition/tests/test_pls.py::test_pls\", \"sklearn/cross_decomposition/tests/test_pls.py::test_convergence_fail\", \"sklearn/cross_decomposition/tests/test_pls.py::test_PLSSVD\", \"sklearn/cross_decomposition/tests/test_pls.py::test_univariate_pls_regression\", \"sklearn/cross_decomposition/tests/test_pls.py::test_predict_transform_copy\", \"sklearn/cross_decomposition/tests/test_pls.py::test_scale_and_stability\", \"sklearn/cross_decomposition/tests/test_pls.py::test_pls_errors\", \"sklearn/cross_decomposition/tests/test_pls.py::test_pls_scaling\", \"sklearn/decomposition/tests/test_fastica.py::test_gs\", \"sklearn/decomposition/tests/test_fastica.py::test_fastica_simple[0-True]\", \"sklearn/decomposition/tests/test_fastica.py::test_fastica_simple[0-False]\", \"sklearn/decomposition/tests/test_fastica.py::test_fastica_nowhiten\", \"sklearn/decomposition/tests/test_fastica.py::test_fastica_convergence_fail\", \"sklearn/decomposition/tests/test_fastica.py::test_non_square_fastica\", \"sklearn/decomposition/tests/test_fastica.py::test_fit_transform\", \"sklearn/decomposition/tests/test_fastica.py::test_inverse_transform\", \"sklearn/decomposition/tests/test_fastica.py::test_fastica_errors\", \"sklearn/linear_model/tests/test_least_angle.py::test_simple\", \"sklearn/linear_model/tests/test_least_angle.py::test_simple_precomputed\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_path_gram_equivalent[True-lar]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_path_gram_equivalent[True-lasso]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_path_gram_equivalent[False-lar]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_path_gram_equivalent[False-lasso]\", \"sklearn/linear_model/tests/test_least_angle.py::test_x_none_gram_none_raises_value_error\", \"sklearn/linear_model/tests/test_least_angle.py::test_all_precomputed\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_lstsq\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_gives_lstsq_solution\", \"sklearn/linear_model/tests/test_least_angle.py::test_collinearity\", \"sklearn/linear_model/tests/test_least_angle.py::test_no_path\", \"sklearn/linear_model/tests/test_least_angle.py::test_no_path_precomputed\", \"sklearn/linear_model/tests/test_least_angle.py::test_no_path_all_precomputed\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[Lars]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[LarsCV]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[LassoLarsIC]\", \"sklearn/linear_model/tests/test_least_angle.py::test_singular_matrix\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_early_stopping\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_path_length\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_ill_conditioned\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_ill_conditioned2\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_add_features\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_n_nonzero_coefs\", \"sklearn/linear_model/tests/test_least_angle.py::test_multitarget\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_cv\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_cv_max_iter\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_ic\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_path_readonly_data\", \"sklearn/linear_model/tests/test_least_angle.py::test_lars_path_positive_constraint\", \"sklearn/linear_model/tests/test_least_angle.py::test_estimatorclasses_positive_constraint\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_positive\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_R_implementation\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_copyX_behaviour[True]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_copyX_behaviour[False]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_fit_copyX_behaviour[True]\", \"sklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_fit_copyX_behaviour[False]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[dice]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[jaccard]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[kulsinski]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[matching]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[rogerstanimoto]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[russellrao]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[sokalmichener]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[sokalsneath]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_boolean_distance[yule]\", \"sklearn/metrics/tests/test_pairwise.py::test_no_data_conversion_warning\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_precomputed[pairwise_distances]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_precomputed[pairwise_kernels]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_precomputed_non_negative\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-array-pairwise_distances-euclidean-kwds0]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-array-pairwise_distances-wminkowski-kwds1]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-array-pairwise_distances-wminkowski-kwds2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-array-pairwise_kernels-polynomial-kwds3]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-array-pairwise_kernels-callable_rbf_kernel-kwds4]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-csr_matrix-pairwise_distances-euclidean-kwds0]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-csr_matrix-pairwise_distances-wminkowski-kwds1]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-csr_matrix-pairwise_distances-wminkowski-kwds2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-csr_matrix-pairwise_kernels-polynomial-kwds3]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[float64-csr_matrix-pairwise_kernels-callable_rbf_kernel-kwds4]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-array-pairwise_distances-euclidean-kwds0]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-array-pairwise_distances-wminkowski-kwds1]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-array-pairwise_distances-wminkowski-kwds2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-array-pairwise_kernels-polynomial-kwds3]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-array-pairwise_kernels-callable_rbf_kernel-kwds4]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-csr_matrix-pairwise_distances-euclidean-kwds0]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-csr_matrix-pairwise_distances-wminkowski-kwds1]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-csr_matrix-pairwise_distances-wminkowski-kwds2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-csr_matrix-pairwise_kernels-polynomial-kwds3]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_parallel[int-csr_matrix-pairwise_kernels-callable_rbf_kernel-kwds4]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_callable_nonstrict_metric\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels[rbf]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels[laplacian]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels[sigmoid]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels[polynomial]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels[linear]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels[chi2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels[additive_chi2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels_callable\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_kernels_filter_param\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_distances[cosine-paired_cosine_distances]\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_distances[euclidean-paired_euclidean_distances]\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_distances[l2-paired_euclidean_distances]\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_distances[l1-paired_manhattan_distances]\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_distances[manhattan-paired_manhattan_distances]\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_distances[cityblock-paired_manhattan_distances]\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_distances_callable\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_argmin_min\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_valid[<lambda>0]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_valid[<lambda>1]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_valid[<lambda>2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_valid[<lambda>3]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_valid[<lambda>4]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_invalid[<lambda>-ValueError-length\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_invalid[<lambda>-TypeError-returned\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_invalid[<lambda>-TypeError-,\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_diagonal[euclidean]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_diagonal[l2]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_diagonal[sqeuclidean]\", \"sklearn/metrics/tests/test_pairwise.py::test_parallel_pairwise_distances_diagonal[euclidean]\", \"sklearn/metrics/tests/test_pairwise.py::test_parallel_pairwise_distances_diagonal[l2]\", \"sklearn/metrics/tests/test_pairwise.py::test_parallel_pairwise_distances_diagonal[sqeuclidean]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_known_result[dense-dense]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_known_result[dense-sparse]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_known_result[sparse-dense]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_known_result[sparse-sparse]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_with_norms[dense-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_with_norms[dense-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_with_norms[sparse-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_with_norms[sparse-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[dense-dense-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[dense-dense-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[dense-sparse-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[dense-sparse-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[sparse-dense-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[sparse-dense-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[sparse-sparse-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances[sparse-sparse-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_sym[dense-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_sym[dense-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_sym[sparse-float32]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_sym[sparse-float64]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_extreme_values[1-float32-0.0001-1e-05]\", \"sklearn/metrics/tests/test_pairwise.py::test_euclidean_distances_extreme_values[1000000-float32-0.0001-1e-05]\", \"sklearn/metrics/tests/test_pairwise.py::test_cosine_distances\", \"sklearn/metrics/tests/test_pairwise.py::test_haversine_distances\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_euclidean_distances\", \"sklearn/metrics/tests/test_pairwise.py::test_paired_manhattan_distances\", \"sklearn/metrics/tests/test_pairwise.py::test_chi_square_kernel\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_symmetry[linear_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_symmetry[polynomial_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_symmetry[rbf_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_symmetry[laplacian_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_symmetry[sigmoid_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_symmetry[cosine_similarity]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_sparse[linear_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_sparse[polynomial_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_sparse[rbf_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_sparse[laplacian_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_sparse[sigmoid_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_kernel_sparse[cosine_similarity]\", \"sklearn/metrics/tests/test_pairwise.py::test_linear_kernel\", \"sklearn/metrics/tests/test_pairwise.py::test_rbf_kernel\", \"sklearn/metrics/tests/test_pairwise.py::test_laplacian_kernel\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_similarity_sparse_output[linear-linear_kernel]\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_similarity_sparse_output[cosine-cosine_similarity]\", \"sklearn/metrics/tests/test_pairwise.py::test_cosine_similarity\", \"sklearn/metrics/tests/test_pairwise.py::test_check_dense_matrices\", \"sklearn/metrics/tests/test_pairwise.py::test_check_XB_returned\", \"sklearn/metrics/tests/test_pairwise.py::test_check_different_dimensions\", \"sklearn/metrics/tests/test_pairwise.py::test_check_invalid_dimensions\", \"sklearn/metrics/tests/test_pairwise.py::test_check_sparse_arrays\", \"sklearn/metrics/tests/test_pairwise.py::test_check_tuple_input\", \"sklearn/metrics/tests/test_pairwise.py::test_check_preserve_type\", \"sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_data_derived_params[Y\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_sparse\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dense\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_deprecationwarnings\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_force_new_behaviour\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categorical_features\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categorical_features_ignore_unknown\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_not_fitted\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_no_categorical_features\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown_strings\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_set_params\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[None-False]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[None-True]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[first-False]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[first-True]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X0-fit]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X0-fit_transform]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X1-fit]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X1-fit_transform]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D_pandas[fit]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D_pandas[fit_transform]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[string]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-cat]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_unsorted_categories\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories_mixed_columns\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_unicode\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[error-array-numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[error-array-object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[error-dataframe-numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[error-dataframe-object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[ignore-array-numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[ignore-array-object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[ignore-dataframe-numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_raise_missing[ignore-dataframe-object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[object-string-cat]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_inverse\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_raise_missing[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_raise_missing[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_raise_categories_shape\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_warning\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_manual\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_invalid_params\", \"sklearn/preprocessing/tests/test_encoders.py::test_invalid_drop_length[drop0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_invalid_drop_length[drop1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[first-sparse]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[first-dense]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[manual-sparse]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[manual-dense]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_mean_variance_axis0\", \"sklearn/utils/tests/test_sparsefuncs.py::test_mean_variance_axis1\", \"sklearn/utils/tests/test_sparsefuncs.py::test_incr_mean_variance_axis\", \"sklearn/utils/tests/test_sparsefuncs.py::test_incr_mean_variance_axis_ignore_nan[csc_matrix-0]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_incr_mean_variance_axis_ignore_nan[csc_matrix-1]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_incr_mean_variance_axis_ignore_nan[csr_matrix-0]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_incr_mean_variance_axis_ignore_nan[csr_matrix-1]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_mean_variance_illegal_axis\", \"sklearn/utils/tests/test_sparsefuncs.py::test_densify_rows\", \"sklearn/utils/tests/test_sparsefuncs.py::test_inplace_column_scale\", \"sklearn/utils/tests/test_sparsefuncs.py::test_inplace_row_scale\", \"sklearn/utils/tests/test_sparsefuncs.py::test_inplace_swap_row\", \"sklearn/utils/tests/test_sparsefuncs.py::test_inplace_swap_column\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csr_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csr_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csr_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csr_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csr_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csr_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csc_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csc_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csc_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csc_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csc_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-0-amin-amax-False-csc_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csr_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csr_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csr_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csr_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csr_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csr_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csc_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csc_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csc_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csc_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csc_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[True-nan-nanmin-nanmax-True-csc_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csr_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csr_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csr_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csr_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csr_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csr_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csc_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csc_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csc_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csc_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csc_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-0-amin-amax-False-csc_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csr_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csr_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csr_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csr_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csr_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csr_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csc_matrix-0-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csc_matrix-0-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csc_matrix-1-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csc_matrix-1-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csc_matrix-None-float32]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max[False-nan-nanmin-nanmax-True-csc_matrix-None-float64]\", \"sklearn/utils/tests/test_sparsefuncs.py::test_min_max_axis_errors\", \"sklearn/utils/tests/test_sparsefuncs.py::test_count_nonzero\", \"sklearn/utils/tests/test_sparsefuncs.py::test_csc_row_median\", \"sklearn/utils/tests/test_sparsefuncs.py::test_inplace_normalize\"]",
  "environment_setup_commit": "7813f7efb5b2012412888b69e73d76f2df2b50b6",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.999892",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}