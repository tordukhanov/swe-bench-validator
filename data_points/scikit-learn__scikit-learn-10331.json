{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-10331",
  "base_commit": "61e6f502956d6e49bfab342d7a5b8d8eab45a2ad",
  "patch": "diff --git a/sklearn/grid_search.py b/sklearn/grid_search.py\n--- a/sklearn/grid_search.py\n+++ b/sklearn/grid_search.py\n@@ -740,7 +740,7 @@ class GridSearchCV(BaseSearchCV):\n     >>> from sklearn import svm, grid_search, datasets\n     >>> iris = datasets.load_iris()\n     >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n-    >>> svr = svm.SVC()\n+    >>> svr = svm.SVC(gamma=\"scale\")\n     >>> clf = grid_search.GridSearchCV(svr, parameters)\n     >>> clf.fit(iris.data, iris.target)\n     ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\ndiff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -937,7 +937,7 @@ class GridSearchCV(BaseSearchCV):\n     >>> from sklearn.model_selection import GridSearchCV\n     >>> iris = datasets.load_iris()\n     >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n-    >>> svc = svm.SVC()\n+    >>> svc = svm.SVC(gamma=\"scale\")\n     >>> clf = GridSearchCV(svc, parameters)\n     >>> clf.fit(iris.data, iris.target)\n     ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\ndiff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -168,7 +168,32 @@ def fit(self, X, y, sample_weight=None):\n                              \"boolean masks (use `indices=True` in CV).\"\n                              % (sample_weight.shape, X.shape))\n \n-        if self.gamma == 'auto':\n+        if self.gamma in ('scale', 'auto_deprecated'):\n+            if sparse:\n+                # std = sqrt(E[X^2] - E[X]^2)\n+                X_std = np.sqrt((X.multiply(X)).mean() - (X.mean())**2)\n+            else:\n+                X_std = X.std()\n+            if self.gamma == 'scale':\n+                if X_std != 0:\n+                    self._gamma = 1.0 / (X.shape[1] * X_std)\n+                else:\n+                    self._gamma = 1.0\n+            else:\n+                kernel_uses_gamma = (not callable(self.kernel) and self.kernel\n+                                     not in ('linear', 'precomputed'))\n+                if kernel_uses_gamma and not np.isclose(X_std, 1.0):\n+                    # NOTE: when deprecation ends we need to remove explicitly\n+                    # setting `gamma` in examples (also in tests). See\n+                    # https://github.com/scikit-learn/scikit-learn/pull/10331\n+                    # for the examples/tests that need to be reverted.\n+                    warnings.warn(\"The default value of gamma will change \"\n+                                  \"from 'auto' to 'scale' in version 0.22 to \"\n+                                  \"account better for unscaled features. Set \"\n+                                  \"gamma explicitly to 'auto' or 'scale' to \"\n+                                  \"avoid this warning.\", FutureWarning)\n+                self._gamma = 1.0 / X.shape[1]\n+        elif self.gamma == 'auto':\n             self._gamma = 1.0 / X.shape[1]\n         else:\n             self._gamma = self.gamma\ndiff --git a/sklearn/svm/classes.py b/sklearn/svm/classes.py\n--- a/sklearn/svm/classes.py\n+++ b/sklearn/svm/classes.py\n@@ -446,12 +446,12 @@ class SVC(BaseSVC):\n         Penalty parameter C of the error term.\n \n     kernel : string, optional (default='rbf')\n-         Specifies the kernel type to be used in the algorithm.\n-         It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n-         a callable.\n-         If none is given, 'rbf' will be used. If a callable is given it is\n-         used to pre-compute the kernel matrix from data matrices; that matrix\n-         should be an array of shape ``(n_samples, n_samples)``.\n+        Specifies the kernel type to be used in the algorithm.\n+        It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n+        a callable.\n+        If none is given, 'rbf' will be used. If a callable is given it is\n+        used to pre-compute the kernel matrix from data matrices; that matrix\n+        should be an array of shape ``(n_samples, n_samples)``.\n \n     degree : int, optional (default=3)\n         Degree of the polynomial kernel function ('poly').\n@@ -459,7 +459,13 @@ class SVC(BaseSVC):\n \n     gamma : float, optional (default='auto')\n         Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n-        If gamma is 'auto' then 1/n_features will be used instead.\n+\n+        Current default is 'auto' which uses 1 / n_features,\n+        if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n+        as value of gamma. The current default of gamma, 'auto', will change\n+        to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n+        'auto' is used as a default indicating that no explicit value of gamma\n+        was passed.\n \n     coef0 : float, optional (default=0.0)\n         Independent term in kernel function.\n@@ -550,7 +556,7 @@ class SVC(BaseSVC):\n     >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n     >>> y = np.array([1, 1, 2, 2])\n     >>> from sklearn.svm import SVC\n-    >>> clf = SVC()\n+    >>> clf = SVC(gamma='auto')\n     >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n     SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n         decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n@@ -573,7 +579,7 @@ class SVC(BaseSVC):\n \n     _impl = 'c_svc'\n \n-    def __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto',\n+    def __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated',\n                  coef0=0.0, shrinking=True, probability=False,\n                  tol=1e-3, cache_size=200, class_weight=None,\n                  verbose=False, max_iter=-1, decision_function_shape='ovr',\n@@ -618,7 +624,13 @@ class NuSVC(BaseSVC):\n \n     gamma : float, optional (default='auto')\n         Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n-        If gamma is 'auto' then 1/n_features will be used instead.\n+\n+        Current default is 'auto' which uses 1 / n_features,\n+        if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n+        as value of gamma. The current default of gamma, 'auto', will change\n+        to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n+        'auto' is used as a default indicating that no explicit value of gamma\n+        was passed.\n \n     coef0 : float, optional (default=0.0)\n         Independent term in kernel function.\n@@ -708,10 +720,10 @@ class NuSVC(BaseSVC):\n     >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n     >>> y = np.array([1, 1, 2, 2])\n     >>> from sklearn.svm import NuSVC\n-    >>> clf = NuSVC()\n+    >>> clf = NuSVC(gamma='scale')\n     >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n     NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n-          decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n+          decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n           max_iter=-1, nu=0.5, probability=False, random_state=None,\n           shrinking=True, tol=0.001, verbose=False)\n     >>> print(clf.predict([[-0.8, -1]]))\n@@ -729,9 +741,9 @@ class NuSVC(BaseSVC):\n \n     _impl = 'nu_svc'\n \n-    def __init__(self, nu=0.5, kernel='rbf', degree=3, gamma='auto', coef0=0.0,\n-                 shrinking=True, probability=False, tol=1e-3, cache_size=200,\n-                 class_weight=None, verbose=False, max_iter=-1,\n+    def __init__(self, nu=0.5, kernel='rbf', degree=3, gamma='auto_deprecated',\n+                 coef0=0.0, shrinking=True, probability=False, tol=1e-3,\n+                 cache_size=200, class_weight=None, verbose=False, max_iter=-1,\n                  decision_function_shape='ovr', random_state=None):\n \n         super(NuSVC, self).__init__(\n@@ -776,7 +788,13 @@ class SVR(BaseLibSVM, RegressorMixin):\n \n     gamma : float, optional (default='auto')\n         Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n-        If gamma is 'auto' then 1/n_features will be used instead.\n+\n+        Current default is 'auto' which uses 1 / n_features,\n+        if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n+        as value of gamma. The current default of gamma, 'auto', will change\n+        to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n+        'auto' is used as a default indicating that no explicit value of gamma\n+        was passed.\n \n     coef0 : float, optional (default=0.0)\n         Independent term in kernel function.\n@@ -831,9 +849,9 @@ class SVR(BaseLibSVM, RegressorMixin):\n     >>> np.random.seed(0)\n     >>> y = np.random.randn(n_samples)\n     >>> X = np.random.randn(n_samples, n_features)\n-    >>> clf = SVR(C=1.0, epsilon=0.2)\n+    >>> clf = SVR(gamma='scale', C=1.0, epsilon=0.2)\n     >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n-    SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n+    SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='scale',\n         kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n \n     See also\n@@ -849,8 +867,8 @@ class SVR(BaseLibSVM, RegressorMixin):\n \n     _impl = 'epsilon_svr'\n \n-    def __init__(self, kernel='rbf', degree=3, gamma='auto', coef0=0.0,\n-                 tol=1e-3, C=1.0, epsilon=0.1, shrinking=True,\n+    def __init__(self, kernel='rbf', degree=3, gamma='auto_deprecated',\n+                 coef0=0.0, tol=1e-3, C=1.0, epsilon=0.1, shrinking=True,\n                  cache_size=200, verbose=False, max_iter=-1):\n \n         super(SVR, self).__init__(\n@@ -894,7 +912,13 @@ class NuSVR(BaseLibSVM, RegressorMixin):\n \n     gamma : float, optional (default='auto')\n         Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n-        If gamma is 'auto' then 1/n_features will be used instead.\n+\n+        Current default is 'auto' which uses 1 / n_features,\n+        if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n+        as value of gamma. The current default of gamma, 'auto', will change\n+        to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n+        'auto' is used as a default indicating that no explicit value of gamma\n+        was passed.\n \n     coef0 : float, optional (default=0.0)\n         Independent term in kernel function.\n@@ -946,9 +970,9 @@ class NuSVR(BaseLibSVM, RegressorMixin):\n     >>> np.random.seed(0)\n     >>> y = np.random.randn(n_samples)\n     >>> X = np.random.randn(n_samples, n_features)\n-    >>> clf = NuSVR(C=1.0, nu=0.1)\n+    >>> clf = NuSVR(gamma='scale', C=1.0, nu=0.1)\n     >>> clf.fit(X, y)  #doctest: +NORMALIZE_WHITESPACE\n-    NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma='auto',\n+    NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma='scale',\n           kernel='rbf', max_iter=-1, nu=0.1, shrinking=True, tol=0.001,\n           verbose=False)\n \n@@ -965,8 +989,8 @@ class NuSVR(BaseLibSVM, RegressorMixin):\n     _impl = 'nu_svr'\n \n     def __init__(self, nu=0.5, C=1.0, kernel='rbf', degree=3,\n-                 gamma='auto', coef0=0.0, shrinking=True, tol=1e-3,\n-                 cache_size=200, verbose=False, max_iter=-1):\n+                 gamma='auto_deprecated', coef0=0.0, shrinking=True,\n+                 tol=1e-3, cache_size=200, verbose=False, max_iter=-1):\n \n         super(NuSVR, self).__init__(\n             kernel=kernel, degree=degree, gamma=gamma, coef0=coef0,\n@@ -1005,7 +1029,13 @@ class OneClassSVM(BaseLibSVM, OutlierMixin):\n \n     gamma : float, optional (default='auto')\n         Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n-        If gamma is 'auto' then 1/n_features will be used instead.\n+\n+        Current default is 'auto' which uses 1 / n_features,\n+        if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n+        as value of gamma. The current default of gamma, 'auto', will change\n+        to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n+        'auto' is used as a default indicating that no explicit value of gamma\n+        was passed.\n \n     coef0 : float, optional (default=0.0)\n         Independent term in kernel function.\n@@ -1066,8 +1096,8 @@ class OneClassSVM(BaseLibSVM, OutlierMixin):\n \n     _impl = 'one_class'\n \n-    def __init__(self, kernel='rbf', degree=3, gamma='auto', coef0=0.0,\n-                 tol=1e-3, nu=0.5, shrinking=True, cache_size=200,\n+    def __init__(self, kernel='rbf', degree=3, gamma='auto_deprecated',\n+                 coef0=0.0, tol=1e-3, nu=0.5, shrinking=True, cache_size=200,\n                  verbose=False, max_iter=-1, random_state=None):\n \n         super(OneClassSVM, self).__init__(\n",
  "test_patch": "diff --git a/sklearn/ensemble/tests/test_bagging.py b/sklearn/ensemble/tests/test_bagging.py\n--- a/sklearn/ensemble/tests/test_bagging.py\n+++ b/sklearn/ensemble/tests/test_bagging.py\n@@ -69,7 +69,7 @@ def test_classification():\n                            Perceptron(tol=1e-3),\n                            DecisionTreeClassifier(),\n                            KNeighborsClassifier(),\n-                           SVC()]:\n+                           SVC(gamma=\"scale\")]:\n         for params in grid:\n             BaggingClassifier(base_estimator=base_estimator,\n                               random_state=rng,\n@@ -115,7 +115,8 @@ def fit(self, X, y):\n             for f in ['predict', 'predict_proba', 'predict_log_proba', 'decision_function']:\n                 # Trained on sparse format\n                 sparse_classifier = BaggingClassifier(\n-                    base_estimator=CustomSVC(decision_function_shape='ovr'),\n+                    base_estimator=CustomSVC(gamma='scale',\n+                                             decision_function_shape='ovr'),\n                     random_state=1,\n                     **params\n                 ).fit(X_train_sparse, y_train)\n@@ -123,12 +124,13 @@ def fit(self, X, y):\n \n                 # Trained on dense format\n                 dense_classifier = BaggingClassifier(\n-                    base_estimator=CustomSVC(decision_function_shape='ovr'),\n+                    base_estimator=CustomSVC(gamma='scale',\n+                                             decision_function_shape='ovr'),\n                     random_state=1,\n                     **params\n                 ).fit(X_train, y_train)\n                 dense_results = getattr(dense_classifier, f)(X_test)\n-                assert_array_equal(sparse_results, dense_results)\n+                assert_array_almost_equal(sparse_results, dense_results)\n \n             sparse_type = type(X_train_sparse)\n             types = [i.data_type_ for i in sparse_classifier.estimators_]\n@@ -151,7 +153,7 @@ def test_regression():\n                            DummyRegressor(),\n                            DecisionTreeRegressor(),\n                            KNeighborsRegressor(),\n-                           SVR()]:\n+                           SVR(gamma='scale')]:\n         for params in grid:\n             BaggingRegressor(base_estimator=base_estimator,\n                              random_state=rng,\n@@ -197,7 +199,7 @@ def fit(self, X, y):\n \n             # Trained on sparse format\n             sparse_classifier = BaggingRegressor(\n-                base_estimator=CustomSVR(),\n+                base_estimator=CustomSVR(gamma='scale'),\n                 random_state=1,\n                 **params\n             ).fit(X_train_sparse, y_train)\n@@ -205,7 +207,7 @@ def fit(self, X, y):\n \n             # Trained on dense format\n             dense_results = BaggingRegressor(\n-                base_estimator=CustomSVR(),\n+                base_estimator=CustomSVR(gamma='scale'),\n                 random_state=1,\n                 **params\n             ).fit(X_train, y_train).predict(X_test)\n@@ -310,7 +312,7 @@ def test_oob_score_classification():\n                                                         iris.target,\n                                                         random_state=rng)\n \n-    for base_estimator in [DecisionTreeClassifier(), SVC()]:\n+    for base_estimator in [DecisionTreeClassifier(), SVC(gamma=\"scale\")]:\n         clf = BaggingClassifier(base_estimator=base_estimator,\n                                 n_estimators=100,\n                                 bootstrap=True,\n@@ -440,7 +442,8 @@ def test_parallel_classification():\n     assert_array_almost_equal(y1, y3)\n \n     # decision_function\n-    ensemble = BaggingClassifier(SVC(decision_function_shape='ovr'),\n+    ensemble = BaggingClassifier(SVC(gamma='scale',\n+                                     decision_function_shape='ovr'),\n                                  n_jobs=3,\n                                  random_state=0).fit(X_train, y_train)\n \n@@ -457,7 +460,8 @@ def test_parallel_classification():\n                          \"\".format(X_test.shape[1], X_err.shape[1]),\n                          ensemble.decision_function, X_err)\n \n-    ensemble = BaggingClassifier(SVC(decision_function_shape='ovr'),\n+    ensemble = BaggingClassifier(SVC(gamma='scale',\n+                                     decision_function_shape='ovr'),\n                                  n_jobs=1,\n                                  random_state=0).fit(X_train, y_train)\n \n@@ -501,7 +505,7 @@ def test_gridsearch():\n     parameters = {'n_estimators': (1, 2),\n                   'base_estimator__C': (1, 2)}\n \n-    GridSearchCV(BaggingClassifier(SVC()),\n+    GridSearchCV(BaggingClassifier(SVC(gamma=\"scale\")),\n                  parameters,\n                  scoring=\"roc_auc\").fit(X, y)\n \n@@ -550,7 +554,7 @@ def test_base_estimator():\n \n     assert_true(isinstance(ensemble.base_estimator_, DecisionTreeRegressor))\n \n-    ensemble = BaggingRegressor(SVR(),\n+    ensemble = BaggingRegressor(SVR(gamma='scale'),\n                                 n_jobs=3,\n                                 random_state=0).fit(X_train, y_train)\n     assert_true(isinstance(ensemble.base_estimator_, SVR))\ndiff --git a/sklearn/ensemble/tests/test_voting_classifier.py b/sklearn/ensemble/tests/test_voting_classifier.py\n--- a/sklearn/ensemble/tests/test_voting_classifier.py\n+++ b/sklearn/ensemble/tests/test_voting_classifier.py\n@@ -251,7 +251,7 @@ def test_sample_weight():\n     \"\"\"Tests sample_weight parameter of VotingClassifier\"\"\"\n     clf1 = LogisticRegression(random_state=123)\n     clf2 = RandomForestClassifier(random_state=123)\n-    clf3 = SVC(probability=True, random_state=123)\n+    clf3 = SVC(gamma='scale', probability=True, random_state=123)\n     eclf1 = VotingClassifier(estimators=[\n         ('lr', clf1), ('rf', clf2), ('svc', clf3)],\n         voting='soft').fit(X, y, sample_weight=np.ones((len(y),)))\ndiff --git a/sklearn/ensemble/tests/test_weight_boosting.py b/sklearn/ensemble/tests/test_weight_boosting.py\n--- a/sklearn/ensemble/tests/test_weight_boosting.py\n+++ b/sklearn/ensemble/tests/test_weight_boosting.py\n@@ -280,29 +280,27 @@ def test_error():\n def test_base_estimator():\n     # Test different base estimators.\n     from sklearn.ensemble import RandomForestClassifier\n-    from sklearn.svm import SVC\n \n     # XXX doesn't work with y_class because RF doesn't support classes_\n     # Shouldn't AdaBoost run a LabelBinarizer?\n     clf = AdaBoostClassifier(RandomForestClassifier())\n     clf.fit(X, y_regr)\n \n-    clf = AdaBoostClassifier(SVC(), algorithm=\"SAMME\")\n+    clf = AdaBoostClassifier(SVC(gamma=\"scale\"), algorithm=\"SAMME\")\n     clf.fit(X, y_class)\n \n     from sklearn.ensemble import RandomForestRegressor\n-    from sklearn.svm import SVR\n \n     clf = AdaBoostRegressor(RandomForestRegressor(), random_state=0)\n     clf.fit(X, y_regr)\n \n-    clf = AdaBoostRegressor(SVR(), random_state=0)\n+    clf = AdaBoostRegressor(SVR(gamma='scale'), random_state=0)\n     clf.fit(X, y_regr)\n \n     # Check that an empty discrete ensemble fails in fit, not predict.\n     X_fail = [[1, 1], [1, 1], [1, 1], [1, 1]]\n     y_fail = [\"foo\", \"bar\", 1, 2]\n-    clf = AdaBoostClassifier(SVC(), algorithm=\"SAMME\")\n+    clf = AdaBoostClassifier(SVC(gamma=\"scale\"), algorithm=\"SAMME\")\n     assert_raises_regexp(ValueError, \"worse than random\",\n                          clf.fit, X_fail, y_fail)\n \n@@ -344,14 +342,14 @@ def fit(self, X, y, sample_weight=None):\n \n         # Trained on sparse format\n         sparse_classifier = AdaBoostClassifier(\n-            base_estimator=CustomSVC(probability=True),\n+            base_estimator=CustomSVC(gamma='scale', probability=True),\n             random_state=1,\n             algorithm=\"SAMME\"\n         ).fit(X_train_sparse, y_train)\n \n         # Trained on dense format\n         dense_classifier = AdaBoostClassifier(\n-            base_estimator=CustomSVC(probability=True),\n+            base_estimator=CustomSVC(gamma='scale', probability=True),\n             random_state=1,\n             algorithm=\"SAMME\"\n         ).fit(X_train, y_train)\n@@ -438,13 +436,13 @@ def fit(self, X, y, sample_weight=None):\n \n         # Trained on sparse format\n         sparse_classifier = AdaBoostRegressor(\n-            base_estimator=CustomSVR(),\n+            base_estimator=CustomSVR(gamma='scale'),\n             random_state=1\n         ).fit(X_train_sparse, y_train)\n \n         # Trained on dense format\n         dense_classifier = dense_results = AdaBoostRegressor(\n-            base_estimator=CustomSVR(),\n+            base_estimator=CustomSVR(gamma='scale'),\n             random_state=1\n         ).fit(X_train, y_train)\n \ndiff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py\n--- a/sklearn/model_selection/tests/test_search.py\n+++ b/sklearn/model_selection/tests/test_search.py\n@@ -484,7 +484,7 @@ def test_grid_search_bad_param_grid():\n         GridSearchCV, clf, param_dict)\n \n     param_dict = {\"C\": []}\n-    clf = SVC()\n+    clf = SVC(gamma=\"scale\")\n     assert_raise_message(\n         ValueError,\n         \"Parameter values for parameter (C) need to be a non-empty sequence.\",\n@@ -499,7 +499,7 @@ def test_grid_search_bad_param_grid():\n         GridSearchCV, clf, param_dict)\n \n     param_dict = {\"C\": np.ones(6).reshape(3, 2)}\n-    clf = SVC()\n+    clf = SVC(gamma=\"scale\")\n     assert_raises(ValueError, GridSearchCV, clf, param_dict)\n \n \n@@ -828,7 +828,8 @@ def test_grid_search_cv_results():\n     n_candidates = n_grid_points\n \n     for iid in (False, True):\n-        search = GridSearchCV(SVC(), cv=n_splits, iid=iid, param_grid=params)\n+        search = GridSearchCV(SVC(gamma='scale'), cv=n_splits, iid=iid,\n+                              param_grid=params)\n         search.fit(X, y)\n         assert_equal(iid, search.iid)\n         cv_results = search.cv_results_\n@@ -878,8 +879,9 @@ def test_random_search_cv_results():\n     n_cand = n_search_iter\n \n     for iid in (False, True):\n-        search = RandomizedSearchCV(SVC(), n_iter=n_search_iter, cv=n_splits,\n-                                    iid=iid, param_distributions=params)\n+        search = RandomizedSearchCV(SVC(gamma='scale'), n_iter=n_search_iter,\n+                                    cv=n_splits, iid=iid,\n+                                    param_distributions=params)\n         search.fit(X, y)\n         assert_equal(iid, search.iid)\n         cv_results = search.cv_results_\n@@ -908,7 +910,8 @@ def test_search_iid_param():\n     # create \"cv\" for splits\n     cv = [[mask, ~mask], [~mask, mask]]\n     # once with iid=True (default)\n-    grid_search = GridSearchCV(SVC(), param_grid={'C': [1, 10]}, cv=cv)\n+    grid_search = GridSearchCV(SVC(), param_grid={'C': [1, 10]},\n+                               cv=cv)\n     random_search = RandomizedSearchCV(SVC(), n_iter=2,\n                                        param_distributions={'C': [1, 10]},\n                                        cv=cv)\n@@ -942,7 +945,8 @@ def test_search_iid_param():\n         assert_almost_equal(test_mean, expected_test_mean)\n         assert_almost_equal(test_std, expected_test_std)\n         assert_array_almost_equal(test_cv_scores,\n-                                  cross_val_score(SVC(C=1), X, y, cv=cv))\n+                                  cross_val_score(SVC(C=1), X,\n+                                                  y, cv=cv))\n \n         # For the train scores, we do not take a weighted mean irrespective of\n         # i.i.d. or not\n@@ -998,9 +1002,9 @@ def test_grid_search_cv_results_multimetric():\n         for scoring in ({'accuracy': make_scorer(accuracy_score),\n                          'recall': make_scorer(recall_score)},\n                         'accuracy', 'recall'):\n-            grid_search = GridSearchCV(SVC(), cv=n_splits, iid=iid,\n-                                       param_grid=params, scoring=scoring,\n-                                       refit=False)\n+            grid_search = GridSearchCV(SVC(gamma='scale'), cv=n_splits,\n+                                       iid=iid, param_grid=params,\n+                                       scoring=scoring, refit=False)\n             grid_search.fit(X, y)\n             assert_equal(grid_search.iid, iid)\n             grid_searches.append(grid_search)\n@@ -1095,8 +1099,8 @@ def test_search_cv_results_rank_tie_breaking():\n     # which would result in a tie of their mean cv-scores\n     param_grid = {'C': [1, 1.001, 0.001]}\n \n-    grid_search = GridSearchCV(SVC(), param_grid=param_grid)\n-    random_search = RandomizedSearchCV(SVC(), n_iter=3,\n+    grid_search = GridSearchCV(SVC(gamma=\"scale\"), param_grid=param_grid)\n+    random_search = RandomizedSearchCV(SVC(gamma=\"scale\"), n_iter=3,\n                                        param_distributions=param_grid)\n \n     for search in (grid_search, random_search):\n@@ -1282,7 +1286,7 @@ def test_predict_proba_disabled():\n     # Test predict_proba when disabled on estimator.\n     X = np.arange(20).reshape(5, -1)\n     y = [0, 0, 1, 1, 1]\n-    clf = SVC(probability=False)\n+    clf = SVC(gamma='scale', probability=False)\n     gs = GridSearchCV(clf, {}, cv=2).fit(X, y)\n     assert_false(hasattr(gs, \"predict_proba\"))\n \n@@ -1536,18 +1540,18 @@ def test_deprecated_grid_search_iid():\n     depr_message = (\"The default of the `iid` parameter will change from True \"\n                     \"to False in version 0.22\")\n     X, y = make_blobs(n_samples=54, random_state=0, centers=2)\n-    grid = GridSearchCV(SVC(), param_grid={'C': [1]}, cv=3)\n+    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=3)\n     # no warning with equally sized test sets\n     assert_no_warnings(grid.fit, X, y)\n \n-    grid = GridSearchCV(SVC(), param_grid={'C': [1]}, cv=5)\n+    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=5)\n     # warning because 54 % 5 != 0\n     assert_warns_message(DeprecationWarning, depr_message, grid.fit, X, y)\n \n-    grid = GridSearchCV(SVC(), param_grid={'C': [1]}, cv=2)\n+    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=2)\n     # warning because stratification into two classes and 27 % 2 != 0\n     assert_warns_message(DeprecationWarning, depr_message, grid.fit, X, y)\n \n-    grid = GridSearchCV(SVC(), param_grid={'C': [1]}, cv=KFold(2))\n+    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=KFold(2))\n     # no warning because no stratification and 54 % 2 == 0\n     assert_no_warnings(grid.fit, X, y)\ndiff --git a/sklearn/model_selection/tests/test_validation.py b/sklearn/model_selection/tests/test_validation.py\n--- a/sklearn/model_selection/tests/test_validation.py\n+++ b/sklearn/model_selection/tests/test_validation.py\n@@ -339,10 +339,10 @@ def test_cross_validate_invalid_scoring_param():\n \n     # Multiclass Scorers that return multiple values are not supported yet\n     assert_raises_regex(ValueError, \"scoring must return a number, got\",\n-                        cross_validate, SVC(), X, y,\n+                        cross_validate, SVC(gamma='scale'), X, y,\n                         scoring=multivalued_scorer)\n     assert_raises_regex(ValueError, \"scoring must return a number, got\",\n-                        cross_validate, SVC(), X, y,\n+                        cross_validate, SVC(gamma='scale'), X, y,\n                         scoring={\"foo\": multivalued_scorer})\n \n     assert_raises_regex(ValueError, \"'mse' is not a valid scoring value.\",\n@@ -572,7 +572,7 @@ def test_cross_val_score_precomputed():\n     assert_array_almost_equal(score_precomputed, score_linear)\n \n     # test with callable\n-    svm = SVC(kernel=lambda x, y: np.dot(x, y.T))\n+    svm = SVC(gamma='scale', kernel=lambda x, y: np.dot(x, y.T))\n     score_callable = cross_val_score(svm, X, y)\n     assert_array_almost_equal(score_precomputed, score_callable)\n \ndiff --git a/sklearn/preprocessing/tests/test_data.py b/sklearn/preprocessing/tests/test_data.py\n--- a/sklearn/preprocessing/tests/test_data.py\n+++ b/sklearn/preprocessing/tests/test_data.py\n@@ -1773,7 +1773,8 @@ def test_cv_pipeline_precomputed():\n     y_true = np.ones((4,))\n     K = X.dot(X.T)\n     kcent = KernelCenterer()\n-    pipeline = Pipeline([(\"kernel_centerer\", kcent), (\"svr\", SVR())])\n+    pipeline = Pipeline([(\"kernel_centerer\", kcent), (\"svr\",\n+                        SVR(gamma='scale'))])\n \n     # did the pipeline set the _pairwise attribute?\n     assert_true(pipeline._pairwise)\ndiff --git a/sklearn/svm/tests/test_sparse.py b/sklearn/svm/tests/test_sparse.py\n--- a/sklearn/svm/tests/test_sparse.py\n+++ b/sklearn/svm/tests/test_sparse.py\n@@ -83,10 +83,10 @@ def test_svc():\n     kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n     for dataset in datasets:\n         for kernel in kernels:\n-            clf = svm.SVC(kernel=kernel, probability=True, random_state=0,\n-                          decision_function_shape='ovo')\n-            sp_clf = svm.SVC(kernel=kernel, probability=True, random_state=0,\n-                             decision_function_shape='ovo')\n+            clf = svm.SVC(gamma='scale', kernel=kernel, probability=True,\n+                          random_state=0, decision_function_shape='ovo')\n+            sp_clf = svm.SVC(gamma='scale', kernel=kernel, probability=True,\n+                             random_state=0, decision_function_shape='ovo')\n             check_svm_model_equal(clf, sp_clf, *dataset)\n \n \n@@ -127,15 +127,16 @@ def test_svc_with_custom_kernel():\n     def kfunc(x, y):\n         return safe_sparse_dot(x, y.T)\n     clf_lin = svm.SVC(kernel='linear').fit(X_sp, Y)\n-    clf_mylin = svm.SVC(kernel=kfunc).fit(X_sp, Y)\n+    clf_mylin = svm.SVC(gamma='scale', kernel=kfunc).fit(X_sp, Y)\n     assert_array_equal(clf_lin.predict(X_sp), clf_mylin.predict(X_sp))\n \n \n def test_svc_iris():\n     # Test the sparse SVC with the iris dataset\n     for k in ('linear', 'poly', 'rbf'):\n-        sp_clf = svm.SVC(kernel=k).fit(iris.data, iris.target)\n-        clf = svm.SVC(kernel=k).fit(iris.data.toarray(), iris.target)\n+        sp_clf = svm.SVC(gamma='scale', kernel=k).fit(iris.data, iris.target)\n+        clf = svm.SVC(gamma='scale', kernel=k).fit(iris.data.toarray(),\n+                                                   iris.target)\n \n         assert_array_almost_equal(clf.support_vectors_,\n                                   sp_clf.support_vectors_.toarray())\n@@ -175,16 +176,16 @@ def test_sparse_decision_function():\n def test_error():\n     # Test that it gives proper exception on deficient input\n     # impossible value of C\n-    assert_raises(ValueError, svm.SVC(C=-1).fit, X, Y)\n+    assert_raises(ValueError, svm.SVC(gamma='scale', C=-1).fit, X, Y)\n \n     # impossible value of nu\n-    clf = svm.NuSVC(nu=0.0)\n+    clf = svm.NuSVC(gamma='scale', nu=0.0)\n     assert_raises(ValueError, clf.fit, X_sp, Y)\n \n     Y2 = Y[:-1]  # wrong dimensions for labels\n     assert_raises(ValueError, clf.fit, X_sp, Y2)\n \n-    clf = svm.SVC()\n+    clf = svm.SVC(gamma=\"scale\")\n     clf.fit(X_sp, Y)\n     assert_array_equal(clf.predict(T), true_result)\n \n@@ -241,7 +242,7 @@ def test_weight():\n     X_ = sparse.csr_matrix(X_)\n     for clf in (linear_model.LogisticRegression(),\n                 svm.LinearSVC(random_state=0),\n-                svm.SVC()):\n+                svm.SVC(gamma=\"scale\")):\n         clf.set_params(class_weight={0: 5})\n         clf.fit(X_[:180], y_[:180])\n         y_pred = clf.predict(X_[180:])\n@@ -250,7 +251,7 @@ def test_weight():\n \n def test_sample_weights():\n     # Test weights on individual samples\n-    clf = svm.SVC()\n+    clf = svm.SVC(gamma=\"scale\")\n     clf.fit(X_sp, Y)\n     assert_array_equal(clf.predict([X[2]]), [1.])\n \n@@ -276,8 +277,8 @@ def test_sparse_oneclasssvm():\n     kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n     for dataset in datasets:\n         for kernel in kernels:\n-            clf = svm.OneClassSVM(kernel=kernel)\n-            sp_clf = svm.OneClassSVM(kernel=kernel)\n+            clf = svm.OneClassSVM(gamma='scale', kernel=kernel)\n+            sp_clf = svm.OneClassSVM(gamma='scale', kernel=kernel)\n             check_svm_model_equal(clf, sp_clf, *dataset)\n \n \n@@ -313,15 +314,15 @@ def test_sparse_realdata():\n def test_sparse_svc_clone_with_callable_kernel():\n     # Test that the \"dense_fit\" is called even though we use sparse input\n     # meaning that everything works fine.\n-    a = svm.SVC(C=1, kernel=lambda x, y: x * y.T, probability=True,\n-                random_state=0)\n+    a = svm.SVC(gamma='scale', C=1, kernel=lambda x, y: x * y.T,\n+                probability=True, random_state=0)\n     b = base.clone(a)\n \n     b.fit(X_sp, Y)\n     pred = b.predict(X_sp)\n     b.predict_proba(X_sp)\n \n-    dense_svm = svm.SVC(C=1, kernel=lambda x, y: np.dot(x, y.T),\n+    dense_svm = svm.SVC(gamma='scale', C=1, kernel=lambda x, y: np.dot(x, y.T),\n                         probability=True, random_state=0)\n     pred_dense = dense_svm.fit(X, Y).predict(X)\n     assert_array_equal(pred_dense, pred)\n@@ -329,17 +330,17 @@ def test_sparse_svc_clone_with_callable_kernel():\n \n \n def test_timeout():\n-    sp = svm.SVC(C=1, kernel=lambda x, y: x * y.T, probability=True,\n-                 random_state=0, max_iter=1)\n+    sp = svm.SVC(gamma='scale', C=1, kernel=lambda x, y: x * y.T,\n+                 probability=True, random_state=0, max_iter=1)\n \n     assert_warns(ConvergenceWarning, sp.fit, X_sp, Y)\n \n \n def test_consistent_proba():\n-    a = svm.SVC(probability=True, max_iter=1, random_state=0)\n+    a = svm.SVC(gamma='scale', probability=True, max_iter=1, random_state=0)\n     with ignore_warnings(category=ConvergenceWarning):\n         proba_1 = a.fit(X, Y).predict_proba(X)\n-    a = svm.SVC(probability=True, max_iter=1, random_state=0)\n+    a = svm.SVC(gamma='scale', probability=True, max_iter=1, random_state=0)\n     with ignore_warnings(category=ConvergenceWarning):\n         proba_2 = a.fit(X, Y).predict_proba(X)\n     assert_array_almost_equal(proba_1, proba_2)\ndiff --git a/sklearn/svm/tests/test_svm.py b/sklearn/svm/tests/test_svm.py\n--- a/sklearn/svm/tests/test_svm.py\n+++ b/sklearn/svm/tests/test_svm.py\n@@ -20,6 +20,7 @@\n from sklearn.utils.testing import assert_raises_regexp, assert_warns\n from sklearn.utils.testing import assert_warns_message, assert_raise_message\n from sklearn.utils.testing import ignore_warnings, assert_raises\n+from sklearn.utils.testing import assert_no_warnings\n from sklearn.exceptions import ConvergenceWarning\n from sklearn.exceptions import NotFittedError\n from sklearn.multiclass import OneVsRestClassifier\n@@ -54,7 +55,7 @@ def test_libsvm_iris():\n \n     # shuffle the dataset so that labels are not ordered\n     for k in ('linear', 'rbf'):\n-        clf = svm.SVC(kernel=k).fit(iris.data, iris.target)\n+        clf = svm.SVC(gamma='scale', kernel=k).fit(iris.data, iris.target)\n         assert_greater(np.mean(clf.predict(iris.data) == iris.target), 0.9)\n         assert_true(hasattr(clf, \"coef_\") == (k == 'linear'))\n \n@@ -119,7 +120,7 @@ def test_precomputed():\n     # matrix. kernel is just a linear kernel\n \n     kfunc = lambda x, y: np.dot(x, y.T)\n-    clf = svm.SVC(kernel=kfunc)\n+    clf = svm.SVC(gamma='scale', kernel=kfunc)\n     clf.fit(X, Y)\n     pred = clf.predict(T)\n \n@@ -151,7 +152,7 @@ def test_precomputed():\n     pred = clf.predict(K)\n     assert_almost_equal(np.mean(pred == iris.target), .99, decimal=2)\n \n-    clf = svm.SVC(kernel=kfunc)\n+    clf = svm.SVC(gamma='scale', kernel=kfunc)\n     clf.fit(iris.data, iris.target)\n     assert_almost_equal(np.mean(pred == iris.target), .99, decimal=2)\n \n@@ -171,7 +172,7 @@ def test_svr():\n \n     # non-regression test; previously, BaseLibSVM would check that\n     # len(np.unique(y)) < 2, which must only be done for SVC\n-    svm.SVR().fit(diabetes.data, np.ones(len(diabetes.data)))\n+    svm.SVR(gamma='scale').fit(diabetes.data, np.ones(len(diabetes.data)))\n     svm.LinearSVR().fit(diabetes.data, np.ones(len(diabetes.data)))\n \n \n@@ -230,22 +231,22 @@ def test_svr_errors():\n     y = [0.0, 0.5]\n \n     # Bad kernel\n-    clf = svm.SVR(kernel=lambda x, y: np.array([[1.0]]))\n+    clf = svm.SVR(gamma='scale', kernel=lambda x, y: np.array([[1.0]]))\n     clf.fit(X, y)\n     assert_raises(ValueError, clf.predict, X)\n \n \n def test_oneclass():\n     # Test OneClassSVM\n-    clf = svm.OneClassSVM()\n+    clf = svm.OneClassSVM(gamma='scale')\n     clf.fit(X)\n     pred = clf.predict(T)\n \n     assert_array_equal(pred, [-1, -1, -1])\n     assert_equal(pred.dtype, np.dtype('intp'))\n-    assert_array_almost_equal(clf.intercept_, [-1.008], decimal=3)\n+    assert_array_almost_equal(clf.intercept_, [-1.117], decimal=3)\n     assert_array_almost_equal(clf.dual_coef_,\n-                              [[0.632, 0.233, 0.633, 0.234, 0.632, 0.633]],\n+                              [[0.681, 0.139, 0.68, 0.14, 0.68, 0.68]],\n                               decimal=3)\n     assert_raises(AttributeError, lambda: clf.coef_)\n \n@@ -306,8 +307,9 @@ def test_probability():\n     # Predict probabilities using SVC\n     # This uses cross validation, so we use a slightly bigger testing set.\n \n-    for clf in (svm.SVC(probability=True, random_state=0, C=1.0),\n-                svm.NuSVC(probability=True, random_state=0)):\n+    for clf in (svm.SVC(gamma='scale', probability=True, random_state=0,\n+                C=1.0), svm.NuSVC(gamma='scale', probability=True,\n+                                  random_state=0)):\n         clf.fit(iris.data, iris.target)\n \n         prob_predict = clf.predict_proba(iris.data)\n@@ -403,7 +405,7 @@ def test_svr_predict():\n \n def test_weight():\n     # Test class weights\n-    clf = svm.SVC(class_weight={1: 0.1})\n+    clf = svm.SVC(gamma='scale', class_weight={1: 0.1})\n     # we give a small weights to class 1\n     clf.fit(X, Y)\n     # so all predicted values belong to class 2\n@@ -413,7 +415,7 @@ def test_weight():\n                                  weights=[0.833, 0.167], random_state=2)\n \n     for clf in (linear_model.LogisticRegression(),\n-                svm.LinearSVC(random_state=0), svm.SVC()):\n+                svm.LinearSVC(random_state=0), svm.SVC(gamma=\"scale\")):\n         clf.set_params(class_weight={0: .1, 1: 10})\n         clf.fit(X_[:100], y_[:100])\n         y_pred = clf.predict(X_[100:])\n@@ -423,7 +425,7 @@ def test_weight():\n def test_sample_weights():\n     # Test weights on individual samples\n     # TODO: check on NuSVR, OneClass, etc.\n-    clf = svm.SVC()\n+    clf = svm.SVC(gamma=\"scale\")\n     clf.fit(X, Y)\n     assert_array_equal(clf.predict([X[2]]), [1.])\n \n@@ -432,7 +434,7 @@ def test_sample_weights():\n     assert_array_equal(clf.predict([X[2]]), [2.])\n \n     # test that rescaling all samples is the same as changing C\n-    clf = svm.SVC()\n+    clf = svm.SVC(gamma=\"scale\")\n     clf.fit(X, Y)\n     dual_coef_no_weight = clf.dual_coef_\n     clf.set_params(C=100)\n@@ -470,17 +472,17 @@ def test_auto_weight():\n def test_bad_input():\n     # Test that it gives proper exception on deficient input\n     # impossible value of C\n-    assert_raises(ValueError, svm.SVC(C=-1).fit, X, Y)\n+    assert_raises(ValueError, svm.SVC(gamma='scale', C=-1).fit, X, Y)\n \n     # impossible value of nu\n-    clf = svm.NuSVC(nu=0.0)\n+    clf = svm.NuSVC(gamma='scale', nu=0.0)\n     assert_raises(ValueError, clf.fit, X, Y)\n \n     Y2 = Y[:-1]  # wrong dimensions for labels\n     assert_raises(ValueError, clf.fit, X, Y2)\n \n     # Test with arrays that are non-contiguous.\n-    for clf in (svm.SVC(), svm.LinearSVC(random_state=0)):\n+    for clf in (svm.SVC(gamma=\"scale\"), svm.LinearSVC(random_state=0)):\n         Xf = np.asfortranarray(X)\n         assert_false(Xf.flags['C_CONTIGUOUS'])\n         yf = np.ascontiguousarray(np.tile(Y, (2, 1)).T)\n@@ -495,18 +497,18 @@ def test_bad_input():\n     assert_raises(ValueError, clf.fit, X, Y)\n \n     # sample_weight bad dimensions\n-    clf = svm.SVC()\n+    clf = svm.SVC(gamma=\"scale\")\n     assert_raises(ValueError, clf.fit, X, Y, sample_weight=range(len(X) - 1))\n \n     # predict with sparse input when trained with dense\n-    clf = svm.SVC().fit(X, Y)\n+    clf = svm.SVC(gamma=\"scale\").fit(X, Y)\n     assert_raises(ValueError, clf.predict, sparse.lil_matrix(X))\n \n     Xt = np.array(X).T\n     clf.fit(np.dot(X, Xt), Y)\n     assert_raises(ValueError, clf.predict, X)\n \n-    clf = svm.SVC()\n+    clf = svm.SVC(gamma=\"scale\")\n     clf.fit(X, Y)\n     assert_raises(ValueError, clf.predict, Xt)\n \n@@ -524,7 +526,7 @@ def test_unicode_kernel():\n                                     random_seed=0)\n \n     # Test default behavior on both versions\n-    clf = svm.SVC(kernel='linear', probability=True)\n+    clf = svm.SVC(gamma='scale', kernel='linear', probability=True)\n     clf.fit(X, Y)\n     clf.predict_proba(T)\n     svm.libsvm.cross_validation(iris.data,\n@@ -811,7 +813,7 @@ def test_linearsvc_verbose():\n def test_svc_clone_with_callable_kernel():\n     # create SVM with callable linear kernel, check that results are the same\n     # as with built-in linear kernel\n-    svm_callable = svm.SVC(kernel=lambda x, y: np.dot(x, y.T),\n+    svm_callable = svm.SVC(gamma='scale', kernel=lambda x, y: np.dot(x, y.T),\n                            probability=True, random_state=0,\n                            decision_function_shape='ovr')\n     # clone for checking clonability with lambda functions..\n@@ -837,7 +839,7 @@ def test_svc_clone_with_callable_kernel():\n \n \n def test_svc_bad_kernel():\n-    svc = svm.SVC(kernel=lambda x, y: x)\n+    svc = svm.SVC(gamma='scale', kernel=lambda x, y: x)\n     assert_raises(ValueError, svc.fit, X, Y)\n \n \n@@ -850,11 +852,11 @@ def test_timeout():\n def test_unfitted():\n     X = \"foo!\"  # input validation not required when SVM not fitted\n \n-    clf = svm.SVC()\n+    clf = svm.SVC(gamma=\"scale\")\n     assert_raises_regexp(Exception, r\".*\\bSVC\\b.*\\bnot\\b.*\\bfitted\\b\",\n                          clf.predict, X)\n \n-    clf = svm.NuSVR()\n+    clf = svm.NuSVR(gamma='scale')\n     assert_raises_regexp(Exception, r\".*\\bNuSVR\\b.*\\bnot\\b.*\\bfitted\\b\",\n                          clf.predict, X)\n \n@@ -913,12 +915,12 @@ def test_hasattr_predict_proba():\n     # Method must be (un)available before or after fit, switched by\n     # `probability` param\n \n-    G = svm.SVC(probability=True)\n+    G = svm.SVC(gamma='scale', probability=True)\n     assert_true(hasattr(G, 'predict_proba'))\n     G.fit(iris.data, iris.target)\n     assert_true(hasattr(G, 'predict_proba'))\n \n-    G = svm.SVC(probability=False)\n+    G = svm.SVC(gamma='scale', probability=False)\n     assert_false(hasattr(G, 'predict_proba'))\n     G.fit(iris.data, iris.target)\n     assert_false(hasattr(G, 'predict_proba'))\n@@ -935,7 +937,7 @@ def test_decision_function_shape_two_class():\n     for n_classes in [2, 3]:\n         X, y = make_blobs(centers=n_classes, random_state=0)\n         for estimator in [svm.SVC, svm.NuSVC]:\n-            clf = OneVsRestClassifier(estimator(\n+            clf = OneVsRestClassifier(estimator(gamma='scale',\n                 decision_function_shape=\"ovr\")).fit(X, y)\n             assert_equal(len(clf.predict(X)), len(y))\n \n@@ -980,3 +982,29 @@ def test_ovr_decision_function():\n     # Test if the first point has lower decision value on every quadrant\n     # compared to the second point\n     assert_true(np.all(pred_class_deci_val[:, 0] < pred_class_deci_val[:, 1]))\n+\n+\n+def test_gamma_auto():\n+    X, y = [[0.0, 1.2], [1.0, 1.3]], [0, 1]\n+\n+    msg = (\"The default value of gamma will change from 'auto' to 'scale' in \"\n+           \"version 0.22 to account better for unscaled features. Set gamma \"\n+           \"explicitly to 'auto' or 'scale' to avoid this warning.\")\n+\n+    assert_warns_message(FutureWarning, msg,\n+                         svm.SVC().fit, X, y)\n+    assert_no_warnings(svm.SVC(kernel='linear').fit, X, y)\n+    assert_no_warnings(svm.SVC(kernel='precomputed').fit, X, y)\n+\n+\n+def test_gamma_scale():\n+    X, y = [[0.], [1.]], [0, 1]\n+\n+    clf = svm.SVC(gamma='scale')\n+    assert_no_warnings(clf.fit, X, y)\n+    assert_equal(clf._gamma, 2.)\n+\n+    # X_std ~= 1 shouldn't raise warning, for when\n+    # gamma is not explicitly set.\n+    X, y = [[1, 2], [3, 2 * np.sqrt(6) / 3 + 2]], [0, 1]\n+    assert_no_warnings(clf.fit, X, y)\ndiff --git a/sklearn/tests/test_cross_validation.py b/sklearn/tests/test_cross_validation.py\n--- a/sklearn/tests/test_cross_validation.py\n+++ b/sklearn/tests/test_cross_validation.py\n@@ -1036,7 +1036,7 @@ def test_shufflesplit_reproducible():\n \n \n def test_safe_split_with_precomputed_kernel():\n-    clf = SVC()\n+    clf = SVC(gamma=\"scale\")\n     clfp = SVC(kernel=\"precomputed\")\n \n     iris = load_iris()\ndiff --git a/sklearn/tests/test_grid_search.py b/sklearn/tests/test_grid_search.py\n--- a/sklearn/tests/test_grid_search.py\n+++ b/sklearn/tests/test_grid_search.py\n@@ -688,7 +688,7 @@ def test_predict_proba_disabled():\n     # Test predict_proba when disabled on estimator.\n     X = np.arange(20).reshape(5, -1)\n     y = [0, 0, 1, 1, 1]\n-    clf = SVC(probability=False)\n+    clf = SVC(gamma='scale', probability=False)\n     gs = GridSearchCV(clf, {}, cv=2).fit(X, y)\n     assert_false(hasattr(gs, \"predict_proba\"))\n \ndiff --git a/sklearn/tests/test_multiclass.py b/sklearn/tests/test_multiclass.py\n--- a/sklearn/tests/test_multiclass.py\n+++ b/sklearn/tests/test_multiclass.py\n@@ -179,7 +179,8 @@ def test_ovr_fit_predict_sparse():\n         assert_array_equal(pred, Y_pred_sprs.toarray())\n \n         # Test decision_function\n-        clf_sprs = OneVsRestClassifier(svm.SVC()).fit(X_train, sparse(Y_train))\n+        clf = svm.SVC(gamma=\"scale\")\n+        clf_sprs = OneVsRestClassifier(clf).fit(X_train, sparse(Y_train))\n         dec_pred = (clf_sprs.decision_function(X_test) > 0).astype(int)\n         assert_array_equal(dec_pred, clf_sprs.predict(X_test).toarray())\n \n@@ -274,7 +275,7 @@ def conduct_test(base_clf, test_predict_proba=False):\n                      Ridge(), ElasticNet()):\n         conduct_test(base_clf)\n \n-    for base_clf in (MultinomialNB(), SVC(probability=True),\n+    for base_clf in (MultinomialNB(), SVC(gamma='scale', probability=True),\n                      LogisticRegression()):\n         conduct_test(base_clf, test_predict_proba=True)\n \n@@ -298,7 +299,7 @@ def test_ovr_multilabel():\n \n \n def test_ovr_fit_predict_svc():\n-    ovr = OneVsRestClassifier(svm.SVC())\n+    ovr = OneVsRestClassifier(svm.SVC(gamma=\"scale\"))\n     ovr.fit(iris.data, iris.target)\n     assert_equal(len(ovr.estimators_), 3)\n     assert_greater(ovr.score(iris.data, iris.target), .9)\n@@ -343,18 +344,20 @@ def test_ovr_multilabel_predict_proba():\n         clf = OneVsRestClassifier(base_clf).fit(X_train, Y_train)\n \n         # Decision function only estimator.\n-        decision_only = OneVsRestClassifier(svm.SVR()).fit(X_train, Y_train)\n+        decision_only = OneVsRestClassifier(svm.SVR(gamma='scale')\n+                                            ).fit(X_train, Y_train)\n         assert_false(hasattr(decision_only, 'predict_proba'))\n \n         # Estimator with predict_proba disabled, depending on parameters.\n-        decision_only = OneVsRestClassifier(svm.SVC(probability=False))\n+        decision_only = OneVsRestClassifier(svm.SVC(gamma='scale',\n+                                                    probability=False))\n         assert_false(hasattr(decision_only, 'predict_proba'))\n         decision_only.fit(X_train, Y_train)\n         assert_false(hasattr(decision_only, 'predict_proba'))\n         assert_true(hasattr(decision_only, 'decision_function'))\n \n         # Estimator which can get predict_proba enabled after fitting\n-        gs = GridSearchCV(svm.SVC(probability=False),\n+        gs = GridSearchCV(svm.SVC(gamma='scale', probability=False),\n                           param_grid={'probability': [True]})\n         proba_after_fit = OneVsRestClassifier(gs)\n         assert_false(hasattr(proba_after_fit, 'predict_proba'))\n@@ -378,7 +381,8 @@ def test_ovr_single_label_predict_proba():\n     clf = OneVsRestClassifier(base_clf).fit(X_train, Y_train)\n \n     # Decision function only estimator.\n-    decision_only = OneVsRestClassifier(svm.SVR()).fit(X_train, Y_train)\n+    decision_only = OneVsRestClassifier(svm.SVR(gamma='scale')\n+                                        ).fit(X_train, Y_train)\n     assert_false(hasattr(decision_only, 'predict_proba'))\n \n     Y_pred = clf.predict(X_test)\n@@ -401,7 +405,7 @@ def test_ovr_multilabel_decision_function():\n                                                    random_state=0)\n     X_train, Y_train = X[:80], Y[:80]\n     X_test = X[80:]\n-    clf = OneVsRestClassifier(svm.SVC()).fit(X_train, Y_train)\n+    clf = OneVsRestClassifier(svm.SVC(gamma=\"scale\")).fit(X_train, Y_train)\n     assert_array_equal((clf.decision_function(X_test) > 0).astype(int),\n                        clf.predict(X_test))\n \n@@ -412,7 +416,7 @@ def test_ovr_single_label_decision_function():\n                                         random_state=0)\n     X_train, Y_train = X[:80], Y[:80]\n     X_test = X[80:]\n-    clf = OneVsRestClassifier(svm.SVC()).fit(X_train, Y_train)\n+    clf = OneVsRestClassifier(svm.SVC(gamma=\"scale\")).fit(X_train, Y_train)\n     assert_array_equal(clf.decision_function(X_test).ravel() > 0,\n                        clf.predict(X_test))\n \ndiff --git a/sklearn/tests/test_pipeline.py b/sklearn/tests/test_pipeline.py\n--- a/sklearn/tests/test_pipeline.py\n+++ b/sklearn/tests/test_pipeline.py\n@@ -318,7 +318,7 @@ def test_pipeline_methods_pca_svm():\n     X = iris.data\n     y = iris.target\n     # Test with PCA + SVC\n-    clf = SVC(probability=True, random_state=0)\n+    clf = SVC(gamma='scale', probability=True, random_state=0)\n     pca = PCA(svd_solver='full', n_components='mle', whiten=True)\n     pipe = Pipeline([('pca', pca), ('svc', clf)])\n     pipe.fit(X, y)\n@@ -337,7 +337,8 @@ def test_pipeline_methods_preprocessing_svm():\n     n_classes = len(np.unique(y))\n     scaler = StandardScaler()\n     pca = PCA(n_components=2, svd_solver='randomized', whiten=True)\n-    clf = SVC(probability=True, random_state=0, decision_function_shape='ovr')\n+    clf = SVC(gamma='scale', probability=True, random_state=0,\n+              decision_function_shape='ovr')\n \n     for preprocessing in [scaler, pca]:\n         pipe = Pipeline([('preprocess', preprocessing), ('svc', clf)])\n@@ -903,8 +904,8 @@ def test_pipeline_wrong_memory():\n     y = iris.target\n     # Define memory as an integer\n     memory = 1\n-    cached_pipe = Pipeline([('transf', DummyTransf()), ('svc', SVC())],\n-                           memory=memory)\n+    cached_pipe = Pipeline([('transf', DummyTransf()),\n+                            ('svc', SVC())], memory=memory)\n     assert_raises_regex(ValueError, \"'memory' should be None, a string or\"\n                         \" have the same interface as \"\n                         \"sklearn.externals.joblib.Memory.\"\n@@ -942,7 +943,7 @@ def test_pipeline_memory():\n     try:\n         memory = Memory(cachedir=cachedir, verbose=10)\n         # Test with Transformer + SVC\n-        clf = SVC(probability=True, random_state=0)\n+        clf = SVC(gamma='scale', probability=True, random_state=0)\n         transf = DummyTransf()\n         pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n         cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n@@ -976,7 +977,7 @@ def test_pipeline_memory():\n         assert_equal(ts, cached_pipe.named_steps['transf'].timestamp_)\n         # Create a new pipeline with cloned estimators\n         # Check that even changing the name step does not affect the cache hit\n-        clf_2 = SVC(probability=True, random_state=0)\n+        clf_2 = SVC(gamma='scale', probability=True, random_state=0)\n         transf_2 = DummyTransf()\n         cached_pipe_2 = Pipeline([('transf_2', transf_2), ('svc', clf_2)],\n                                  memory=memory)\ndiff --git a/sklearn/utils/tests/test_validation.py b/sklearn/utils/tests/test_validation.py\n--- a/sklearn/utils/tests/test_validation.py\n+++ b/sklearn/utils/tests/test_validation.py\n@@ -599,7 +599,7 @@ def test_check_is_fitted():\n     assert_raises(TypeError, check_is_fitted, \"SVR\", \"support_\")\n \n     ard = ARDRegression()\n-    svr = SVR()\n+    svr = SVR(gamma='scale')\n \n     try:\n         assert_raises(NotFittedError, check_is_fitted, ard, \"coef_\")\n",
  "problem_statement": "[WIP] gamma=auto in SVC #8361\n<!--\r\nThanks for contributing a pull request! Please ensure you have taken a look at\r\nthe contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#Contributing-Pull-Requests\r\n-->\r\n#### Reference Issue\r\nAddresses #8361 \r\n\r\n#### What does this implement/fix? Explain your changes.\r\nDeprecates the default SVC gamma parameter value of \"auto\", which is calculated as 1 / n_features, and introduces \"scale\", which is calculated as 1 / (n_features * X.std()).\r\n\r\n#### Any other comments?\r\nCould not run nosetests due to problems with Conda environent. There are potentially other occurrences of SVC() that need to be updated to SVC(gamma=\"scale\") to avoid Deprecation Warnings associated with SVC(gamma = \"auto\"). Submitting pull request to locate errors.\r\n\r\n<!--\r\nPlease be aware that we are a loose team of volunteers so patience is\r\nnecessary; assistance handling other issues is very welcome. We value\r\nall user contributions, no matter how minor they are. If we are slow to\r\nreview, either the pull request needs some benchmarking, tinkering,\r\nconvincing, etc. or more likely the reviewers are simply busy. In either\r\ncase, we ask for your understanding during the review process.\r\nFor more information, see our FAQ on this topic:\r\nhttp://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.\r\n\r\nThanks for contributing!\r\n-->\r\n\n",
  "hints_text": "",
  "created_at": "2017-12-16T09:30:22Z",
  "version": "0.20",
  "FAIL_TO_PASS": "[\"sklearn/ensemble/tests/test_bagging.py::test_classification\", \"sklearn/ensemble/tests/test_bagging.py::test_sparse_classification\", \"sklearn/ensemble/tests/test_bagging.py::test_regression\", \"sklearn/ensemble/tests/test_bagging.py::test_sparse_regression\", \"sklearn/ensemble/tests/test_bagging.py::test_oob_score_classification\", \"sklearn/ensemble/tests/test_bagging.py::test_parallel_classification\", \"sklearn/ensemble/tests/test_bagging.py::test_gridsearch\", \"sklearn/ensemble/tests/test_bagging.py::test_base_estimator\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_sample_weight\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_base_estimator\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_sparse_classification\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_sparse_regression\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_cv_results\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_cv_results_multimetric\", \"sklearn/model_selection/tests/test_search.py::test_search_cv_results_rank_tie_breaking\", \"sklearn/model_selection/tests/test_search.py::test_predict_proba_disabled\", \"sklearn/model_selection/tests/test_search.py::test_deprecated_grid_search_iid\", \"sklearn/model_selection/tests/test_validation.py::test_cross_validate_invalid_scoring_param\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_precomputed\", \"sklearn/preprocessing/tests/test_data.py::test_cv_pipeline_precomputed\", \"sklearn/svm/tests/test_sparse.py::test_svc\", \"sklearn/svm/tests/test_sparse.py::test_svc_with_custom_kernel\", \"sklearn/svm/tests/test_sparse.py::test_svc_iris\", \"sklearn/svm/tests/test_sparse.py::test_error\", \"sklearn/svm/tests/test_sparse.py::test_weight\", \"sklearn/svm/tests/test_sparse.py::test_sample_weights\", \"sklearn/svm/tests/test_sparse.py::test_sparse_oneclasssvm\", \"sklearn/svm/tests/test_sparse.py::test_sparse_svc_clone_with_callable_kernel\", \"sklearn/svm/tests/test_sparse.py::test_timeout\", \"sklearn/svm/tests/test_sparse.py::test_consistent_proba\", \"sklearn/svm/tests/test_svm.py::test_libsvm_iris\", \"sklearn/svm/tests/test_svm.py::test_precomputed\", \"sklearn/svm/tests/test_svm.py::test_svr\", \"sklearn/svm/tests/test_svm.py::test_svr_errors\", \"sklearn/svm/tests/test_svm.py::test_oneclass\", \"sklearn/svm/tests/test_svm.py::test_probability\", \"sklearn/svm/tests/test_svm.py::test_weight\", \"sklearn/svm/tests/test_svm.py::test_sample_weights\", \"sklearn/svm/tests/test_svm.py::test_bad_input\", \"sklearn/svm/tests/test_svm.py::test_unicode_kernel\", \"sklearn/svm/tests/test_svm.py::test_svc_clone_with_callable_kernel\", \"sklearn/svm/tests/test_svm.py::test_hasattr_predict_proba\", \"sklearn/svm/tests/test_svm.py::test_decision_function_shape_two_class\", \"sklearn/svm/tests/test_svm.py::test_gamma_auto\", \"sklearn/svm/tests/test_svm.py::test_gamma_scale\", \"sklearn/tests/test_grid_search.py::test_predict_proba_disabled\", \"sklearn/tests/test_multiclass.py::test_ovr_fit_predict_sparse\", \"sklearn/tests/test_multiclass.py::test_ovr_binary\", \"sklearn/tests/test_multiclass.py::test_ovr_fit_predict_svc\", \"sklearn/tests/test_multiclass.py::test_ovr_multilabel_predict_proba\", \"sklearn/tests/test_multiclass.py::test_ovr_single_label_predict_proba\", \"sklearn/tests/test_multiclass.py::test_ovr_multilabel_decision_function\", \"sklearn/tests/test_multiclass.py::test_ovr_single_label_decision_function\", \"sklearn/tests/test_pipeline.py::test_pipeline_methods_pca_svm\", \"sklearn/tests/test_pipeline.py::test_pipeline_methods_preprocessing_svm\", \"sklearn/tests/test_pipeline.py::test_pipeline_memory\", \"sklearn/utils/tests/test_validation.py::test_check_is_fitted\"]",
  "PASS_TO_PASS": "[\"sklearn/ensemble/tests/test_bagging.py::test_bootstrap_samples\", \"sklearn/ensemble/tests/test_bagging.py::test_bootstrap_features\", \"sklearn/ensemble/tests/test_bagging.py::test_probability\", \"sklearn/ensemble/tests/test_bagging.py::test_oob_score_regression\", \"sklearn/ensemble/tests/test_bagging.py::test_single_estimator\", \"sklearn/ensemble/tests/test_bagging.py::test_error\", \"sklearn/ensemble/tests/test_bagging.py::test_parallel_regression\", \"sklearn/ensemble/tests/test_bagging.py::test_bagging_with_pipeline\", \"sklearn/ensemble/tests/test_bagging.py::test_bagging_sample_weight_unsupported_but_passed\", \"sklearn/ensemble/tests/test_bagging.py::test_warm_start\", \"sklearn/ensemble/tests/test_bagging.py::test_warm_start_smaller_n_estimators\", \"sklearn/ensemble/tests/test_bagging.py::test_warm_start_equal_n_estimators\", \"sklearn/ensemble/tests/test_bagging.py::test_warm_start_equivalence\", \"sklearn/ensemble/tests/test_bagging.py::test_warm_start_with_oob_score_fails\", \"sklearn/ensemble/tests/test_bagging.py::test_oob_score_removed_on_warm_start\", \"sklearn/ensemble/tests/test_bagging.py::test_oob_score_consistency\", \"sklearn/ensemble/tests/test_bagging.py::test_estimators_samples\", \"sklearn/ensemble/tests/test_bagging.py::test_max_samples_consistency\", \"sklearn/ensemble/tests/test_bagging.py::test_set_oob_score_label_encoding\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_estimator_init\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_predictproba_hardvoting\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_notfitted\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_majority_label_iris\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_tie_situation\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_weights_iris\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_predict_on_toy_problem\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_predict_proba_on_toy_problem\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_multilabel\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_gridsearch\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_parallel_fit\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_sample_weight_kwargs\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_set_params\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_set_estimator_none\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_estimator_weights_format\", \"sklearn/ensemble/tests/test_voting_classifier.py::test_transform\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_samme_proba\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_oneclass_adaboost_proba\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_classification_toy\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_regression_toy\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_iris\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_boston\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_staged_predict\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_gridsearch\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_pickle\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_importances\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_error\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_sample_weight_missing\", \"sklearn/ensemble/tests/test_weight_boosting.py::test_sample_weight_adaboost_regressor\", \"sklearn/model_selection/tests/test_search.py::test_parameter_grid\", \"sklearn/model_selection/tests/test_search.py::test_grid_search\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_with_fit_params\", \"sklearn/model_selection/tests/test_search.py::test_random_search_with_fit_params\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_fit_params_deprecation\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_fit_params_two_places\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_no_score\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_score_method\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_groups\", \"sklearn/model_selection/tests/test_search.py::test_return_train_score_warn\", \"sklearn/model_selection/tests/test_search.py::test_classes__property\", \"sklearn/model_selection/tests/test_search.py::test_trivial_cv_results_attr\", \"sklearn/model_selection/tests/test_search.py::test_no_refit\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_error\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_one_grid_point\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_when_param_grid_includes_range\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_bad_param_grid\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_sparse\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_sparse_scoring\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_precomputed_kernel\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_precomputed_kernel_error_nonsquare\", \"sklearn/model_selection/tests/test_search.py::test_refit\", \"sklearn/model_selection/tests/test_search.py::test_gridsearch_nd\", \"sklearn/model_selection/tests/test_search.py::test_X_as_list\", \"sklearn/model_selection/tests/test_search.py::test_y_as_list\", \"sklearn/model_selection/tests/test_search.py::test_pandas_input\", \"sklearn/model_selection/tests/test_search.py::test_unsupervised_grid_search\", \"sklearn/model_selection/tests/test_search.py::test_gridsearch_no_predict\", \"sklearn/model_selection/tests/test_search.py::test_param_sampler\", \"sklearn/model_selection/tests/test_search.py::test_random_search_cv_results\", \"sklearn/model_selection/tests/test_search.py::test_search_iid_param\", \"sklearn/model_selection/tests/test_search.py::test_random_search_cv_results_multimetric\", \"sklearn/model_selection/tests/test_search.py::test_search_cv_results_none_param\", \"sklearn/model_selection/tests/test_search.py::test_search_cv_timing\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_correct_score_results\", \"sklearn/model_selection/tests/test_search.py::test_fit_grid_point\", \"sklearn/model_selection/tests/test_search.py::test_pickle\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_with_multioutput_data\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_allows_nans\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier_raise\", \"sklearn/model_selection/tests/test_search.py::test_parameters_sampler_replacement\", \"sklearn/model_selection/tests/test_search.py::test_stochastic_gradient_loss_param\", \"sklearn/model_selection/tests/test_search.py::test_search_train_scores_set_to_false\", \"sklearn/model_selection/tests/test_search.py::test_grid_search_cv_splits_consistency\", \"sklearn/model_selection/tests/test_search.py::test_transform_inverse_transform_round_trip\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score\", \"sklearn/model_selection/tests/test_validation.py::test_cross_validate_return_train_score_warn\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_predict_groups\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_pandas\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_mask\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_fit_params\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_score_func\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_errors\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_with_score_func_classification\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_with_score_func_regression\", \"sklearn/model_selection/tests/test_validation.py::test_permutation_score\", \"sklearn/model_selection/tests/test_validation.py::test_permutation_test_score_allow_nans\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_allow_nans\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_multilabel\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_decision_function_shape\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_predict_proba_shape\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_predict_log_proba_shape\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_input_types\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_pandas\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_score_sparse_fit_params\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_unsupervised\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_verbose\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_incremental_learning_not_possible\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_incremental_learning\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_incremental_learning_unsupervised\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_batch_and_incremental_learning_are_equal\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_n_sample_range_out_of_bounds\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_remove_duplicate_sample_sizes\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_with_boolean_indices\", \"sklearn/model_selection/tests/test_validation.py::test_learning_curve_with_shuffle\", \"sklearn/model_selection/tests/test_validation.py::test_validation_curve\", \"sklearn/model_selection/tests/test_validation.py::test_validation_curve_clone_estimator\", \"sklearn/model_selection/tests/test_validation.py::test_validation_curve_cv_splits_consistency\", \"sklearn/model_selection/tests/test_validation.py::test_check_is_permutation\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_sparse_prediction\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_with_method\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_method_checking\", \"sklearn/model_selection/tests/test_validation.py::test_gridsearchcv_cross_val_predict_with_method\", \"sklearn/model_selection/tests/test_validation.py::test_cross_val_predict_class_subset\", \"sklearn/model_selection/tests/test_validation.py::test_score_memmap\", \"sklearn/model_selection/tests/test_validation.py::test_permutation_test_score_pandas\", \"sklearn/model_selection/tests/test_validation.py::test_fit_and_score\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_feature_names\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[1-True-False-int]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[2-True-False-int]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[2-True-False-float32]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[2-True-False-float64]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[3-False-False-float64]\", \"sklearn/preprocessing/tests/test_data.py::test_polynomial_features_sparse_X[3-False-True-float64]\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_scale_1d\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_numerical_stability\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_2d_arrays\", \"sklearn/preprocessing/tests/test_data.py::test_handle_zeros_in_scale\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_partial_fit_numerical_stability\", \"sklearn/preprocessing/tests/test_data.py::test_partial_fit_sparse_input\", \"sklearn/preprocessing/tests/test_data.py::test_standard_scaler_trasform_with_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_iris\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_minmax_scale_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_min_max_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_without_centering\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_int\", \"sklearn/preprocessing/tests/test_data.py::test_scaler_without_copy\", \"sklearn/preprocessing/tests/test_data.py::test_scale_sparse_with_mean_raise_exception\", \"sklearn/preprocessing/tests/test_data.py::test_scale_input_finiteness_validation\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_2d_arrays\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_transform_one_row_csr\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_iris\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_iris_quantiles\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_iris\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_check_error\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_sparse_ignore_zeros\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_dense_toy\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_subsampling\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_sparse_toy\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_bounds\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_and_inverse\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_invalid_range\", \"sklearn/preprocessing/tests/test_data.py::test_scale_function_without_centering\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scale_axis1\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scale_1d_array\", \"sklearn/preprocessing/tests/test_data.py::test_robust_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_zero_variance_features\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_large_negative_value\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_transform_one_row_csr\", \"sklearn/preprocessing/tests/test_data.py::test_warning_scaling_integers\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_1d\", \"sklearn/preprocessing/tests/test_data.py::test_maxabs_scaler_partial_fit\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_l1\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_l2\", \"sklearn/preprocessing/tests/test_data.py::test_normalizer_max\", \"sklearn/preprocessing/tests/test_data.py::test_normalize\", \"sklearn/preprocessing/tests/test_data.py::test_binarizer\", \"sklearn/preprocessing/tests/test_data.py::test_center_kernel\", \"sklearn/preprocessing/tests/test_data.py::test_fit_transform\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_coo\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_csc\", \"sklearn/preprocessing/tests/test_data.py::test_add_dummy_feature_csr\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_sparse\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_dense\", \"sklearn/preprocessing/tests/test_data.py::test_transform_selected\", \"sklearn/preprocessing/tests/test_data.py::test_transform_selected_copy_arg\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_categorical_features\", \"sklearn/preprocessing/tests/test_data.py::test_one_hot_encoder_unknown_transform\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_onehot\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_onehot_inverse\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_handle_unknown\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_categories\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_specified_categories\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_pandas\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_ordinal\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_ordinal_inverse\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_dtypes\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_dtypes_pandas\", \"sklearn/preprocessing/tests/test_data.py::test_categorical_encoder_warning\", \"sklearn/preprocessing/tests/test_data.py::test_fit_cold_start\", \"sklearn/preprocessing/tests/test_data.py::test_quantile_transform_valid_axis\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_notfitted\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_1d\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_2d\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_strictly_positive_exception\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_shape_exception\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_method_exception\", \"sklearn/preprocessing/tests/test_data.py::test_power_transformer_lambda_zero\", \"sklearn/svm/tests/test_sparse.py::test_sparse_decision_function\", \"sklearn/svm/tests/test_sparse.py::test_linearsvc\", \"sklearn/svm/tests/test_sparse.py::test_linearsvc_iris\", \"sklearn/svm/tests/test_sparse.py::test_sparse_liblinear_intercept_handling\", \"sklearn/svm/tests/test_sparse.py::test_sparse_realdata\", \"sklearn/svm/tests/test_svm.py::test_libsvm_parameters\", \"sklearn/svm/tests/test_svm.py::test_linearsvr\", \"sklearn/svm/tests/test_svm.py::test_linearsvr_fit_sampleweight\", \"sklearn/svm/tests/test_svm.py::test_oneclass_decision_function\", \"sklearn/svm/tests/test_svm.py::test_oneclass_score_samples\", \"sklearn/svm/tests/test_svm.py::test_tweak_params\", \"sklearn/svm/tests/test_svm.py::test_decision_function\", \"sklearn/svm/tests/test_svm.py::test_decision_function_shape\", \"sklearn/svm/tests/test_svm.py::test_svr_predict\", \"sklearn/svm/tests/test_svm.py::test_auto_weight\", \"sklearn/svm/tests/test_svm.py::test_sparse_precomputed\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_parameters\", \"sklearn/svm/tests/test_svm.py::test_linearsvx_loss_penalty_deprecations\", \"sklearn/svm/tests/test_svm.py::test_linear_svx_uppercase_loss_penality_raises_error\", \"sklearn/svm/tests/test_svm.py::test_linearsvc\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_crammer_singer\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_fit_sampleweight\", \"sklearn/svm/tests/test_svm.py::test_crammer_singer_binary\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_iris\", \"sklearn/svm/tests/test_svm.py::test_dense_liblinear_intercept_handling\", \"sklearn/svm/tests/test_svm.py::test_liblinear_set_coef\", \"sklearn/svm/tests/test_svm.py::test_immutable_coef_property\", \"sklearn/svm/tests/test_svm.py::test_linearsvc_verbose\", \"sklearn/svm/tests/test_svm.py::test_svc_bad_kernel\", \"sklearn/svm/tests/test_svm.py::test_timeout\", \"sklearn/svm/tests/test_svm.py::test_unfitted\", \"sklearn/svm/tests/test_svm.py::test_consistent_proba\", \"sklearn/svm/tests/test_svm.py::test_linear_svc_convergence_warnings\", \"sklearn/svm/tests/test_svm.py::test_svr_coef_sign\", \"sklearn/svm/tests/test_svm.py::test_linear_svc_intercept_scaling\", \"sklearn/svm/tests/test_svm.py::test_lsvc_intercept_scaling_zero\", \"sklearn/svm/tests/test_svm.py::test_ovr_decision_function\", \"sklearn/tests/test_cross_validation.py::test_kfold_valueerrors\", \"sklearn/tests/test_cross_validation.py::test_kfold_indices\", \"sklearn/tests/test_cross_validation.py::test_kfold_no_shuffle\", \"sklearn/tests/test_cross_validation.py::test_stratified_kfold_no_shuffle\", \"sklearn/tests/test_cross_validation.py::test_stratified_kfold_ratios\", \"sklearn/tests/test_cross_validation.py::test_kfold_balance\", \"sklearn/tests/test_cross_validation.py::test_stratifiedkfold_balance\", \"sklearn/tests/test_cross_validation.py::test_shuffle_kfold\", \"sklearn/tests/test_cross_validation.py::test_shuffle_stratifiedkfold\", \"sklearn/tests/test_cross_validation.py::test_kfold_can_detect_dependent_samples_on_digits\", \"sklearn/tests/test_cross_validation.py::test_label_kfold\", \"sklearn/tests/test_cross_validation.py::test_shuffle_split\", \"sklearn/tests/test_cross_validation.py::test_stratified_shuffle_split_init\", \"sklearn/tests/test_cross_validation.py::test_stratified_shuffle_split_iter\", \"sklearn/tests/test_cross_validation.py::test_stratified_shuffle_split_even\", \"sklearn/tests/test_cross_validation.py::test_stratified_shuffle_split_overlap_train_test_bug\", \"sklearn/tests/test_cross_validation.py::test_predefinedsplit_with_kfold_split\", \"sklearn/tests/test_cross_validation.py::test_label_shuffle_split\", \"sklearn/tests/test_cross_validation.py::test_leave_label_out_changing_labels\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_pandas\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_mask\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_precomputed\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_fit_params\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_score_func\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_errors\", \"sklearn/tests/test_cross_validation.py::test_train_test_split_errors\", \"sklearn/tests/test_cross_validation.py::test_train_test_split\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_with_score_func_classification\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_with_score_func_regression\", \"sklearn/tests/test_cross_validation.py::test_permutation_score\", \"sklearn/tests/test_cross_validation.py::test_cross_val_generator_with_indices\", \"sklearn/tests/test_cross_validation.py::test_cross_val_generator_with_default_indices\", \"sklearn/tests/test_cross_validation.py::test_shufflesplit_errors\", \"sklearn/tests/test_cross_validation.py::test_shufflesplit_reproducible\", \"sklearn/tests/test_cross_validation.py::test_safe_split_with_precomputed_kernel\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_allow_nans\", \"sklearn/tests/test_cross_validation.py::test_train_test_split_allow_nans\", \"sklearn/tests/test_cross_validation.py::test_permutation_test_score_allow_nans\", \"sklearn/tests/test_cross_validation.py::test_check_cv_return_types\", \"sklearn/tests/test_cross_validation.py::test_cross_val_score_multilabel\", \"sklearn/tests/test_cross_validation.py::test_cross_val_predict\", \"sklearn/tests/test_cross_validation.py::test_cross_val_predict_input_types\", \"sklearn/tests/test_cross_validation.py::test_cross_val_predict_pandas\", \"sklearn/tests/test_cross_validation.py::test_sparse_fit_params\", \"sklearn/tests/test_cross_validation.py::test_check_is_partition\", \"sklearn/tests/test_cross_validation.py::test_cross_val_predict_sparse_prediction\", \"sklearn/tests/test_grid_search.py::test_parameter_grid\", \"sklearn/tests/test_grid_search.py::test_grid_search\", \"sklearn/tests/test_grid_search.py::test_transform_inverse_transform_round_trip\", \"sklearn/tests/test_grid_search.py::test_grid_search_no_score\", \"sklearn/tests/test_grid_search.py::test_grid_search_score_method\", \"sklearn/tests/test_grid_search.py::test_trivial_grid_scores\", \"sklearn/tests/test_grid_search.py::test_no_refit\", \"sklearn/tests/test_grid_search.py::test_grid_search_error\", \"sklearn/tests/test_grid_search.py::test_grid_search_iid\", \"sklearn/tests/test_grid_search.py::test_grid_search_one_grid_point\", \"sklearn/tests/test_grid_search.py::test_grid_search_bad_param_grid\", \"sklearn/tests/test_grid_search.py::test_grid_search_sparse\", \"sklearn/tests/test_grid_search.py::test_grid_search_sparse_scoring\", \"sklearn/tests/test_grid_search.py::test_grid_search_precomputed_kernel\", \"sklearn/tests/test_grid_search.py::test_grid_search_precomputed_kernel_error_nonsquare\", \"sklearn/tests/test_grid_search.py::test_grid_search_precomputed_kernel_error_kernel_function\", \"sklearn/tests/test_grid_search.py::test_refit\", \"sklearn/tests/test_grid_search.py::test_gridsearch_nd\", \"sklearn/tests/test_grid_search.py::test_X_as_list\", \"sklearn/tests/test_grid_search.py::test_y_as_list\", \"sklearn/tests/test_grid_search.py::test_pandas_input\", \"sklearn/tests/test_grid_search.py::test_unsupervised_grid_search\", \"sklearn/tests/test_grid_search.py::test_gridsearch_no_predict\", \"sklearn/tests/test_grid_search.py::test_param_sampler\", \"sklearn/tests/test_grid_search.py::test_randomized_search_grid_scores\", \"sklearn/tests/test_grid_search.py::test_grid_search_score_consistency\", \"sklearn/tests/test_grid_search.py::test_pickle\", \"sklearn/tests/test_grid_search.py::test_grid_search_with_multioutput_data\", \"sklearn/tests/test_grid_search.py::test_grid_search_allows_nans\", \"sklearn/tests/test_grid_search.py::test_grid_search_failing_classifier\", \"sklearn/tests/test_grid_search.py::test_grid_search_failing_classifier_raise\", \"sklearn/tests/test_grid_search.py::test_parameters_sampler_replacement\", \"sklearn/tests/test_grid_search.py::test_classes__property\", \"sklearn/tests/test_multiclass.py::test_ovr_exceptions\", \"sklearn/tests/test_multiclass.py::test_check_classification_targets\", \"sklearn/tests/test_multiclass.py::test_ovr_fit_predict\", \"sklearn/tests/test_multiclass.py::test_ovr_partial_fit\", \"sklearn/tests/test_multiclass.py::test_ovr_partial_fit_exceptions\", \"sklearn/tests/test_multiclass.py::test_ovr_ovo_regressor\", \"sklearn/tests/test_multiclass.py::test_ovr_always_present\", \"sklearn/tests/test_multiclass.py::test_ovr_multiclass\", \"sklearn/tests/test_multiclass.py::test_ovr_multilabel\", \"sklearn/tests/test_multiclass.py::test_ovr_multilabel_dataset\", \"sklearn/tests/test_multiclass.py::test_ovr_gridsearch\", \"sklearn/tests/test_multiclass.py::test_ovr_pipeline\", \"sklearn/tests/test_multiclass.py::test_ovr_coef_\", \"sklearn/tests/test_multiclass.py::test_ovr_coef_exceptions\", \"sklearn/tests/test_multiclass.py::test_ovo_exceptions\", \"sklearn/tests/test_multiclass.py::test_ovo_fit_on_list\", \"sklearn/tests/test_multiclass.py::test_ovo_fit_predict\", \"sklearn/tests/test_multiclass.py::test_ovo_partial_fit_predict\", \"sklearn/tests/test_multiclass.py::test_ovo_decision_function\", \"sklearn/tests/test_multiclass.py::test_ovo_gridsearch\", \"sklearn/tests/test_multiclass.py::test_ovo_ties\", \"sklearn/tests/test_multiclass.py::test_ovo_ties2\", \"sklearn/tests/test_multiclass.py::test_ovo_string_y\", \"sklearn/tests/test_multiclass.py::test_ovo_one_class\", \"sklearn/tests/test_multiclass.py::test_ovo_float_y\", \"sklearn/tests/test_multiclass.py::test_ecoc_exceptions\", \"sklearn/tests/test_multiclass.py::test_ecoc_fit_predict\", \"sklearn/tests/test_multiclass.py::test_ecoc_gridsearch\", \"sklearn/tests/test_multiclass.py::test_ecoc_float_y\", \"sklearn/tests/test_multiclass.py::test_pairwise_indices\", \"sklearn/tests/test_multiclass.py::test_pairwise_attribute\", \"sklearn/tests/test_multiclass.py::test_pairwise_cross_val_score\", \"sklearn/tests/test_pipeline.py::test_pipeline_init\", \"sklearn/tests/test_pipeline.py::test_pipeline_init_tuple\", \"sklearn/tests/test_pipeline.py::test_pipeline_methods_anova\", \"sklearn/tests/test_pipeline.py::test_pipeline_fit_params\", \"sklearn/tests/test_pipeline.py::test_pipeline_sample_weight_supported\", \"sklearn/tests/test_pipeline.py::test_pipeline_sample_weight_unsupported\", \"sklearn/tests/test_pipeline.py::test_pipeline_raise_set_params_error\", \"sklearn/tests/test_pipeline.py::test_fit_predict_on_pipeline\", \"sklearn/tests/test_pipeline.py::test_fit_predict_on_pipeline_without_fit_predict\", \"sklearn/tests/test_pipeline.py::test_fit_predict_with_intermediate_fit_params\", \"sklearn/tests/test_pipeline.py::test_predict_with_predict_params\", \"sklearn/tests/test_pipeline.py::test_feature_union\", \"sklearn/tests/test_pipeline.py::test_make_union\", \"sklearn/tests/test_pipeline.py::test_make_union_kwargs\", \"sklearn/tests/test_pipeline.py::test_pipeline_transform\", \"sklearn/tests/test_pipeline.py::test_pipeline_fit_transform\", \"sklearn/tests/test_pipeline.py::test_set_pipeline_steps\", \"sklearn/tests/test_pipeline.py::test_pipeline_named_steps\", \"sklearn/tests/test_pipeline.py::test_set_pipeline_step_none\", \"sklearn/tests/test_pipeline.py::test_pipeline_ducktyping\", \"sklearn/tests/test_pipeline.py::test_make_pipeline\", \"sklearn/tests/test_pipeline.py::test_feature_union_weights\", \"sklearn/tests/test_pipeline.py::test_feature_union_parallel\", \"sklearn/tests/test_pipeline.py::test_feature_union_feature_names\", \"sklearn/tests/test_pipeline.py::test_classes_property\", \"sklearn/tests/test_pipeline.py::test_set_feature_union_steps\", \"sklearn/tests/test_pipeline.py::test_set_feature_union_step_none\", \"sklearn/tests/test_pipeline.py::test_step_name_validation\", \"sklearn/tests/test_pipeline.py::test_set_params_nested_pipeline\", \"sklearn/tests/test_pipeline.py::test_pipeline_wrong_memory\", \"sklearn/tests/test_pipeline.py::test_pipeline_with_cache_attribute\", \"sklearn/tests/test_pipeline.py::test_make_pipeline_memory\", \"sklearn/utils/tests/test_validation.py::test_as_float_array\", \"sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X0]\", \"sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X1]\", \"sklearn/utils/tests/test_validation.py::test_np_matrix\", \"sklearn/utils/tests/test_validation.py::test_memmap\", \"sklearn/utils/tests/test_validation.py::test_ordering\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-inf-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-allow-nan]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-inf-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-allow-nan]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array\", \"sklearn/utils/tests/test_validation.py::test_check_array_pandas_dtype_object_conversion\", \"sklearn/utils/tests/test_validation.py::test_check_array_on_mock_dataframe\", \"sklearn/utils/tests/test_validation.py::test_check_array_dtype_stability\", \"sklearn/utils/tests/test_validation.py::test_check_array_dtype_warning\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_type_exception\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_no_exception\", \"sklearn/utils/tests/test_validation.py::test_check_array_min_samples_and_features_messages\", \"sklearn/utils/tests/test_validation.py::test_check_array_complex_data_error\", \"sklearn/utils/tests/test_validation.py::test_has_fit_parameter\", \"sklearn/utils/tests/test_validation.py::test_check_symmetric\", \"sklearn/utils/tests/test_validation.py::test_check_consistent_length\", \"sklearn/utils/tests/test_validation.py::test_check_dataframe_fit_attribute\", \"sklearn/utils/tests/test_validation.py::test_suppress_validation\", \"sklearn/utils/tests/test_validation.py::test_check_memory\"]",
  "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.949446",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}