{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-13641",
  "base_commit": "badaa153e67ffa56fb1a413b3b7b5b8507024291",
  "patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -31,6 +31,7 @@\n from ..utils.validation import check_is_fitted, check_array, FLOAT_DTYPES\n from ..utils import _IS_32BIT\n from ..utils.fixes import _astype_copy_false\n+from ..exceptions import ChangedBehaviorWarning\n \n \n __all__ = ['HashingVectorizer',\n@@ -304,10 +305,34 @@ def _check_stop_words_consistency(self, stop_words, preprocess, tokenize):\n             self._stop_words_id = id(self.stop_words)\n             return 'error'\n \n+    def _validate_custom_analyzer(self):\n+        # This is to check if the given custom analyzer expects file or a\n+        # filename instead of data.\n+        # Behavior changed in v0.21, function could be removed in v0.23\n+        import tempfile\n+        with tempfile.NamedTemporaryFile() as f:\n+            fname = f.name\n+        # now we're sure fname doesn't exist\n+\n+        msg = (\"Since v0.21, vectorizers pass the data to the custom analyzer \"\n+               \"and not the file names or the file objects. This warning \"\n+               \"will be removed in v0.23.\")\n+        try:\n+            self.analyzer(fname)\n+        except FileNotFoundError:\n+            warnings.warn(msg, ChangedBehaviorWarning)\n+        except AttributeError as e:\n+            if str(e) == \"'str' object has no attribute 'read'\":\n+                warnings.warn(msg, ChangedBehaviorWarning)\n+        except Exception:\n+            pass\n+\n     def build_analyzer(self):\n         \"\"\"Return a callable that handles preprocessing and tokenization\"\"\"\n         if callable(self.analyzer):\n-            return self.analyzer\n+            if self.input in ['file', 'filename']:\n+                self._validate_custom_analyzer()\n+            return lambda doc: self.analyzer(self.decode(doc))\n \n         preprocess = self.build_preprocessor()\n \n@@ -490,6 +515,11 @@ class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):\n         If a callable is passed it is used to extract the sequence of features\n         out of the raw, unprocessed input.\n \n+        .. versionchanged:: 0.21\n+        Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n+        first read from the file and then passed to the given callable\n+        analyzer.\n+\n     n_features : integer, default=(2 ** 20)\n         The number of features (columns) in the output matrices. Small numbers\n         of features are likely to cause hash collisions, but large numbers\n@@ -745,6 +775,11 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         If a callable is passed it is used to extract the sequence of features\n         out of the raw, unprocessed input.\n \n+        .. versionchanged:: 0.21\n+        Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n+        first read from the file and then passed to the given callable\n+        analyzer.\n+\n     max_df : float in range [0.0, 1.0] or int, default=1.0\n         When building the vocabulary ignore terms that have a document\n         frequency strictly higher than the given threshold (corpus-specific\n@@ -1369,6 +1404,11 @@ class TfidfVectorizer(CountVectorizer):\n         If a callable is passed it is used to extract the sequence of features\n         out of the raw, unprocessed input.\n \n+        .. versionchanged:: 0.21\n+        Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n+        first read from the file and then passed to the given callable\n+        analyzer.\n+\n     stop_words : string {'english'}, list, or None (default=None)\n         If a string, it is passed to _check_stop_list and the appropriate stop\n         list is returned. 'english' is currently the only supported string\n",
  "test_patch": "diff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py\n--- a/sklearn/feature_extraction/tests/test_text.py\n+++ b/sklearn/feature_extraction/tests/test_text.py\n@@ -29,6 +29,7 @@\n from numpy.testing import assert_array_almost_equal\n from numpy.testing import assert_array_equal\n from sklearn.utils import IS_PYPY\n+from sklearn.exceptions import ChangedBehaviorWarning\n from sklearn.utils.testing import (assert_equal, assert_not_equal,\n                                    assert_almost_equal, assert_in,\n                                    assert_less, assert_greater,\n@@ -1196,3 +1197,47 @@ def build_preprocessor(self):\n                                             .findall(doc),\n                     stop_words=['and'])\n     assert _check_stop_words_consistency(vec) is True\n+\n+\n+@pytest.mark.parametrize('Estimator',\n+                         [CountVectorizer, TfidfVectorizer, HashingVectorizer])\n+@pytest.mark.parametrize(\n+    'input_type, err_type, err_msg',\n+    [('filename', FileNotFoundError, ''),\n+     ('file', AttributeError, \"'str' object has no attribute 'read'\")]\n+)\n+def test_callable_analyzer_error(Estimator, input_type, err_type, err_msg):\n+    data = ['this is text, not file or filename']\n+    with pytest.raises(err_type, match=err_msg):\n+        Estimator(analyzer=lambda x: x.split(),\n+                  input=input_type).fit_transform(data)\n+\n+\n+@pytest.mark.parametrize('Estimator',\n+                         [CountVectorizer, TfidfVectorizer, HashingVectorizer])\n+@pytest.mark.parametrize(\n+    'analyzer', [lambda doc: open(doc, 'r'), lambda doc: doc.read()]\n+)\n+@pytest.mark.parametrize('input_type', ['file', 'filename'])\n+def test_callable_analyzer_change_behavior(Estimator, analyzer, input_type):\n+    data = ['this is text, not file or filename']\n+    warn_msg = 'Since v0.21, vectorizer'\n+    with pytest.raises((FileNotFoundError, AttributeError)):\n+        with pytest.warns(ChangedBehaviorWarning, match=warn_msg) as records:\n+            Estimator(analyzer=analyzer, input=input_type).fit_transform(data)\n+    assert len(records) == 1\n+    assert warn_msg in str(records[0])\n+\n+\n+@pytest.mark.parametrize('Estimator',\n+                         [CountVectorizer, TfidfVectorizer, HashingVectorizer])\n+def test_callable_analyzer_reraise_error(tmpdir, Estimator):\n+    # check if a custom exception from the analyzer is shown to the user\n+    def analyzer(doc):\n+        raise Exception(\"testing\")\n+\n+    f = tmpdir.join(\"file.txt\")\n+    f.write(\"sample content\\n\")\n+\n+    with pytest.raises(Exception, match=\"testing\"):\n+        Estimator(analyzer=analyzer, input='file').fit_transform([f])\n",
  "problem_statement": "CountVectorizer with custom analyzer ignores input argument\nExample:\n\n``` py\ncv = CountVectorizer(analyzer=lambda x: x.split(), input='filename')\ncv.fit(['hello world']).vocabulary_\n```\n\nSame for `input=\"file\"`. Not sure if this should be fixed or just documented; I don't like changing the behavior of the vectorizers yet again...\n\n",
  "hints_text": "To be sure, the current docstring says:\n\n```\nIf a callable is passed it is used to extract the sequence of features\nout of the raw, unprocessed input.\n```\n\n\"Unprocessed\" seems to mean that even `input=` is ignored, but this is not obvious.\n\nI'll readily agree that's the wrong behaviour even with that docstring.\n\nOn 20 October 2015 at 22:59, Lars notifications@github.com wrote:\n\n> To be sure, the current docstring says:\n> \n> ```\n> If a callable is passed it is used to extract the sequence of features\n> out of the raw, unprocessed input.\n> ```\n> \n> \"Unprocessed\" seems to mean that even input= is ignored, but this is not\n> obvious.\n> \n> â€”\n> Reply to this email directly or view it on GitHub\n> https://github.com/scikit-learn/scikit-learn/issues/5482#issuecomment-149541462\n> .\n\nI'm a new contributor, i'm interested to work on this issue. To be sure, what is expected is improving the docstring on that behavior ?\n\nI'm not at all sure. The behavior is probably a bug, but it has stood for so long that it's very hard to fix without breaking someone's code.\n\n@TTRh , did you have had some more thoughts on that? Otherwise, I will give it a shot and clarify how the input parameter is ought to be used vs. providing input in the fit method.\n\nPlease go ahead, i didn't produce anything on it !\n\n@jnothman @larsmans commit is pending on the docstring side of things.. after looking at the code, I think one would need to introduce a parameter like preprocessing=\"none\" to not break old code. If supplying a custom analyzer and using inbuilt preprocessing is no boundary case, this should become a feature request?\n\nI'd be tempted to say that any user using `input='file'` or `input='filename'` who then passed text to `fit` or `transform` was doing something obviously wrong. That is, I think this is a bug that can be fixed without notice. However, the correct behaviour still requires some definition. If we load from file for the user, do we decode? Probably not. Which means behaviour will differ between Py 2/3. But that's the user's problem.\r\n\r\n",
  "created_at": "2019-04-14T21:20:41Z",
  "version": "0.21",
  "FAIL_TO_PASS": "[\"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--HashingVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[file-AttributeError-'str'\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-HashingVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-HashingVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-HashingVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-HashingVectorizer]\"]",
  "PASS_TO_PASS": "[\"sklearn/feature_extraction/tests/test_text.py::test_strip_accents\", \"sklearn/feature_extraction/tests/test_text.py::test_to_ascii\", \"sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams[CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams[HashingVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams_and_bigrams\", \"sklearn/feature_extraction/tests/test_text.py::test_unicode_decode_error\", \"sklearn/feature_extraction/tests/test_text.py::test_char_ngram_analyzer\", \"sklearn/feature_extraction/tests/test_text.py::test_char_wb_ngram_analyzer\", \"sklearn/feature_extraction/tests/test_text.py::test_word_ngram_analyzer\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_pipeline\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_repeated_indices\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_gap_index\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_stop_words\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_empty_vocabulary\", \"sklearn/feature_extraction/tests/test_text.py::test_fit_countvectorizer_twice\", \"sklearn/feature_extraction/tests/test_text.py::test_tf_idf_smoothing\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_no_smoothing\", \"sklearn/feature_extraction/tests/test_text.py::test_sublinear_tf\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_setters\", \"sklearn/feature_extraction/tests/test_text.py::test_hashing_vectorizer\", \"sklearn/feature_extraction/tests/test_text.py::test_feature_names\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_features[CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_features[TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_max_features\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_df\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_min_df\", \"sklearn/feature_extraction/tests/test_text.py::test_count_binary_occurrences\", \"sklearn/feature_extraction/tests/test_text.py::test_hashed_binary_occurrences\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_inverse_transform[CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_inverse_transform[TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_pipeline_grid_selection\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_grid_selection\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_cross_validation\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_unicode\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_with_fixed_vocabulary\", \"sklearn/feature_extraction/tests/test_text.py::test_pickling_vectorizer\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_sets_when_pickling\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_dicts_when_pickling\", \"sklearn/feature_extraction/tests/test_text.py::test_stop_words_removal\", \"sklearn/feature_extraction/tests/test_text.py::test_pickling_transformer\", \"sklearn/feature_extraction/tests/test_text.py::test_transformer_idf_setter\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_setter\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_invalid_idf_attr\", \"sklearn/feature_extraction/tests/test_text.py::test_non_unique_vocab\", \"sklearn/feature_extraction/tests/test_text.py::test_hashingvectorizer_nan_in_docs\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_binary\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_export_idf\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_vocab_clone\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_string_object_as_input[CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_string_object_as_input[TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_string_object_as_input[HashingVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_transformer_type[float32]\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_transformer_type[float64]\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_transformer_sparse\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_type[int32-float64-True]\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_type[int64-float64-True]\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_type[float32-float32-False]\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_type[float64-float64-False]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec1]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec2]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_stop_words_inconsistent\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_sort_features_64bit_sparse_indices\", \"sklearn/feature_extraction/tests/test_text.py::test_stop_word_validation_custom_preprocessor[CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_stop_word_validation_custom_preprocessor[TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_stop_word_validation_custom_preprocessor[HashingVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[CountVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[TfidfVectorizer]\", \"sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[HashingVectorizer]\"]",
  "environment_setup_commit": "7813f7efb5b2012412888b69e73d76f2df2b50b6",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.997967",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}