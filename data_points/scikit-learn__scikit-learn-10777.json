{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-10777",
  "base_commit": "2eb731b375fa0b48f6902daa839ff6a8477b48fd",
  "patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -306,6 +306,15 @@ def _check_vocabulary(self):\n         if len(self.vocabulary_) == 0:\n             raise ValueError(\"Vocabulary is empty\")\n \n+    def _validate_params(self):\n+        \"\"\"Check validity of ngram_range parameter\"\"\"\n+        min_n, max_m = self.ngram_range\n+        if min_n > max_m:\n+            raise ValueError(\n+                \"Invalid value for ngram_range=%s \"\n+                \"lower boundary larger than the upper boundary.\"\n+                % str(self.ngram_range))\n+\n \n class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):\n     \"\"\"Convert a collection of text documents to a matrix of token occurrences\n@@ -497,6 +506,8 @@ def fit(self, X, y=None):\n                 \"Iterable over raw text documents expected, \"\n                 \"string object received.\")\n \n+        self._validate_params()\n+\n         self._get_hasher().fit(X, y=y)\n         return self\n \n@@ -520,6 +531,8 @@ def transform(self, X):\n                 \"Iterable over raw text documents expected, \"\n                 \"string object received.\")\n \n+        self._validate_params()\n+\n         analyzer = self.build_analyzer()\n         X = self._get_hasher().transform(analyzer(doc) for doc in X)\n         if self.binary:\n@@ -882,6 +895,7 @@ def fit_transform(self, raw_documents, y=None):\n                 \"Iterable over raw text documents expected, \"\n                 \"string object received.\")\n \n+        self._validate_params()\n         self._validate_vocabulary()\n         max_df = self.max_df\n         min_df = self.min_df\n",
  "test_patch": "diff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py\n--- a/sklearn/feature_extraction/tests/test_text.py\n+++ b/sklearn/feature_extraction/tests/test_text.py\n@@ -35,6 +35,7 @@\n import pickle\n from io import StringIO\n \n+import pytest\n \n JUNK_FOOD_DOCS = (\n     \"the pizza pizza beer copyright\",\n@@ -995,3 +996,26 @@ def test_vectorizer_string_object_as_input():\n             ValueError, message, vec.fit, \"hello world!\")\n         assert_raise_message(\n             ValueError, message, vec.transform, \"hello world!\")\n+\n+\n+@pytest.mark.parametrize(\"vec\", [\n+        HashingVectorizer(ngram_range=(2, 1)),\n+        CountVectorizer(ngram_range=(2, 1)),\n+        TfidfVectorizer(ngram_range=(2, 1))\n+    ])\n+def test_vectorizers_invalid_ngram_range(vec):\n+    # vectorizers could be initialized with invalid ngram range\n+    # test for raising error message\n+    invalid_range = vec.ngram_range\n+    message = (\"Invalid value for ngram_range=%s \"\n+               \"lower boundary larger than the upper boundary.\"\n+               % str(invalid_range))\n+\n+    assert_raise_message(\n+        ValueError, message, vec.fit, [\"good news everyone\"])\n+    assert_raise_message(\n+        ValueError, message, vec.fit_transform, [\"good news everyone\"])\n+\n+    if isinstance(vec, HashingVectorizer):\n+        assert_raise_message(\n+            ValueError, message, vec.transform, [\"good news everyone\"])\n",
  "problem_statement": "no error on CountVectorizer(ngram_range=(2, 1))\nI think if ngram_range[0] is greater than ngram_range[1] we should throw an error. Not sure what the current behavior is.\n",
  "hints_text": "Now there is no error occurred, this also happened in `HashingVectorizer` and`TfidfVectorizer`\r\nI think we can add an error message in `VectorizerMixin`？\nSince `CountVectorizer`, `HashingVectorizer` and `andTfidfVectorizer` are inherited from `VectorizerMixin`, we can add a validation check in `VectorizerMixin`. I think using Python [property](https://docs.python.org/2/library/functions.html#property) is a good way. \r\nFor example:\r\n```python\r\n#within VectorizerMixin\r\n@property\r\ndef ngram_range(self):\r\n    return self._ngram_range\r\n\r\n# alternatively, a cleaner style:\r\n# from operator import attrgetter \r\n# ngram_range = property(attrgetter('_ngram_range'))\r\n\r\n@ngram_range.setter\r\ndef ngram_range(self, value):\r\n    # raise ValueError if the input is invalid.\r\n    self.__ngram_range = value\r\n```\r\nI would like to work on it. I'm a new contributor, so any suggestions are welcome :)\r\n\r\nReferences:\r\n[1] https://docs.python.org/2/library/functions.html#property\r\n[2] http://stackoverflow.com/a/2825580/6865504\nHmm... We conventionally perform validation in `fit`, for good or bad.\n\nOn 5 April 2017 at 03:29, neyanbhbin <notifications@github.com> wrote:\n\n> Since CountVectorizer, HashingVectorizer and andTfidfVectorizer are\n> inherited from VectorizerMixin, we can add a validation check in\n> VectorizerMixin. I think using Python property\n> <https://docs.python.org/2/library/functions.html#property> is a good way.\n> For example:\n>\n> #within VectorizerMixin@propertydef ngram_range(self):\n>     return self._ngram_range\n> # alternatively, a cleaner style:# from operator import attrgetter # ngram_range = property(attrgetter('_ngram_range'))\n> @ngram_range.setterdef ngram_range(self, value):\n>     # raise ValueError if the input is invalid.\n>     self.__ngram_range = value\n>\n> I would like to work on it. I'm a new contributor, so any suggestions are\n> welcome :)\n>\n> References:\n> [1] https://docs.python.org/2/library/functions.html#property\n> [2] http://stackoverflow.com/a/2825580/6865504\n>\n> —\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/8688#issuecomment-291573285>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz6w2mFZFCsFTlYO4O37FgynC0FVZSks5rsn4BgaJpZM4Mw7gK>\n> .\n>\n\nI think this case is same as the validation of [min_df, max_df](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L676) and [max_features](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L678)\r\n\r\n> Hmm... We conventionally perform validation in `fit`, for good or bad.\nThat's there for historical reasons. If we wrote that code today, it would\nhappen in fit.\n\nOn 6 April 2017 at 15:41, neyanbhbin <notifications@github.com> wrote:\n\n> I think this case is same as the validation of min_df, max_df\n> <https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L676>\n> and max_features\n> <https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L678>\n>\n> Hmm... We conventionally perform validation in fit, for good or bad.\n>\n> —\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/8688#issuecomment-292074352>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz6-GA6tiQRNkvKJtfJRyPeFi55peiks5rtHsTgaJpZM4Mw7gK>\n> .\n>\n\nIn particular, any validation should not *only* happen in __init__ because\nthings can change between __init__ and fit.\n\nOn 6 April 2017 at 16:25, Joel Nothman <joel.nothman@gmail.com> wrote:\n\n> That's there for historical reasons. If we wrote that code today, it would\n> happen in fit.\n>\n> On 6 April 2017 at 15:41, neyanbhbin <notifications@github.com> wrote:\n>\n>> I think this case is same as the validation of min_df, max_df\n>> <https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L676>\n>> and max_features\n>> <https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L678>\n>>\n>> Hmm... We conventionally perform validation in fit, for good or bad.\n>>\n>> —\n>> You are receiving this because you commented.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/scikit-learn/scikit-learn/issues/8688#issuecomment-292074352>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/AAEz6-GA6tiQRNkvKJtfJRyPeFi55peiks5rtHsTgaJpZM4Mw7gK>\n>> .\n>>\n>\n>\n\nOh, I see. I might oversimplify the problem here. Sorry. \r\nSo is it similar with [raw_documents](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L828) in `fit`(or `fit_transform`)? Or we need a more common function to deal with the invalid parameters, including `max_features`, `min_df`, `max_df` and `ngram_range`?\r\n\r\n> That's there for historical reasons. If we wrote that code today, it would\r\nhappen in fit.\nfactoring out validation into a separate function would be welcome imo\n\nOn 7 Apr 2017 3:36 am, \"neyanbhbin\" <notifications@github.com> wrote:\n\n> Oh, I see. I might oversimplify the problem here. Sorry.\n> So is it similar with raw_documents\n> <https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L828>\n> in fit(or fit_transform)? Or we need a more common function to deal with\n> the invalid parameters, including max_features, min_df, max_df and\n> ngram_range?\n>\n> That's there for historical reasons. If we wrote that code today, it would\n> happen in fit.\n>\n> —\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/8688#issuecomment-292250403>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz6-prUMGhwf7GnzUVSBtcHRAomG_eks5rtSKVgaJpZM4Mw7gK>\n> .\n>\n",
  "created_at": "2018-03-08T12:15:46Z",
  "version": "0.20",
  "FAIL_TO_PASS": "[\"sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec0]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec1]\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec2]\"]",
  "PASS_TO_PASS": "[\"sklearn/feature_extraction/tests/test_text.py::test_strip_accents\", \"sklearn/feature_extraction/tests/test_text.py::test_to_ascii\", \"sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams\", \"sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams_and_bigrams\", \"sklearn/feature_extraction/tests/test_text.py::test_unicode_decode_error\", \"sklearn/feature_extraction/tests/test_text.py::test_char_ngram_analyzer\", \"sklearn/feature_extraction/tests/test_text.py::test_char_wb_ngram_analyzer\", \"sklearn/feature_extraction/tests/test_text.py::test_word_ngram_analyzer\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_pipeline\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_repeated_indeces\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_gap_index\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_stop_words\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_empty_vocabulary\", \"sklearn/feature_extraction/tests/test_text.py::test_fit_countvectorizer_twice\", \"sklearn/feature_extraction/tests/test_text.py::test_tf_idf_smoothing\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_no_smoothing\", \"sklearn/feature_extraction/tests/test_text.py::test_sublinear_tf\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_setters\", \"sklearn/feature_extraction/tests/test_text.py::test_hashing_vectorizer\", \"sklearn/feature_extraction/tests/test_text.py::test_feature_names\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_features\", \"sklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_max_features\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_df\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_min_df\", \"sklearn/feature_extraction/tests/test_text.py::test_count_binary_occurrences\", \"sklearn/feature_extraction/tests/test_text.py::test_hashed_binary_occurrences\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_inverse_transform\", \"sklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_pipeline_grid_selection\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_grid_selection\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_cross_validation\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_unicode\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_with_fixed_vocabulary\", \"sklearn/feature_extraction/tests/test_text.py::test_pickling_vectorizer\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_sets_when_pickling\", \"sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_dicts_when_pickling\", \"sklearn/feature_extraction/tests/test_text.py::test_stop_words_removal\", \"sklearn/feature_extraction/tests/test_text.py::test_pickling_transformer\", \"sklearn/feature_extraction/tests/test_text.py::test_non_unique_vocab\", \"sklearn/feature_extraction/tests/test_text.py::test_hashingvectorizer_nan_in_docs\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_binary\", \"sklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_export_idf\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_vocab_clone\", \"sklearn/feature_extraction/tests/test_text.py::test_vectorizer_string_object_as_input\"]",
  "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.955013",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}