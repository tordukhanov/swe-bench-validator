{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-12462",
  "base_commit": "9ec5a15823dcb924a5cca322f9f97357f9428345",
  "patch": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -140,7 +140,12 @@ def _num_samples(x):\n         if len(x.shape) == 0:\n             raise TypeError(\"Singleton array %r cannot be considered\"\n                             \" a valid collection.\" % x)\n-        return x.shape[0]\n+        # Check that shape is returning an integer or default to len\n+        # Dask dataframes may not return numeric shape[0] value\n+        if isinstance(x.shape[0], numbers.Integral):\n+            return x.shape[0]\n+        else:\n+            return len(x)\n     else:\n         return len(x)\n \n",
  "test_patch": "diff --git a/sklearn/utils/tests/test_validation.py b/sklearn/utils/tests/test_validation.py\n--- a/sklearn/utils/tests/test_validation.py\n+++ b/sklearn/utils/tests/test_validation.py\n@@ -41,6 +41,7 @@\n     check_memory,\n     check_non_negative,\n     LARGE_SPARSE_SUPPORTED,\n+    _num_samples\n )\n import sklearn\n \n@@ -786,3 +787,15 @@ def test_check_X_y_informative_error():\n     X = np.ones((2, 2))\n     y = None\n     assert_raise_message(ValueError, \"y cannot be None\", check_X_y, X, y)\n+\n+\n+def test_retrieve_samples_from_non_standard_shape():\n+    class TestNonNumericShape:\n+        def __init__(self):\n+            self.shape = (\"not numeric\",)\n+\n+        def __len__(self):\n+            return len([1, 2, 3])\n+\n+    X = TestNonNumericShape()\n+    assert _num_samples(X) == len(X)\n",
  "problem_statement": "SkLearn `.score()` method generating error with Dask DataFrames\nWhen using Dask Dataframes with SkLearn, I used to be able to just ask SkLearn for the score of any given algorithm. It would spit out a nice answer and I'd move on. After updating to the newest versions, all metrics that compute based on (y_true, y_predicted) are failing. I've tested `accuracy_score`, `precision_score`, `r2_score`, and `mean_squared_error.` Work-around shown below, but it's not ideal because it requires me to cast from Dask Arrays to numpy arrays which won't work if the data is huge.\r\n\r\nI've asked Dask about it here: https://github.com/dask/dask/issues/4137 and they've said it's an issue with the SkLearn `shape` check, and that they won't be addressing it. It seems like it should be not super complicated to add a `try-except` that says \"if shape doesn't return a tuple revert to pretending shape didn't exist\". If others think that sounds correct, I can attempt a pull-request, but I don't want to attempt to solve it on my own only to find out others don't deem that an acceptable solutions.\r\n\r\nTrace, MWE, versions, and workaround all in-line.\r\n\r\nMWE:\r\n\r\n```\r\nimport dask.dataframe as dd\r\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\r\n\r\ndf = dd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=';')\r\nlr = LinearRegression()\r\nX = df.drop('quality', axis=1)\r\ny = df['quality']\r\n\r\nlr.fit(X,y)\r\nlr.score(X,y)\r\n```\r\n\r\nOutput of error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-5-4eafa0e7fc85> in <module>\r\n      8 \r\n      9 lr.fit(X,y)\r\n---> 10 lr.score(X,y)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/sklearn/base.py in score(self, X, y, sample_weight)\r\n    327         from .metrics import r2_score\r\n    328         return r2_score(y, self.predict(X), sample_weight=sample_weight,\r\n--> 329                         multioutput='variance_weighted')\r\n    330 \r\n    331 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py in r2_score(y_true, y_pred, sample_weight, multioutput)\r\n    532     \"\"\"\r\n    533     y_type, y_true, y_pred, multioutput = _check_reg_targets(\r\n--> 534         y_true, y_pred, multioutput)\r\n    535     check_consistent_length(y_true, y_pred, sample_weight)\r\n    536 \r\n\r\n~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true, y_pred, multioutput)\r\n     73 \r\n     74     \"\"\"\r\n---> 75     check_consistent_length(y_true, y_pred)\r\n     76     y_true = check_array(y_true, ensure_2d=False)\r\n     77     y_pred = check_array(y_pred, ensure_2d=False)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py in check_consistent_length(*arrays)\r\n    225 \r\n    226     lengths = [_num_samples(X) for X in arrays if X is not None]\r\n--> 227     uniques = np.unique(lengths)\r\n    228     if len(uniques) > 1:\r\n    229         raise ValueError(\"Found input variables with inconsistent numbers of\"\r\n\r\n~/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py in unique(ar, return_index, return_inverse, return_counts, axis)\r\n    229 \r\n    230     \"\"\"\r\n--> 231     ar = np.asanyarray(ar)\r\n    232     if axis is None:\r\n    233         ret = _unique1d(ar, return_index, return_inverse, return_counts)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py in asanyarray(a, dtype, order)\r\n    551 \r\n    552     \"\"\"\r\n--> 553     return array(a, dtype, copy=False, order=order, subok=True)\r\n    554 \r\n    555 \r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'Scalar'\r\n```\r\n\r\nProblem occurs after upgrading as follows:\r\n\r\nBefore bug:\r\n```\r\nfor lib in (sklearn, dask):\r\n    print(f'{lib.__name__} Version: {lib.__version__}')\r\n> sklearn Version: 0.19.1\r\n> dask Version: 0.18.2\r\n```\r\n\r\nUpdate from conda, then bug starts:\r\n```\r\nfor lib in (sklearn, dask):\r\n    print(f'{lib.__name__} Version: {lib.__version__}')\r\n> sklearn Version: 0.20.0\r\n> dask Version: 0.19.4\r\n```\r\n\r\nWork around:\r\n\r\n```\r\nfrom sklearn.metrics import r2_score\r\npreds = lr.predict(X_test)\r\nr2_score(np.array(y_test), np.array(preds))\r\n```\n",
  "hints_text": "Some context: dask DataFrame doesn't know it's length. Previously, it didn't have a `shape` attribute.\r\n\r\nNow dask DataFrame has a shape that returns a `Tuple[Delayed, int]` for the number of rows and columns.\r\n\r\n> Work-around shown below, but it's not ideal because it requires me to cast from Dask Arrays to numpy arrays which won't work if the data is huge.\r\n\r\nFYI @ZWMiller that's exactly what was occurring previously. Personally, I don't think relying on this is a good idea, for exactly the reason you state.\r\n\r\nIn `_num_samples` scikit-learn simply checks whether the array-like has a `'shape'` attribute, and then assumes that it's an int from there on. The potential fix would be slightly stricter duck typing. Checking something like `hasattr(x, 'shape') and isinstance(x.shape[0], int)` or `numbers.Integral`.\r\n\r\n```python\r\nif hasattr(x, 'shape') and isinstance(x.shape[0], int):\r\n    ...\r\nelse:\r\n    return len(x) \r\n```",
  "created_at": "2018-10-25T21:53:00Z",
  "version": "0.21",
  "FAIL_TO_PASS": "[\"sklearn/utils/tests/test_validation.py::test_retrieve_samples_from_non_standard_shape\"]",
  "PASS_TO_PASS": "[\"sklearn/utils/tests/test_validation.py::test_as_float_array\", \"sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X0]\", \"sklearn/utils/tests/test_validation.py::test_as_float_array_nan[X1]\", \"sklearn/utils/tests/test_validation.py::test_np_matrix\", \"sklearn/utils/tests/test_validation.py::test_memmap\", \"sklearn/utils/tests/test_validation.py::test_ordering\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-inf-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-allow-nan]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[asarray-nan-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-inf-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-allow-nan]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finite_valid[csr_matrix-nan-False]\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-inf-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-inf-allow-nan-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-nan-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-nan-allow-inf-force_all_finite\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[asarray-nan-1-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-inf-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-inf-allow-nan-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-nan-True-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-nan-allow-inf-force_all_finite\", \"sklearn/utils/tests/test_validation.py::test_check_array_force_all_finiteinvalid[csr_matrix-nan-1-Input\", \"sklearn/utils/tests/test_validation.py::test_check_array\", \"sklearn/utils/tests/test_validation.py::test_check_array_pandas_dtype_object_conversion\", \"sklearn/utils/tests/test_validation.py::test_check_array_on_mock_dataframe\", \"sklearn/utils/tests/test_validation.py::test_check_array_dtype_stability\", \"sklearn/utils/tests/test_validation.py::test_check_array_dtype_warning\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_type_exception\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_sparse_no_exception\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[csr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[csc]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[coo]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_no_exception[bsr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[csr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[csc]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[coo]\", \"sklearn/utils/tests/test_validation.py::test_check_array_accept_large_sparse_raise_exception[bsr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[csr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[csc]\", \"sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[coo]\", \"sklearn/utils/tests/test_validation.py::test_check_array_large_indices_non_supported_scipy_version[bsr]\", \"sklearn/utils/tests/test_validation.py::test_check_array_min_samples_and_features_messages\", \"sklearn/utils/tests/test_validation.py::test_check_array_complex_data_error\", \"sklearn/utils/tests/test_validation.py::test_has_fit_parameter\", \"sklearn/utils/tests/test_validation.py::test_check_symmetric\", \"sklearn/utils/tests/test_validation.py::test_check_is_fitted\", \"sklearn/utils/tests/test_validation.py::test_check_consistent_length\", \"sklearn/utils/tests/test_validation.py::test_check_dataframe_fit_attribute\", \"sklearn/utils/tests/test_validation.py::test_suppress_validation\", \"sklearn/utils/tests/test_validation.py::test_check_dataframe_warns_on_dtype\", \"sklearn/utils/tests/test_validation.py::test_check_memory\", \"sklearn/utils/tests/test_validation.py::test_check_array_memmap[True]\", \"sklearn/utils/tests/test_validation.py::test_check_array_memmap[False]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[asarray]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[csr_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[csc_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[coo_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[lil_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[bsr_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[dok_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_non_negative[dia_matrix]\", \"sklearn/utils/tests/test_validation.py::test_check_X_y_informative_error\"]",
  "environment_setup_commit": "7813f7efb5b2012412888b69e73d76f2df2b50b6",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.964401",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}