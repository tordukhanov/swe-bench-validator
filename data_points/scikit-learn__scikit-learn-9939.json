{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-9939",
  "base_commit": "f247ad5adfe86b2ee64a4a3db1b496c8bf1c9dff",
  "patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -1101,14 +1101,18 @@ class LogisticRegression(BaseEstimator, LinearClassifierMixin,\n     coef_ : array, shape (1, n_features) or (n_classes, n_features)\n         Coefficient of the features in the decision function.\n \n-        `coef_` is of shape (1, n_features) when the given problem\n-        is binary.\n+        `coef_` is of shape (1, n_features) when the given problem is binary.\n+        In particular, when `multi_class='multinomial'`, `coef_` corresponds\n+        to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n \n     intercept_ : array, shape (1,) or (n_classes,)\n         Intercept (a.k.a. bias) added to the decision function.\n \n         If `fit_intercept` is set to False, the intercept is set to zero.\n-        `intercept_` is of shape(1,) when the problem is binary.\n+        `intercept_` is of shape (1,) when the given problem is binary.\n+        In particular, when `multi_class='multinomial'`, `intercept_`\n+        corresponds to outcome 1 (True) and `-intercept_` corresponds to\n+        outcome 0 (False).\n \n     n_iter_ : array, shape (n_classes,) or (1, )\n         Actual number of iterations for all classes. If binary or multinomial,\n@@ -1332,11 +1336,17 @@ def predict_proba(self, X):\n         \"\"\"\n         if not hasattr(self, \"coef_\"):\n             raise NotFittedError(\"Call fit before prediction\")\n-        calculate_ovr = self.coef_.shape[0] == 1 or self.multi_class == \"ovr\"\n-        if calculate_ovr:\n+        if self.multi_class == \"ovr\":\n             return super(LogisticRegression, self)._predict_proba_lr(X)\n         else:\n-            return softmax(self.decision_function(X), copy=False)\n+            decision = self.decision_function(X)\n+            if decision.ndim == 1:\n+                # Workaround for multi_class=\"multinomial\" and binary outcomes\n+                # which requires softmax prediction with only a 1D decision.\n+                decision_2d = np.c_[-decision, decision]\n+            else:\n+                decision_2d = decision\n+            return softmax(decision_2d, copy=False)\n \n     def predict_log_proba(self, X):\n         \"\"\"Log of probability estimates.\n",
  "test_patch": "diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -198,6 +198,23 @@ def test_multinomial_binary():\n         assert_greater(np.mean(pred == target), .9)\n \n \n+def test_multinomial_binary_probabilities():\n+    # Test multinomial LR gives expected probabilities based on the\n+    # decision function, for a binary problem.\n+    X, y = make_classification()\n+    clf = LogisticRegression(multi_class='multinomial', solver='saga')\n+    clf.fit(X, y)\n+\n+    decision = clf.decision_function(X)\n+    proba = clf.predict_proba(X)\n+\n+    expected_proba_class_1 = (np.exp(decision) /\n+                              (np.exp(decision) + np.exp(-decision)))\n+    expected_proba = np.c_[1-expected_proba_class_1, expected_proba_class_1]\n+\n+    assert_almost_equal(proba, expected_proba)\n+\n+\n def test_sparsify():\n     # Test sparsify and densify members.\n     n_samples, n_features = iris.data.shape\n",
  "problem_statement": "Incorrect predictions when fitting a LogisticRegression model on binary outcomes with `multi_class='multinomial'`.\n#### Description\r\nIncorrect predictions when fitting a LogisticRegression model on binary outcomes with `multi_class='multinomial'`.\r\n<!-- Example: Joblib Error thrown when calling fit on LatentDirichletAllocation with evaluate_every > 0-->\r\n\r\n#### Steps/Code to Reproduce\r\n```python\r\n    from sklearn.linear_model import LogisticRegression\r\n    import sklearn.metrics\r\n    import numpy as np\r\n\r\n    # Set up a logistic regression object\r\n    lr = LogisticRegression(C=1000000, multi_class='multinomial',\r\n                            solver='sag', tol=0.0001, warm_start=False,\r\n                            verbose=0)\r\n\r\n    # Set independent variable values\r\n    Z = np.array([\r\n       [ 0.        ,  0.        ],\r\n       [ 1.33448632,  0.        ],\r\n       [ 1.48790105, -0.33289528],\r\n       [-0.47953866, -0.61499779],\r\n       [ 1.55548163,  1.14414766],\r\n       [-0.31476657, -1.29024053],\r\n       [-1.40220786, -0.26316645],\r\n       [ 2.227822  , -0.75403668],\r\n       [-0.78170885, -1.66963585],\r\n       [ 2.24057471, -0.74555021],\r\n       [-1.74809665,  2.25340192],\r\n       [-1.74958841,  2.2566389 ],\r\n       [ 2.25984734, -1.75106702],\r\n       [ 0.50598996, -0.77338402],\r\n       [ 1.21968303,  0.57530831],\r\n       [ 1.65370219, -0.36647173],\r\n       [ 0.66569897,  1.77740068],\r\n       [-0.37088553, -0.92379819],\r\n       [-1.17757946, -0.25393047],\r\n       [-1.624227  ,  0.71525192]])\r\n    \r\n    # Set dependant variable values\r\n    Y = np.array([1, 0, 0, 1, 0, 0, 0, 0, \r\n                  0, 0, 1, 1, 1, 0, 0, 1, \r\n                  0, 0, 1, 1], dtype=np.int32)\r\n\r\n    lr.fit(Z, Y)\r\n    p = lr.predict_proba(Z)\r\n    print(sklearn.metrics.log_loss(Y, p)) # ...\r\n\r\n    print(lr.intercept_)\r\n    print(lr.coef_)\r\n```\r\n<!--\r\nExample:\r\n```python\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\nfrom sklearn.decomposition import LatentDirichletAllocation\r\n\r\ndocs = [\"Help I have a bug\" for i in range(1000)]\r\n\r\nvectorizer = CountVectorizer(input=docs, analyzer='word')\r\nlda_features = vectorizer.fit_transform(docs)\r\n\r\nlda_model = LatentDirichletAllocation(\r\n    n_topics=10,\r\n    learning_method='online',\r\n    evaluate_every=10,\r\n    n_jobs=4,\r\n)\r\nmodel = lda_model.fit(lda_features)\r\n```\r\nIf the code is too long, feel free to put it in a public gist and link\r\nit in the issue: https://gist.github.com\r\n-->\r\n\r\n#### Expected Results\r\nIf we compare against R or using `multi_class='ovr'`, the log loss (which is approximately proportional to the objective function as the regularisation is set to be negligible through the choice of `C`) is incorrect. We expect the log loss to be roughly `0.5922995`\r\n\r\n#### Actual Results\r\nThe actual log loss when using `multi_class='multinomial'` is `0.61505641264`.\r\n\r\n#### Further Information\r\nSee the stack exchange question https://stats.stackexchange.com/questions/306886/confusing-behaviour-of-scikit-learn-logistic-regression-multinomial-optimisation?noredirect=1#comment583412_306886 for more information.\r\n\r\nThe issue it seems is caused in https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/linear_model/logistic.py#L762. In the `multinomial` case even if `classes.size==2` we cannot reduce to a 1D case by throwing away one of the vectors of coefficients (as we can in normal binary logistic regression). This is essentially a difference between softmax (redundancy allowed) and logistic regression.\r\n\r\nThis can be fixed by commenting out the lines 762 and 763. I am apprehensive however that this may cause some other unknown issues which is why I am positing as a bug.\r\n\r\n#### Versions\r\n<!--\r\nPlease run the following snippet and paste the output below.\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport numpy; print(\"NumPy\", numpy.__version__)\r\nimport scipy; print(\"SciPy\", scipy.__version__)\r\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)\r\n-->\r\nLinux-4.10.0-33-generic-x86_64-with-Ubuntu-16.04-xenial\r\nPython 3.5.2 (default, Nov 17 2016, 17:05:23) \r\nNumPy 1.13.1\r\nSciPy 0.19.1\r\nScikit-Learn 0.19.0\r\n<!-- Thanks for contributing! -->\r\n\n",
  "hints_text": "Yes, just taking the coef for one class indeed seems incorrect. Is there\nany way to adjust the coef of one class (and the intercept) given the other\nto get the right probabilities?\n\n> This is essentially a difference between softmax (redundancy allowed) and logistic regression.\r\n\r\nIndeed, there is a difference in the way we want to compute `predict_proba`:\r\n1. In OVR-LR, you want a sigmoid: `exp(D(x)) / (exp(D(x)) + 1)`, where `D(x)` is the decision function.\r\n2. In multinomial-LR with `n_classes=2`, you want a softmax `exp(D(x)) / (exp(D(x)) + exp(-D(x))`.\r\n\r\nSo we **do** expect different results between (1) and (2). \r\nHowever, there is indeed a bug and your fix is correct:\r\n\r\nIn the current code, we incorrectly use the sigmoid on case (2). Removing lines 762 and 763 does solve this problem, but change the API of `self.coef_`, which specifically states `coef_ is of shape (1, n_features) when the given problem is binary`.\r\n\r\nAnother way to fix it is to change directly `predict_proba`, adding the case binary+multinomial:\r\n```py\r\n        if self.multi_class == \"ovr\":\r\n            return super(LogisticRegression, self)._predict_proba_lr(X)\r\n        elif self.coef_.shape[0] == 1:\r\n            decision = self.decision_function(X)\r\n            return softmax(np.c_[-decision, decision], copy=False)\r\n        else:\r\n            return softmax(self.decision_function(X), copy=False)\r\n```\r\nIt will also break current behavior of `predict_proba`, but we don't need deprecation if we consider it is a bug.\r\n\r\n\nIf it didn't cause too many further issues, I think the first solution would be better i.e. changing the API of `self.coef_` for the `multinomial` case. This is because, say we fit a logistic regression `lr`, then upon inspecting the `lr.coef_ ` and `lr.intercept_` objects, it is clear what model is being used. \r\n\r\nI also believe anyone using `multinomial` for a binary case (as I was) is doing it as part of some more general functionality and will also be fitting non-binary models depending on their data. If they want to access the parameters of the models (as I was) `.intercept_` and `.coef_` their generalisation will be broken in the binary case if only `predict_proba` is changed.\nWe already break the generalisation elsewhere, as in `decision_function` and in the `coef_` shape for other multiclass methods. I think maintaining internal consistency here might be more important than some abstract concern that \"generalisation will be broken\". I think we should choose modifying `predict_proba`. This also makes it clear that the multinomial case does not suddenly introduce more free parameters.\nI agree it would make more sense to have `coef_.shape = (n_classes, n_features)` even when `n_classes = 2`, to have more consistency and avoid special cases.\r\n\r\nHowever, it is a valid argument also for the OVR case (actually, it is nice to have the same `coef_` API for both multinomial and OVR cases). Does that mean we should change the `coef_`  API in all cases? It is an important API change which will break a lot of user code, and which might not be consistent with the rest of scikit-learn...\nAnother option could be to always use the `ovr` method in the binary case even when `multiclass` is set to `multinomial`. This would avoid the case of models having exactly the same coefficients but predicting different values due to have different `multiclass` parameters. As previously mentioned, if `predict_proba` gets changed, the `multinomial` prediction would be particularly confusing if someone just looks at the 1D coefficients `coef_` (I think the `ovr` case is the intuitive one).\r\n\r\nI believe by doing this, the only code that would get broken would be anyone who already knew about the bug and had coded their own workaround.\r\n\r\nNote: If we do this, it is not returning the actual correct parameters with regards to the regularisation, despite the fact the solutions will be identical in terms of prediction. This may make it a no go.\nChanging the binary coef_ in the general case is just not going to happen.\nIf you want to fix a bug, fix a bug...\n\nOn 10 October 2017 at 00:05, Tom Dupré la Tour <notifications@github.com>\nwrote:\n\n> I agree it would make more sense to have coef_.shape = (n_classes,\n> n_features) even when n_classes = 2, to have more consistency and avoid\n> special cases.\n>\n> However, it is a valid argument also for the OVR case (actually, it is\n> nice to have the same coef_ API for both multinomial and OVR cases). Does\n> that mean we should change the coef_ API in all cases? It is an important\n> API changes which will break a lot of user code, and which might not be\n> consistent with the rest of scikit-learn.\n>\n> —\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/9889#issuecomment-335150971>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz6-kpIPulfN1z6KQYbqEQP2bRd3pPks5sqhkPgaJpZM4PyMNd>\n> .\n>\n\nAre the learnt probabilities then equivalent if it changes to ovr for 2\nclasses? Seems a reasonable idea to me.\n\nThinking about it, it works with no regularisation but when regularisation is involved we should expect slightly different results for `ovr` and `multinomial`.\r\n\r\nMaybe then just change `predict_proba` as suggested and a warning message when fitting a binary model with `multinomial`.\nwhy the warning? what would it say?\n\nThe issue is that the values of `coef_` do not intuitively describe the model in the binary case using `multinomial`. If someone fits a binary logistic regression and receives back a 1D vector of coefficients (`W` say for convenience), I would assume that they will think the predicted probability of a new observation `X`, is given by\r\n\r\n    exp(dot(W,X)) / (1 + exp(dot(W,X)))\r\n\r\nThis is true in the `ovr` case only. In the `multinomial` case, it is actually given by\r\n\r\n    exp(dot(W,X)) / (exp(dot(-W,X)) + exp(dot(W,X)))\r\n\r\nI believe this would surprise and cause errors for many people upon receiving a 1D vector of coefficients `W` so I think they should be warned about it. In fact I wouldn't be surprised if people currently using the logistic regression coefficients in the `multinomial`, binary outcome case, have bugs in their code.\r\n\r\nI would suggest a warning message when `.fit` is called with `multinomial`, when binary outcomes are detected. Something along the lines of (this can probably be made more concise):\r\n\r\n    Fitting a binary model with multi_class=multinomial. The returned `coef_` and `intercept_` values form the coefficients for outcome 1 (True), use `-coef_` and `-intercept` to form the coefficients for outcome 0 (False).\nI think it would be excessive noise to warn such upon fit. why not just\namend the coef_ description? most users will not be manually making\nprobabilistic interpretations of coef_ in any case, and we can't in general\nstop users misinterpreting things on the basis of assumption rather than\nreading the docs...\n\nFair enough. My only argument to the contrary would be that using `multinomial` for binary classification is a fairly uncommon thing to do, so the warning would be infrequent.\r\n\r\nHowever I agree in this case that if a user is only receiving a 1D vector of coefficients (i.e. it is not in the general form as for dimensions > 2), then they should be checking the documentation for exactly what this means, so amending the `coef_` description should suffice.\nSo to sum-up, we need to:\r\n - update `predict_proba` as described in https://github.com/scikit-learn/scikit-learn/issues/9889#issuecomment-335129554\r\n- update `coef_`'s docstring\r\n- add a test and a bugfix entry in `whats_new`\r\n\r\nDo you want to do it @rwolst ?\nSure, I'll do it.\nThanks",
  "created_at": "2017-10-17T10:52:38Z",
  "version": "0.20",
  "FAIL_TO_PASS": "[\"sklearn/linear_model/tests/test_logistic.py::test_multinomial_binary_probabilities\"]",
  "PASS_TO_PASS": "[\"sklearn/linear_model/tests/test_logistic.py::test_predict_2_classes\", \"sklearn/linear_model/tests/test_logistic.py::test_error\", \"sklearn/linear_model/tests/test_logistic.py::test_lr_liblinear_warning\", \"sklearn/linear_model/tests/test_logistic.py::test_predict_3_classes\", \"sklearn/linear_model/tests/test_logistic.py::test_predict_iris\", \"sklearn/linear_model/tests/test_logistic.py::test_multinomial_validation\", \"sklearn/linear_model/tests/test_logistic.py::test_check_solver_option\", \"sklearn/linear_model/tests/test_logistic.py::test_multinomial_binary\", \"sklearn/linear_model/tests/test_logistic.py::test_sparsify\", \"sklearn/linear_model/tests/test_logistic.py::test_inconsistent_input\", \"sklearn/linear_model/tests/test_logistic.py::test_write_parameters\", \"sklearn/linear_model/tests/test_logistic.py::test_nan\", \"sklearn/linear_model/tests/test_logistic.py::test_consistency_path\", \"sklearn/linear_model/tests/test_logistic.py::test_liblinear_dual_random_state\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_loss_and_grad\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_grad_hess\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_cv\", \"sklearn/linear_model/tests/test_logistic.py::test_multinomial_logistic_regression_string_inputs\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_cv_sparse\", \"sklearn/linear_model/tests/test_logistic.py::test_intercept_logistic_helper\", \"sklearn/linear_model/tests/test_logistic.py::test_ovr_multinomial_iris\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_regression_solvers\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_regression_solvers_multiclass\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_regressioncv_class_weights\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_regression_sample_weights\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_regression_class_weights\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_regression_convergence_warnings\", \"sklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multinomial\", \"sklearn/linear_model/tests/test_logistic.py::test_multinomial_grad_hess\", \"sklearn/linear_model/tests/test_logistic.py::test_liblinear_decision_function_zero\", \"sklearn/linear_model/tests/test_logistic.py::test_liblinear_logregcv_sparse\", \"sklearn/linear_model/tests/test_logistic.py::test_saga_sparse\", \"sklearn/linear_model/tests/test_logistic.py::test_logreg_intercept_scaling\", \"sklearn/linear_model/tests/test_logistic.py::test_logreg_intercept_scaling_zero\", \"sklearn/linear_model/tests/test_logistic.py::test_logreg_l1\", \"sklearn/linear_model/tests/test_logistic.py::test_logreg_l1_sparse_data\", \"sklearn/linear_model/tests/test_logistic.py::test_logreg_cv_penalty\", \"sklearn/linear_model/tests/test_logistic.py::test_logreg_predict_proba_multinomial\", \"sklearn/linear_model/tests/test_logistic.py::test_n_iter\", \"sklearn/linear_model/tests/test_logistic.py::test_warm_start\", \"sklearn/linear_model/tests/test_logistic.py::test_saga_vs_liblinear\", \"sklearn/linear_model/tests/test_logistic.py::test_dtype_match\"]",
  "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.029131",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}