{
  "repo": "pytest-dev/pytest",
  "instance_id": "pytest-dev__pytest-7231",
  "base_commit": "85a06cfafbe49f2c56e22cef4fa88adcf7b54f59",
  "patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -312,6 +312,14 @@ def reset(self) -> None:\n         self.records = []\n         self.stream = StringIO()\n \n+    def handleError(self, record: logging.LogRecord) -> None:\n+        if logging.raiseExceptions:\n+            # Fail the test if the log message is bad (emit failed).\n+            # The default behavior of logging is to print \"Logging error\"\n+            # to stderr with the call stack and some extra details.\n+            # pytest wants to make such mistakes visible during testing.\n+            raise\n+\n \n class LogCaptureFixture:\n     \"\"\"Provides access and control of log capturing.\"\"\"\n@@ -499,9 +507,7 @@ def __init__(self, config: Config) -> None:\n         # File logging.\n         self.log_file_level = get_log_level_for_setting(config, \"log_file_level\")\n         log_file = get_option_ini(config, \"log_file\") or os.devnull\n-        self.log_file_handler = logging.FileHandler(\n-            log_file, mode=\"w\", encoding=\"UTF-8\"\n-        )\n+        self.log_file_handler = _FileHandler(log_file, mode=\"w\", encoding=\"UTF-8\")\n         log_file_format = get_option_ini(config, \"log_file_format\", \"log_format\")\n         log_file_date_format = get_option_ini(\n             config, \"log_file_date_format\", \"log_date_format\"\n@@ -687,6 +693,16 @@ def pytest_unconfigure(self):\n         self.log_file_handler.close()\n \n \n+class _FileHandler(logging.FileHandler):\n+    \"\"\"\n+    Custom FileHandler with pytest tweaks.\n+    \"\"\"\n+\n+    def handleError(self, record: logging.LogRecord) -> None:\n+        # Handled by LogCaptureHandler.\n+        pass\n+\n+\n class _LiveLoggingStreamHandler(logging.StreamHandler):\n     \"\"\"\n     Custom StreamHandler used by the live logging feature: it will write a newline before the first log message\n@@ -737,6 +753,10 @@ def emit(self, record):\n                 self._section_name_shown = True\n             super().emit(record)\n \n+    def handleError(self, record: logging.LogRecord) -> None:\n+        # Handled by LogCaptureHandler.\n+        pass\n+\n \n class _LiveLoggingNullHandler(logging.NullHandler):\n     \"\"\"A handler used when live logging is disabled.\"\"\"\n@@ -746,3 +766,7 @@ def reset(self):\n \n     def set_when(self, when):\n         pass\n+\n+    def handleError(self, record: logging.LogRecord) -> None:\n+        # Handled by LogCaptureHandler.\n+        pass\n",
  "test_patch": "diff --git a/testing/logging/test_reporting.py b/testing/logging/test_reporting.py\n--- a/testing/logging/test_reporting.py\n+++ b/testing/logging/test_reporting.py\n@@ -3,6 +3,7 @@\n import re\n \n import pytest\n+from _pytest.pytester import Testdir\n \n \n def test_nothing_logged(testdir):\n@@ -1101,3 +1102,48 @@ def test_foo(caplog):\n     )\n     result = testdir.runpytest(\"--log-level=INFO\", \"--color=yes\")\n     assert result.ret == 0\n+\n+\n+def test_logging_emit_error(testdir: Testdir) -> None:\n+    \"\"\"\n+    An exception raised during emit() should fail the test.\n+\n+    The default behavior of logging is to print \"Logging error\"\n+    to stderr with the call stack and some extra details.\n+\n+    pytest overrides this behavior to propagate the exception.\n+    \"\"\"\n+    testdir.makepyfile(\n+        \"\"\"\n+        import logging\n+\n+        def test_bad_log():\n+            logging.warning('oops', 'first', 2)\n+        \"\"\"\n+    )\n+    result = testdir.runpytest()\n+    result.assert_outcomes(failed=1)\n+    result.stdout.fnmatch_lines(\n+        [\n+            \"====* FAILURES *====\",\n+            \"*not all arguments converted during string formatting*\",\n+        ]\n+    )\n+\n+\n+def test_logging_emit_error_supressed(testdir: Testdir) -> None:\n+    \"\"\"\n+    If logging is configured to silently ignore errors, pytest\n+    doesn't propagate errors either.\n+    \"\"\"\n+    testdir.makepyfile(\n+        \"\"\"\n+        import logging\n+\n+        def test_bad_log(monkeypatch):\n+            monkeypatch.setattr(logging, 'raiseExceptions', False)\n+            logging.warning('oops', 'first', 2)\n+        \"\"\"\n+    )\n+    result = testdir.runpytest()\n+    result.assert_outcomes(passed=1)\n",
  "problem_statement": "warn when logging fails\n```python\r\ndef func():\r\n    logging.error(\"%s\" , \"a\", \"b\")\r\n\r\ndef test_func():\r\n    func()\r\n```\r\n\r\nNow an expectation will be thrown and written on the output... but no warning is thrown... so the test run can't be marked as failed. ðŸ¤” \n",
  "hints_text": "this is the logging default behaviour\r\n\r\n```pycon\r\n>>> import logging\r\n>>> logging.error(\"%s\" , \"a\", \"b\")\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"/usr/lib64/python3.7/logging/__init__.py\", line 1025, in emit\r\n    msg = self.format(record)\r\n  File \"/usr/lib64/python3.7/logging/__init__.py\", line 869, in format\r\n    return fmt.format(record)\r\n  File \"/usr/lib64/python3.7/logging/__init__.py\", line 608, in format\r\n    record.message = record.getMessage()\r\n  File \"/usr/lib64/python3.7/logging/__init__.py\", line 369, in getMessage\r\n    msg = msg % self.args\r\nTypeError: not all arguments converted during string formatting\r\nCall stack:\r\n  File \"<stdin>\", line 1, in <module>\r\nMessage: '%s'\r\nArguments: ('a', 'b')\r\n>>> \r\n```\r\n\r\nso we need  a more out of band handling for logging errors\nAs far as I can see the ``logging.error`` is not shown if test is passed. But if test fails ``Captured stderr call`` is printed and looks like default behaviour presented by @RonnyPfannschmidt. How exactly should the expected result look like?\nThis is the expected result for wrong calls to logging\n\nIt should how alway fail the test ",
  "created_at": "2020-05-19T08:17:40Z",
  "version": "5.4",
  "FAIL_TO_PASS": "[\"testing/logging/test_reporting.py::test_logging_emit_error\"]",
  "PASS_TO_PASS": "[\"[100%]\", \"[\", \"[100%]------------------------------\", \"testing/logging/test_reporting.py::test_live_logging_suspends_capture[True]\", \"testing/logging/test_reporting.py::test_live_logging_suspends_capture[False]\", \"testing/logging/test_reporting.py::test_nothing_logged\", \"testing/logging/test_reporting.py::test_messages_logged\", \"testing/logging/test_reporting.py::test_root_logger_affected\", \"testing/logging/test_reporting.py::test_log_cli_level_log_level_interaction\", \"testing/logging/test_reporting.py::test_setup_logging\", \"testing/logging/test_reporting.py::test_teardown_logging\", \"testing/logging/test_reporting.py::test_log_cli_enabled_disabled[True]\", \"testing/logging/test_reporting.py::test_log_cli_enabled_disabled[False]\", \"testing/logging/test_reporting.py::test_log_cli_default_level\", \"testing/logging/test_reporting.py::test_log_cli_default_level_multiple_tests\", \"testing/logging/test_reporting.py::test_log_cli_default_level_sections\", \"testing/logging/test_reporting.py::test_live_logs_unknown_sections\", \"testing/logging/test_reporting.py::test_sections_single_new_line_after_test_outcome\", \"testing/logging/test_reporting.py::test_log_cli_level\", \"testing/logging/test_reporting.py::test_log_cli_ini_level\", \"testing/logging/test_reporting.py::test_log_cli_auto_enable[]\", \"testing/logging/test_reporting.py::test_log_cli_auto_enable[--log-level=WARNING]\", \"testing/logging/test_reporting.py::test_log_cli_auto_enable[--log-file-level=WARNING]\", \"testing/logging/test_reporting.py::test_log_cli_auto_enable[--log-cli-level=WARNING]\", \"testing/logging/test_reporting.py::test_log_file_cli\", \"testing/logging/test_reporting.py::test_log_file_cli_level\", \"testing/logging/test_reporting.py::test_log_level_not_changed_by_default\", \"testing/logging/test_reporting.py::test_log_file_ini\", \"testing/logging/test_reporting.py::test_log_file_ini_level\", \"testing/logging/test_reporting.py::test_log_file_unicode\", \"testing/logging/test_reporting.py::test_collection_live_logging\", \"testing/logging/test_reporting.py::test_collection_collect_only_live_logging[]\", \"testing/logging/test_reporting.py::test_collection_collect_only_live_logging[-q]\", \"testing/logging/test_reporting.py::test_collection_collect_only_live_logging[-qq]\", \"testing/logging/test_reporting.py::test_collection_logging_to_file\", \"testing/logging/test_reporting.py::test_log_in_hooks\", \"testing/logging/test_reporting.py::test_log_in_runtest_logreport\", \"testing/logging/test_reporting.py::test_log_set_path\", \"testing/logging/test_reporting.py::test_colored_captured_log\", \"testing/logging/test_reporting.py::test_colored_ansi_esc_caplogtext\", \"testing/logging/test_reporting.py::test_logging_emit_error_supressed\"]",
  "environment_setup_commit": "678c1a0745f1cf175c442c719906a1f13e496910",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.935308",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}