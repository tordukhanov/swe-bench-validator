{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-25697",
  "base_commit": "097c3683a73c5805a84e6eada71e4928cb35496e",
  "patch": "diff --git a/sklearn/linear_model/_bayes.py b/sklearn/linear_model/_bayes.py\n--- a/sklearn/linear_model/_bayes.py\n+++ b/sklearn/linear_model/_bayes.py\n@@ -5,6 +5,7 @@\n # Authors: V. Michel, F. Pedregosa, A. Gramfort\n # License: BSD 3 clause\n \n+import warnings\n from math import log\n from numbers import Integral, Real\n import numpy as np\n@@ -15,7 +16,49 @@\n from ..utils.extmath import fast_logdet\n from scipy.linalg import pinvh\n from ..utils.validation import _check_sample_weight\n-from ..utils._param_validation import Interval\n+from ..utils._param_validation import Interval, Hidden, StrOptions\n+\n+\n+# TODO(1.5) Remove\n+def _deprecate_n_iter(n_iter, max_iter):\n+    \"\"\"Deprecates n_iter in favour of max_iter. Checks if the n_iter has been\n+    used instead of max_iter and generates a deprecation warning if True.\n+\n+    Parameters\n+    ----------\n+    n_iter : int,\n+        Value of n_iter attribute passed by the estimator.\n+\n+    max_iter : int, default=None\n+        Value of max_iter attribute passed by the estimator.\n+        If `None`, it corresponds to `max_iter=300`.\n+\n+    Returns\n+    -------\n+    max_iter : int,\n+        Value of max_iter which shall further be used by the estimator.\n+\n+    Notes\n+    -----\n+    This function should be completely removed in 1.5.\n+    \"\"\"\n+    if n_iter != \"deprecated\":\n+        if max_iter is not None:\n+            raise ValueError(\n+                \"Both `n_iter` and `max_iter` attributes were set. Attribute\"\n+                \" `n_iter` was deprecated in version 1.3 and will be removed in\"\n+                \" 1.5. To avoid this error, only set the `max_iter` attribute.\"\n+            )\n+        warnings.warn(\n+            \"'n_iter' was renamed to 'max_iter' in version 1.3 and \"\n+            \"will be removed in 1.5\",\n+            FutureWarning,\n+        )\n+        max_iter = n_iter\n+    elif max_iter is None:\n+        max_iter = 300\n+    return max_iter\n+\n \n ###############################################################################\n # BayesianRidge regression\n@@ -32,8 +75,12 @@ class BayesianRidge(RegressorMixin, LinearModel):\n \n     Parameters\n     ----------\n-    n_iter : int, default=300\n-        Maximum number of iterations. Should be greater than or equal to 1.\n+    max_iter : int, default=None\n+        Maximum number of iterations over the complete dataset before\n+        stopping independently of any early stopping criterion. If `None`, it\n+        corresponds to `max_iter=300`.\n+\n+        .. versionchanged:: 1.3\n \n     tol : float, default=1e-3\n         Stop the algorithm if w has converged.\n@@ -83,6 +130,13 @@ class BayesianRidge(RegressorMixin, LinearModel):\n     verbose : bool, default=False\n         Verbose mode when fitting the model.\n \n+    n_iter : int\n+        Maximum number of iterations. Should be greater than or equal to 1.\n+\n+        .. deprecated:: 1.3\n+           `n_iter` is deprecated in 1.3 and will be removed in 1.5. Use\n+           `max_iter` instead.\n+\n     Attributes\n     ----------\n     coef_ : array-like of shape (n_features,)\n@@ -90,7 +144,7 @@ class BayesianRidge(RegressorMixin, LinearModel):\n \n     intercept_ : float\n         Independent term in decision function. Set to 0.0 if\n-        ``fit_intercept = False``.\n+        `fit_intercept = False`.\n \n     alpha_ : float\n        Estimated precision of the noise.\n@@ -162,7 +216,7 @@ class BayesianRidge(RegressorMixin, LinearModel):\n     \"\"\"\n \n     _parameter_constraints: dict = {\n-        \"n_iter\": [Interval(Integral, 1, None, closed=\"left\")],\n+        \"max_iter\": [Interval(Integral, 1, None, closed=\"left\"), None],\n         \"tol\": [Interval(Real, 0, None, closed=\"neither\")],\n         \"alpha_1\": [Interval(Real, 0, None, closed=\"left\")],\n         \"alpha_2\": [Interval(Real, 0, None, closed=\"left\")],\n@@ -174,12 +228,16 @@ class BayesianRidge(RegressorMixin, LinearModel):\n         \"fit_intercept\": [\"boolean\"],\n         \"copy_X\": [\"boolean\"],\n         \"verbose\": [\"verbose\"],\n+        \"n_iter\": [\n+            Interval(Integral, 1, None, closed=\"left\"),\n+            Hidden(StrOptions({\"deprecated\"})),\n+        ],\n     }\n \n     def __init__(\n         self,\n         *,\n-        n_iter=300,\n+        max_iter=None,  # TODO(1.5): Set to 300\n         tol=1.0e-3,\n         alpha_1=1.0e-6,\n         alpha_2=1.0e-6,\n@@ -191,8 +249,9 @@ def __init__(\n         fit_intercept=True,\n         copy_X=True,\n         verbose=False,\n+        n_iter=\"deprecated\",  # TODO(1.5): Remove\n     ):\n-        self.n_iter = n_iter\n+        self.max_iter = max_iter\n         self.tol = tol\n         self.alpha_1 = alpha_1\n         self.alpha_2 = alpha_2\n@@ -204,6 +263,7 @@ def __init__(\n         self.fit_intercept = fit_intercept\n         self.copy_X = copy_X\n         self.verbose = verbose\n+        self.n_iter = n_iter\n \n     def fit(self, X, y, sample_weight=None):\n         \"\"\"Fit the model.\n@@ -228,6 +288,8 @@ def fit(self, X, y, sample_weight=None):\n         \"\"\"\n         self._validate_params()\n \n+        max_iter = _deprecate_n_iter(self.n_iter, self.max_iter)\n+\n         X, y = self._validate_data(X, y, dtype=[np.float64, np.float32], y_numeric=True)\n \n         if sample_weight is not None:\n@@ -274,7 +336,7 @@ def fit(self, X, y, sample_weight=None):\n         eigen_vals_ = S**2\n \n         # Convergence loop of the bayesian ridge regression\n-        for iter_ in range(self.n_iter):\n+        for iter_ in range(max_iter):\n \n             # update posterior mean coef_ based on alpha_ and lambda_ and\n             # compute corresponding rmse\n@@ -430,8 +492,10 @@ class ARDRegression(RegressorMixin, LinearModel):\n \n     Parameters\n     ----------\n-    n_iter : int, default=300\n-        Maximum number of iterations.\n+    max_iter : int, default=None\n+        Maximum number of iterations. If `None`, it corresponds to `max_iter=300`.\n+\n+        .. versionchanged:: 1.3\n \n     tol : float, default=1e-3\n         Stop the algorithm if w has converged.\n@@ -470,6 +534,13 @@ class ARDRegression(RegressorMixin, LinearModel):\n     verbose : bool, default=False\n         Verbose mode when fitting the model.\n \n+    n_iter : int\n+        Maximum number of iterations.\n+\n+        .. deprecated:: 1.3\n+           `n_iter` is deprecated in 1.3 and will be removed in 1.5. Use\n+           `max_iter` instead.\n+\n     Attributes\n     ----------\n     coef_ : array-like of shape (n_features,)\n@@ -487,6 +558,11 @@ class ARDRegression(RegressorMixin, LinearModel):\n     scores_ : float\n         if computed, value of the objective function (to be maximized)\n \n+    n_iter_ : int\n+        The actual number of iterations to reach the stopping criterion.\n+\n+        .. versionadded:: 1.3\n+\n     intercept_ : float\n         Independent term in decision function. Set to 0.0 if\n         ``fit_intercept = False``.\n@@ -542,7 +618,7 @@ class ARDRegression(RegressorMixin, LinearModel):\n     \"\"\"\n \n     _parameter_constraints: dict = {\n-        \"n_iter\": [Interval(Integral, 1, None, closed=\"left\")],\n+        \"max_iter\": [Interval(Integral, 1, None, closed=\"left\"), None],\n         \"tol\": [Interval(Real, 0, None, closed=\"left\")],\n         \"alpha_1\": [Interval(Real, 0, None, closed=\"left\")],\n         \"alpha_2\": [Interval(Real, 0, None, closed=\"left\")],\n@@ -553,12 +629,16 @@ class ARDRegression(RegressorMixin, LinearModel):\n         \"fit_intercept\": [\"boolean\"],\n         \"copy_X\": [\"boolean\"],\n         \"verbose\": [\"verbose\"],\n+        \"n_iter\": [\n+            Interval(Integral, 1, None, closed=\"left\"),\n+            Hidden(StrOptions({\"deprecated\"})),\n+        ],\n     }\n \n     def __init__(\n         self,\n         *,\n-        n_iter=300,\n+        max_iter=None,  # TODO(1.5): Set to 300\n         tol=1.0e-3,\n         alpha_1=1.0e-6,\n         alpha_2=1.0e-6,\n@@ -569,8 +649,9 @@ def __init__(\n         fit_intercept=True,\n         copy_X=True,\n         verbose=False,\n+        n_iter=\"deprecated\",  # TODO(1.5): Remove\n     ):\n-        self.n_iter = n_iter\n+        self.max_iter = max_iter\n         self.tol = tol\n         self.fit_intercept = fit_intercept\n         self.alpha_1 = alpha_1\n@@ -581,6 +662,7 @@ def __init__(\n         self.threshold_lambda = threshold_lambda\n         self.copy_X = copy_X\n         self.verbose = verbose\n+        self.n_iter = n_iter\n \n     def fit(self, X, y):\n         \"\"\"Fit the model according to the given training data and parameters.\n@@ -603,6 +685,8 @@ def fit(self, X, y):\n \n         self._validate_params()\n \n+        max_iter = _deprecate_n_iter(self.n_iter, self.max_iter)\n+\n         X, y = self._validate_data(\n             X, y, dtype=[np.float64, np.float32], y_numeric=True, ensure_min_samples=2\n         )\n@@ -648,7 +732,7 @@ def update_coeff(X, y, coef_, alpha_, keep_lambda, sigma_):\n             else self._update_sigma_woodbury\n         )\n         # Iterative procedure of ARDRegression\n-        for iter_ in range(self.n_iter):\n+        for iter_ in range(max_iter):\n             sigma_ = update_sigma(X, alpha_, lambda_, keep_lambda)\n             coef_ = update_coeff(X, y, coef_, alpha_, keep_lambda, sigma_)\n \n@@ -688,6 +772,8 @@ def update_coeff(X, y, coef_, alpha_, keep_lambda, sigma_):\n             if not keep_lambda.any():\n                 break\n \n+        self.n_iter_ = iter_ + 1\n+\n         if keep_lambda.any():\n             # update sigma and mu using updated params from the last iteration\n             sigma_ = update_sigma(X, alpha_, lambda_, keep_lambda)\n",
  "test_patch": "diff --git a/sklearn/linear_model/tests/test_bayes.py b/sklearn/linear_model/tests/test_bayes.py\n--- a/sklearn/linear_model/tests/test_bayes.py\n+++ b/sklearn/linear_model/tests/test_bayes.py\n@@ -73,7 +73,7 @@ def test_bayesian_ridge_score_values():\n         alpha_2=alpha_2,\n         lambda_1=lambda_1,\n         lambda_2=lambda_2,\n-        n_iter=1,\n+        max_iter=1,\n         fit_intercept=False,\n         compute_score=True,\n     )\n@@ -174,7 +174,7 @@ def test_update_of_sigma_in_ard():\n     # of the ARDRegression algorithm. See issue #10128.\n     X = np.array([[1, 0], [0, 0]])\n     y = np.array([0, 0])\n-    clf = ARDRegression(n_iter=1)\n+    clf = ARDRegression(max_iter=1)\n     clf.fit(X, y)\n     # With the inputs above, ARDRegression prunes both of the two coefficients\n     # in the first iteration. Hence, the expected shape of `sigma_` is (0, 0).\n@@ -292,3 +292,33 @@ def test_dtype_correctness(Estimator):\n     coef_32 = model.fit(X.astype(np.float32), y).coef_\n     coef_64 = model.fit(X.astype(np.float64), y).coef_\n     np.testing.assert_allclose(coef_32, coef_64, rtol=1e-4)\n+\n+\n+# TODO(1.5) remove\n+@pytest.mark.parametrize(\"Estimator\", [BayesianRidge, ARDRegression])\n+def test_bayesian_ridge_ard_n_iter_deprecated(Estimator):\n+    \"\"\"Check the deprecation warning of `n_iter`.\"\"\"\n+    depr_msg = (\n+        \"'n_iter' was renamed to 'max_iter' in version 1.3 and will be removed in 1.5\"\n+    )\n+    X, y = diabetes.data, diabetes.target\n+    model = Estimator(n_iter=5)\n+\n+    with pytest.warns(FutureWarning, match=depr_msg):\n+        model.fit(X, y)\n+\n+\n+# TODO(1.5) remove\n+@pytest.mark.parametrize(\"Estimator\", [BayesianRidge, ARDRegression])\n+def test_bayesian_ridge_ard_max_iter_and_n_iter_both_set(Estimator):\n+    \"\"\"Check that a ValueError is raised when both `max_iter` and `n_iter` are set.\"\"\"\n+    err_msg = (\n+        \"Both `n_iter` and `max_iter` attributes were set. Attribute\"\n+        \" `n_iter` was deprecated in version 1.3 and will be removed in\"\n+        \" 1.5. To avoid this error, only set the `max_iter` attribute.\"\n+    )\n+    X, y = diabetes.data, diabetes.target\n+    model = Estimator(n_iter=5, max_iter=5)\n+\n+    with pytest.raises(ValueError, match=err_msg):\n+        model.fit(X, y)\n",
  "problem_statement": "Deprecate `n_iter` in favor of `max_iter` for consistency\n`BayesianRidge` and `ARDRegression` are exposing the parameter `n_iter` instead of `max_iter` as in other models. I think that we should deprecate `n_iter` and rename it `max_iter` to be consistent.\n",
  "hints_text": "@glemaitre I would like to attempt this one !\n@saucam please go ahead and propose a pull-request. You can refer to the following documentation page to follow our deprecation rule: https://scikit-learn.org/dev/developers/contributing.html#deprecation\n@saucam ,let me know incase you need help. We can work together on this issue if it is fine with you. \n@jpangas sorry but I lost track of this one. You can go ahead with your changes as it looks like you already have some progress.\nThank you for getting back to me. I am working on the changes, should be done within the week. ",
  "created_at": "2023-02-24T21:43:48Z",
  "version": "1.3",
  "FAIL_TO_PASS": "[\"sklearn/linear_model/tests/test_bayes.py::test_bayesian_ridge_score_values\", \"sklearn/linear_model/tests/test_bayes.py::test_update_of_sigma_in_ard\", \"sklearn/linear_model/tests/test_bayes.py::test_bayesian_ridge_ard_n_iter_deprecated[BayesianRidge]\", \"sklearn/linear_model/tests/test_bayes.py::test_bayesian_ridge_ard_n_iter_deprecated[ARDRegression]\", \"sklearn/linear_model/tests/test_bayes.py::test_bayesian_ridge_ard_max_iter_and_n_iter_both_set[BayesianRidge]\", \"sklearn/linear_model/tests/test_bayes.py::test_bayesian_ridge_ard_max_iter_and_n_iter_both_set[ARDRegression]\"]",
  "PASS_TO_PASS": "[\"sklearn/linear_model/tests/test_bayes.py::test_bayesian_ridge_scores\", \"sklearn/linear_model/tests/test_bayes.py::test_bayesian_ridge_parameter\", \"sklearn/linear_model/tests/test_bayes.py::test_bayesian_sample_weights\", \"sklearn/linear_model/tests/test_bayes.py::test_toy_bayesian_ridge_object\", \"sklearn/linear_model/tests/test_bayes.py::test_bayesian_initial_params\", \"sklearn/linear_model/tests/test_bayes.py::test_prediction_bayesian_ridge_ard_with_constant_input\", \"sklearn/linear_model/tests/test_bayes.py::test_std_bayesian_ridge_ard_with_constant_input\", \"sklearn/linear_model/tests/test_bayes.py::test_toy_ard_object\", \"sklearn/linear_model/tests/test_bayes.py::test_ard_accuracy_on_easy_problem[42-10-100]\", \"sklearn/linear_model/tests/test_bayes.py::test_ard_accuracy_on_easy_problem[42-100-10]\", \"sklearn/linear_model/tests/test_bayes.py::test_return_std\", \"sklearn/linear_model/tests/test_bayes.py::test_update_sigma[42]\", \"sklearn/linear_model/tests/test_bayes.py::test_dtype_match[BayesianRidge-float32]\", \"sklearn/linear_model/tests/test_bayes.py::test_dtype_match[BayesianRidge-float64]\", \"sklearn/linear_model/tests/test_bayes.py::test_dtype_match[ARDRegression-float32]\", \"sklearn/linear_model/tests/test_bayes.py::test_dtype_match[ARDRegression-float64]\", \"sklearn/linear_model/tests/test_bayes.py::test_dtype_correctness[BayesianRidge]\", \"sklearn/linear_model/tests/test_bayes.py::test_dtype_correctness[ARDRegression]\"]",
  "environment_setup_commit": "1e8a5b833d1b58f3ab84099c4582239af854b23a",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.021802",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}