{
  "repo": "django/django",
  "instance_id": "django__django-15969",
  "base_commit": "081871bc20cc8b28481109b8dcadc321e177e6be",
  "patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -1,9 +1,9 @@\n from collections import Counter, defaultdict\n-from functools import partial\n+from functools import partial, reduce\n from itertools import chain\n-from operator import attrgetter\n+from operator import attrgetter, or_\n \n-from django.db import IntegrityError, connections, transaction\n+from django.db import IntegrityError, connections, models, transaction\n from django.db.models import query_utils, signals, sql\n \n \n@@ -61,6 +61,7 @@ def set_on_delete(collector, field, sub_objs, using):\n             collector.add_field_update(field, value, sub_objs)\n \n     set_on_delete.deconstruct = lambda: (\"django.db.models.SET\", (value,), {})\n+    set_on_delete.lazy_sub_objs = True\n     return set_on_delete\n \n \n@@ -68,10 +69,16 @@ def SET_NULL(collector, field, sub_objs, using):\n     collector.add_field_update(field, None, sub_objs)\n \n \n+SET_NULL.lazy_sub_objs = True\n+\n+\n def SET_DEFAULT(collector, field, sub_objs, using):\n     collector.add_field_update(field, field.get_default(), sub_objs)\n \n \n+SET_DEFAULT.lazy_sub_objs = True\n+\n+\n def DO_NOTHING(collector, field, sub_objs, using):\n     pass\n \n@@ -93,8 +100,8 @@ def __init__(self, using, origin=None):\n         self.origin = origin\n         # Initially, {model: {instances}}, later values become lists.\n         self.data = defaultdict(set)\n-        # {model: {(field, value): {instances}}}\n-        self.field_updates = defaultdict(partial(defaultdict, set))\n+        # {(field, value): [instances, …]}\n+        self.field_updates = defaultdict(list)\n         # {model: {field: {instances}}}\n         self.restricted_objects = defaultdict(partial(defaultdict, set))\n         # fast_deletes is a list of queryset-likes that can be deleted without\n@@ -145,10 +152,7 @@ def add_field_update(self, field, value, objs):\n         Schedule a field update. 'objs' must be a homogeneous iterable\n         collection of model instances (e.g. a QuerySet).\n         \"\"\"\n-        if not objs:\n-            return\n-        model = objs[0].__class__\n-        self.field_updates[model][field, value].update(objs)\n+        self.field_updates[field, value].append(objs)\n \n     def add_restricted_objects(self, field, objs):\n         if objs:\n@@ -312,7 +316,8 @@ def collect(\n             if keep_parents and related.model in parents:\n                 continue\n             field = related.field\n-            if field.remote_field.on_delete == DO_NOTHING:\n+            on_delete = field.remote_field.on_delete\n+            if on_delete == DO_NOTHING:\n                 continue\n             related_model = related.related_model\n             if self.can_fast_delete(related_model, from_field=field):\n@@ -340,9 +345,9 @@ def collect(\n                         )\n                     )\n                     sub_objs = sub_objs.only(*tuple(referenced_fields))\n-                if sub_objs:\n+                if getattr(on_delete, \"lazy_sub_objs\", False) or sub_objs:\n                     try:\n-                        field.remote_field.on_delete(self, field, sub_objs, self.using)\n+                        on_delete(self, field, sub_objs, self.using)\n                     except ProtectedError as error:\n                         key = \"'%s.%s'\" % (field.model.__name__, field.name)\n                         protected_objects[key] += error.protected_objects\n@@ -469,11 +474,25 @@ def delete(self):\n                     deleted_counter[qs.model._meta.label] += count\n \n             # update fields\n-            for model, instances_for_fieldvalues in self.field_updates.items():\n-                for (field, value), instances in instances_for_fieldvalues.items():\n+            for (field, value), instances_list in self.field_updates.items():\n+                updates = []\n+                objs = []\n+                for instances in instances_list:\n+                    if (\n+                        isinstance(instances, models.QuerySet)\n+                        and instances._result_cache is None\n+                    ):\n+                        updates.append(instances)\n+                    else:\n+                        objs.extend(instances)\n+                if updates:\n+                    combined_updates = reduce(or_, updates)\n+                    combined_updates.update(**{field.name: value})\n+                if objs:\n+                    model = objs[0].__class__\n                     query = sql.UpdateQuery(model)\n                     query.update_batch(\n-                        [obj.pk for obj in instances], {field.name: value}, self.using\n+                        list({obj.pk for obj in objs}), {field.name: value}, self.using\n                     )\n \n             # reverse instance collections\n@@ -497,11 +516,6 @@ def delete(self):\n                             origin=self.origin,\n                         )\n \n-        # update collected instances\n-        for instances_for_fieldvalues in self.field_updates.values():\n-            for (field, value), instances in instances_for_fieldvalues.items():\n-                for obj in instances:\n-                    setattr(obj, field.attname, value)\n         for model, instances in self.data.items():\n             for instance in instances:\n                 setattr(instance, model._meta.pk.attname, None)\n",
  "test_patch": "diff --git a/tests/delete_regress/models.py b/tests/delete_regress/models.py\n--- a/tests/delete_regress/models.py\n+++ b/tests/delete_regress/models.py\n@@ -90,6 +90,12 @@ class Location(models.Model):\n class Item(models.Model):\n     version = models.ForeignKey(Version, models.CASCADE)\n     location = models.ForeignKey(Location, models.SET_NULL, blank=True, null=True)\n+    location_value = models.ForeignKey(\n+        Location, models.SET(42), default=1, db_constraint=False, related_name=\"+\"\n+    )\n+    location_default = models.ForeignKey(\n+        Location, models.SET_DEFAULT, default=1, db_constraint=False, related_name=\"+\"\n+    )\n \n \n # Models for #16128\ndiff --git a/tests/delete_regress/tests.py b/tests/delete_regress/tests.py\n--- a/tests/delete_regress/tests.py\n+++ b/tests/delete_regress/tests.py\n@@ -399,3 +399,19 @@ def test_disallowed_delete_distinct(self):\n             Book.objects.distinct().delete()\n         with self.assertRaisesMessage(TypeError, msg):\n             Book.objects.distinct(\"id\").delete()\n+\n+\n+class SetQueryCountTests(TestCase):\n+    def test_set_querycount(self):\n+        policy = Policy.objects.create()\n+        version = Version.objects.create(policy=policy)\n+        location = Location.objects.create(version=version)\n+        Item.objects.create(\n+            version=version,\n+            location=location,\n+            location_default=location,\n+            location_value=location,\n+        )\n+        # 3 UPDATEs for SET of item values and one for DELETE locations.\n+        with self.assertNumQueries(4):\n+            location.delete()\n",
  "problem_statement": "Performance issues with `on_delete=models.SET_NULL` on large tables\nDescription\n\t\nHello,\nI have the following models configuration:\nParent model\nChild model, with a parent_id foreign key to a Parent model, set with on_delete=models.SET_NULL\nEach Parent can have a lot of children, in my case roughly 30k.\nI'm starting to encounter performance issues that make my jobs timeout, because the SQL queries simply timeout.\nI've enabled query logging, and noticed something weird (that is certainly that way on purpose, but I don't understand why).\n# Select the parent\nSELECT * FROM \"parent\" WHERE \"parent\".\"id\" = 'parent123';\n# Select all children\nSELECT * FROM \"children\" WHERE \"children\".\"parent_id\" IN ('parent123');\n# Update all children `parent_id` column to `NULL`\nUPDATE \"children\" SET \"parent_id\" = NULL WHERE \"children\".\"id\" IN ('child1', 'child2', 'child3', ..., 'child30000');\n# Finally delete the parent\nDELETE FROM \"parent\" WHERE \"parent\".\"id\" IN ('parent123');\nI would have expected the update condition to simply be WHERE \"children\".\"parent_id\" = 'parent123', but for some reason it isn't.\nIn the meantime, I'll switch to on_delete=models.CASCADE, which in my case does the trick, but I was curious about the reason why this happens in the first place.\nThanks in advance\n",
  "hints_text": "You are right that is an opportunity for an optimization when SET, SET_DEFAULT, or SET_NULL is used but I wonder if it's worth doing given db_on_delete support (see #21961) make things even better for this use case. In the meantime, I'll switch to on_delete=models.CASCADE, which in my case does the trick, but I was curious about the reason why this happens in the first place. This is likely the case because the collector is able to take ​the fast delete route and avoid object fetching entirely. If you want to give a shot at a patch you'll want to have a look at Collector.collect and have it skip collection entirely when dealing with SET and friends likely by adding a branch that turns them into fast updates. ​One branch that worries me is the post-deletion assignment of values to in-memory instances but I can't understand why this is even necessary given all the instances that are collected for field updates are never make their way out of the collector so I would expect it to be entirely unnecessary at least all delete and delete_regress tests pass if I entirely remove it django/db/models/deletion.py diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py index 2cb3c88444..2eb8e95281 100644 a b def delete(self): 496496 using=self.using, 497497 origin=self.origin, 498498 ) 499 500 # update collected instances 501 for instances_for_fieldvalues in self.field_updates.values(): 502 for (field, value), instances in instances_for_fieldvalues.items(): 503 for obj in instances: 504 setattr(obj, field.attname, value) 505499 for model, instances in self.data.items(): 506500 for instance in instances: 507501 setattr(instance, model._meta.pk.attname, None) You'll want to make sure to avoid breaking the ​admin's collector subclass used to display deletion confirmation pages but from a quick look it doesn't seem to care about field updates. Tentatively accepting but I think we should revisit when #21961 lands.",
  "created_at": "2022-08-18T01:11:18Z",
  "version": "4.2",
  "FAIL_TO_PASS": "[\"test_set_querycount (delete_regress.tests.SetQueryCountTests)\"]",
  "PASS_TO_PASS": "[\"test_disallowed_delete_distinct (delete_regress.tests.DeleteDistinct)\", \"test_15776 (delete_regress.tests.DeleteCascadeTests)\", \"If an M2M relationship has an explicitly-specified through model, and\", \"Django cascades deletes through generic-related objects to their\", \"With a model (Researcher) that has two foreign keys pointing to the\", \"test_meta_ordered_delete (delete_regress.tests.DeleteTests)\", \"test_self_reference_with_through_m2m_at_second_level (delete_regress.tests.DeleteTests)\", \"test_19187_values (delete_regress.tests.ProxyDeleteTest)\", \"Deleting an instance of a concrete model should also delete objects\", \"Deleting the *proxy* instance bubbles through to its non-proxy and\", \"Deleting a proxy-of-proxy instance should bubble through to its proxy\", \"If a pair of proxy models are linked by an FK from one concrete parent\", \"test_ticket_19102_annotate (delete_regress.tests.Ticket19102Tests)\", \"test_ticket_19102_defer (delete_regress.tests.Ticket19102Tests)\", \"test_ticket_19102_extra (delete_regress.tests.Ticket19102Tests)\", \"test_ticket_19102_select_related (delete_regress.tests.Ticket19102Tests)\", \"If the number of objects > chunk size, deletion still occurs.\", \"Auto-created many-to-many through tables referencing a parent model are\", \"Cascade deletion works with ForeignKey.to_field set to non-PK.\"]",
  "environment_setup_commit": "0fbdb9784da915fce5dcc1fe82bac9b4785749e5",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.743526",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}