{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-25589",
  "base_commit": "53e0d95cb10cba5827751657e487f792afd94329",
  "patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -270,6 +270,10 @@ class OneHotEncoder(_BaseEncoder):\n         - array : ``drop[i]`` is the category in feature ``X[:, i]`` that\n           should be dropped.\n \n+        When `max_categories` or `min_frequency` is configured to group\n+        infrequent categories, the dropping behavior is handled after the\n+        grouping.\n+\n         .. versionadded:: 0.21\n            The parameter `drop` was added in 0.21.\n \n@@ -544,7 +548,7 @@ def _map_drop_idx_to_infrequent(self, feature_idx, drop_idx):\n         \"\"\"Convert `drop_idx` into the index for infrequent categories.\n \n         If there are no infrequent categories, then `drop_idx` is\n-        returned. This method is called in `_compute_drop_idx` when the `drop`\n+        returned. This method is called in `_set_drop_idx` when the `drop`\n         parameter is an array-like.\n         \"\"\"\n         if not self._infrequent_enabled:\n@@ -564,24 +568,35 @@ def _map_drop_idx_to_infrequent(self, feature_idx, drop_idx):\n             )\n         return default_to_infrequent[drop_idx]\n \n-    def _compute_drop_idx(self):\n+    def _set_drop_idx(self):\n         \"\"\"Compute the drop indices associated with `self.categories_`.\n \n         If `self.drop` is:\n-        - `None`, returns `None`.\n-        - `'first'`, returns all zeros to drop the first category.\n-        - `'if_binary'`, returns zero if the category is binary and `None`\n+        - `None`, No categories have been dropped.\n+        - `'first'`, All zeros to drop the first category.\n+        - `'if_binary'`, All zeros if the category is binary and `None`\n           otherwise.\n-        - array-like, returns the indices of the categories that match the\n+        - array-like, The indices of the categories that match the\n           categories in `self.drop`. If the dropped category is an infrequent\n           category, then the index for the infrequent category is used. This\n           means that the entire infrequent category is dropped.\n+\n+        This methods defines a public `drop_idx_` and a private\n+        `_drop_idx_after_grouping`.\n+\n+        - `drop_idx_`: Public facing API that references the drop category in\n+          `self.categories_`.\n+        - `_drop_idx_after_grouping`: Used internally to drop categories *after* the\n+          infrequent categories are grouped together.\n+\n+        If there are no infrequent categories or drop is `None`, then\n+        `drop_idx_=_drop_idx_after_grouping`.\n         \"\"\"\n         if self.drop is None:\n-            return None\n+            drop_idx_after_grouping = None\n         elif isinstance(self.drop, str):\n             if self.drop == \"first\":\n-                return np.zeros(len(self.categories_), dtype=object)\n+                drop_idx_after_grouping = np.zeros(len(self.categories_), dtype=object)\n             elif self.drop == \"if_binary\":\n                 n_features_out_no_drop = [len(cat) for cat in self.categories_]\n                 if self._infrequent_enabled:\n@@ -590,7 +605,7 @@ def _compute_drop_idx(self):\n                             continue\n                         n_features_out_no_drop[i] -= infreq_idx.size - 1\n \n-                return np.array(\n+                drop_idx_after_grouping = np.array(\n                     [\n                         0 if n_features_out == 2 else None\n                         for n_features_out in n_features_out_no_drop\n@@ -647,7 +662,29 @@ def _compute_drop_idx(self):\n                     )\n                 )\n                 raise ValueError(msg)\n-            return np.array(drop_indices, dtype=object)\n+            drop_idx_after_grouping = np.array(drop_indices, dtype=object)\n+\n+        # `_drop_idx_after_grouping` are the categories to drop *after* the infrequent\n+        # categories are grouped together. If needed, we remap `drop_idx` back\n+        # to the categories seen in `self.categories_`.\n+        self._drop_idx_after_grouping = drop_idx_after_grouping\n+\n+        if not self._infrequent_enabled or drop_idx_after_grouping is None:\n+            self.drop_idx_ = self._drop_idx_after_grouping\n+        else:\n+            drop_idx_ = []\n+            for feature_idx, drop_idx in enumerate(drop_idx_after_grouping):\n+                default_to_infrequent = self._default_to_infrequent_mappings[\n+                    feature_idx\n+                ]\n+                if drop_idx is None or default_to_infrequent is None:\n+                    orig_drop_idx = drop_idx\n+                else:\n+                    orig_drop_idx = np.flatnonzero(default_to_infrequent == drop_idx)[0]\n+\n+                drop_idx_.append(orig_drop_idx)\n+\n+            self.drop_idx_ = np.asarray(drop_idx_, dtype=object)\n \n     def _identify_infrequent(self, category_count, n_samples, col_idx):\n         \"\"\"Compute the infrequent indices.\n@@ -809,16 +846,19 @@ def _compute_transformed_categories(self, i, remove_dropped=True):\n \n     def _remove_dropped_categories(self, categories, i):\n         \"\"\"Remove dropped categories.\"\"\"\n-        if self.drop_idx_ is not None and self.drop_idx_[i] is not None:\n-            return np.delete(categories, self.drop_idx_[i])\n+        if (\n+            self._drop_idx_after_grouping is not None\n+            and self._drop_idx_after_grouping[i] is not None\n+        ):\n+            return np.delete(categories, self._drop_idx_after_grouping[i])\n         return categories\n \n     def _compute_n_features_outs(self):\n         \"\"\"Compute the n_features_out for each input feature.\"\"\"\n         output = [len(cats) for cats in self.categories_]\n \n-        if self.drop_idx_ is not None:\n-            for i, drop_idx in enumerate(self.drop_idx_):\n+        if self._drop_idx_after_grouping is not None:\n+            for i, drop_idx in enumerate(self._drop_idx_after_grouping):\n                 if drop_idx is not None:\n                     output[i] -= 1\n \n@@ -875,7 +915,7 @@ def fit(self, X, y=None):\n             self._fit_infrequent_category_mapping(\n                 fit_results[\"n_samples\"], fit_results[\"category_counts\"]\n             )\n-        self.drop_idx_ = self._compute_drop_idx()\n+        self._set_drop_idx()\n         self._n_features_outs = self._compute_n_features_outs()\n         return self\n \n@@ -914,8 +954,8 @@ def transform(self, X):\n \n         n_samples, n_features = X_int.shape\n \n-        if self.drop_idx_ is not None:\n-            to_drop = self.drop_idx_.copy()\n+        if self._drop_idx_after_grouping is not None:\n+            to_drop = self._drop_idx_after_grouping.copy()\n             # We remove all the dropped categories from mask, and decrement all\n             # categories that occur after them to avoid an empty column.\n             keep_cells = X_int != to_drop\n@@ -1014,7 +1054,7 @@ def inverse_transform(self, X):\n             # category. In this case we just fill the column with this\n             # unique category value.\n             if n_categories == 0:\n-                X_tr[:, i] = self.categories_[i][self.drop_idx_[i]]\n+                X_tr[:, i] = self.categories_[i][self._drop_idx_after_grouping[i]]\n                 j += n_categories\n                 continue\n             sub = X[:, j : j + n_categories]\n@@ -1031,14 +1071,19 @@ def inverse_transform(self, X):\n                 if unknown.any():\n                     # if categories were dropped then unknown categories will\n                     # be mapped to the dropped category\n-                    if self.drop_idx_ is None or self.drop_idx_[i] is None:\n+                    if (\n+                        self._drop_idx_after_grouping is None\n+                        or self._drop_idx_after_grouping[i] is None\n+                    ):\n                         found_unknown[i] = unknown\n                     else:\n-                        X_tr[unknown, i] = self.categories_[i][self.drop_idx_[i]]\n+                        X_tr[unknown, i] = self.categories_[i][\n+                            self._drop_idx_after_grouping[i]\n+                        ]\n             else:\n                 dropped = np.asarray(sub.sum(axis=1) == 0).flatten()\n                 if dropped.any():\n-                    if self.drop_idx_ is None:\n+                    if self._drop_idx_after_grouping is None:\n                         all_zero_samples = np.flatnonzero(dropped)\n                         raise ValueError(\n                             f\"Samples {all_zero_samples} can not be inverted \"\n@@ -1047,7 +1092,7 @@ def inverse_transform(self, X):\n                         )\n                     # we can safely assume that all of the nulls in each column\n                     # are the dropped value\n-                    drop_idx = self.drop_idx_[i]\n+                    drop_idx = self._drop_idx_after_grouping[i]\n                     X_tr[dropped, i] = transformed_features[i][drop_idx]\n \n             j += n_categories\n",
  "test_patch": "diff --git a/sklearn/preprocessing/tests/test_encoders.py b/sklearn/preprocessing/tests/test_encoders.py\n--- a/sklearn/preprocessing/tests/test_encoders.py\n+++ b/sklearn/preprocessing/tests/test_encoders.py\n@@ -929,7 +929,7 @@ def test_ohe_infrequent_two_levels_drop_frequent(drop):\n         max_categories=2,\n         drop=drop,\n     ).fit(X_train)\n-    assert_array_equal(ohe.drop_idx_, [0])\n+    assert ohe.categories_[0][ohe.drop_idx_[0]] == \"b\"\n \n     X_test = np.array([[\"b\"], [\"c\"]])\n     X_trans = ohe.transform(X_test)\n@@ -2015,3 +2015,39 @@ def test_ordinal_encoder_missing_unknown_encoding_max():\n     X_test = np.array([[\"snake\"]])\n     X_trans = enc.transform(X_test)\n     assert_allclose(X_trans, [[2]])\n+\n+\n+def test_drop_idx_infrequent_categories():\n+    \"\"\"Check drop_idx is defined correctly with infrequent categories.\n+\n+    Non-regression test for gh-25550.\n+    \"\"\"\n+    X = np.array(\n+        [[\"a\"] * 2 + [\"b\"] * 4 + [\"c\"] * 4 + [\"d\"] * 4 + [\"e\"] * 4], dtype=object\n+    ).T\n+    ohe = OneHotEncoder(min_frequency=4, sparse_output=False, drop=\"first\").fit(X)\n+    assert_array_equal(\n+        ohe.get_feature_names_out(), [\"x0_c\", \"x0_d\", \"x0_e\", \"x0_infrequent_sklearn\"]\n+    )\n+    assert ohe.categories_[0][ohe.drop_idx_[0]] == \"b\"\n+\n+    X = np.array([[\"a\"] * 2 + [\"b\"] * 2 + [\"c\"] * 10], dtype=object).T\n+    ohe = OneHotEncoder(min_frequency=4, sparse_output=False, drop=\"if_binary\").fit(X)\n+    assert_array_equal(ohe.get_feature_names_out(), [\"x0_infrequent_sklearn\"])\n+    assert ohe.categories_[0][ohe.drop_idx_[0]] == \"c\"\n+\n+    X = np.array(\n+        [[\"a\"] * 2 + [\"b\"] * 4 + [\"c\"] * 4 + [\"d\"] * 4 + [\"e\"] * 4], dtype=object\n+    ).T\n+    ohe = OneHotEncoder(min_frequency=4, sparse_output=False, drop=[\"d\"]).fit(X)\n+    assert_array_equal(\n+        ohe.get_feature_names_out(), [\"x0_b\", \"x0_c\", \"x0_e\", \"x0_infrequent_sklearn\"]\n+    )\n+    assert ohe.categories_[0][ohe.drop_idx_[0]] == \"d\"\n+\n+    ohe = OneHotEncoder(min_frequency=4, sparse_output=False, drop=None).fit(X)\n+    assert_array_equal(\n+        ohe.get_feature_names_out(),\n+        [\"x0_b\", \"x0_c\", \"x0_d\", \"x0_e\", \"x0_infrequent_sklearn\"],\n+    )\n+    assert ohe.drop_idx_ is None\n",
  "problem_statement": "OneHotEncoder `drop_idx_` attribute description in presence of infrequent categories\n### Describe the issue linked to the documentation\r\n\r\n### Issue summary\r\n\r\nIn the OneHotEncoder documentation both for [v1.2](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) and [v1.1](https://scikit-learn.org/1.1/modules/generated/sklearn.preprocessing.OneHotEncoder.html?highlight=one+hot+encoder#sklearn.preprocessing.OneHotEncoder), the description of attribute `drop_idx_` in presence of infrequent categories reads as follows:\r\n\r\n> If infrequent categories are enabled by setting `min_frequency` or `max_categories` to a non-default value and `drop_idx[i]` corresponds to a infrequent category, then the entire infrequent category is dropped.`\r\n\r\n### User interpretation\r\n\r\nMy understanding of this description is that when `drop_idx_[i]` corresponds to an infrequent category for column `i`, then the expected encoded column `i_infrequent_sklearn` is dropped. For example, suppose we have the following situation:\r\n```\r\n>>> X = np.array([['a'] * 2 + ['b'] * 4 + ['c'] * 4\r\n...               + ['d'] * 4 + ['e'] * 4], dtype=object).T\r\n>>> enc = preprocessing.OneHotEncoder(min_frequency=4, sparse_output=False, drop='first')\r\n```\r\nHere `X` is a column with five categories where category `a` is considered infrequent. If the above interpretation is correct, then the expected output will consist of four columns, namely, `x0_b`, `x0_c`, `x0_d` and `x0_e`. This is because `a` is both the first category to get dropped due to `drop='first'` as well as an infrequent one. However, the transform output is as follows:\r\n```\r\n>>> Xt = enc.fit_transform(X)\r\n>>> pd.DataFrame(Xt, columns = enc.get_feature_names_out())\r\nent_categories_\r\n    x0_c  x0_d  x0_e  x0_infrequent_sklearn\r\n0    0.0   0.0   0.0                    1.0\r\n1    0.0   0.0   0.0                    1.0\r\n2    0.0   0.0   0.0                    0.0\r\n3    0.0   0.0   0.0                    0.0\r\n4    0.0   0.0   0.0                    0.0\r\n5    0.0   0.0   0.0                    0.0\r\n6    1.0   0.0   0.0                    0.0\r\n7    1.0   0.0   0.0                    0.0\r\n8    1.0   0.0   0.0                    0.0\r\n9    1.0   0.0   0.0                    0.0\r\n10   0.0   1.0   0.0                    0.0\r\n11   0.0   1.0   0.0                    0.0\r\n12   0.0   1.0   0.0                    0.0\r\n13   0.0   1.0   0.0                    0.0\r\n14   0.0   0.0   1.0                    0.0\r\n15   0.0   0.0   1.0                    0.0\r\n16   0.0   0.0   1.0                    0.0\r\n17   0.0   0.0   1.0                    0.0\r\n```\r\nThis means that category `a` is part of the `x0_infrequent_sklearn` column, which takes the value of `1` when `X=='a'`. Category `b` is dropped, this is expected since the `drop='first'` functionality drops the column indexed `0` and after the `_encode` function is applied, categories are remapped based on their sorting order and infrequent ones are mapped last. Meaning that `'a'->4, 'b'->0, 'c'->1, 'd'->2, 'e'->3. This can be verified by the following objects:\r\n```\r\n>>> enc.categories_\r\n[array(['a', 'b', 'c', 'd', 'e'], dtype=object)]\r\n>>> enc._default_to_infrequent_mappings\r\n[array([4, 0, 1, 2, 3])]\r\n```\r\nNotice how at transform the values of the encoded columns are `0` when `X=='b'`. Finally, columns `x0_c`, `x0_d` and `x0_e` are encoded as expected.\r\n\r\n### Suggest a potential alternative/fix\r\n\r\n### Correct suggestive description based on what is actually happening.\r\n\r\n> If infrequent categories are enabled by setting `min_frequency` or `max_categories` to a non-default value and `drop_idx_[i]` corresponds to a infrequent category, then the \"first\", i.e., indexed `0`, frequent category is dropped after `_encode` is applied during `_transform`.\n",
  "hints_text": "Thank you for opening the issue! In this case, API-wise I think `drop_idx` is defined incorrectly and should be `1` point to `b`, because it is the categorical that is actually dropped. \r\n\r\nThere seems to be a bigger issue with how `drop_idx` is defined when there are any infrequent categories. I am looking into a fix.",
  "created_at": "2023-02-10T17:30:04Z",
  "version": "1.3",
  "FAIL_TO_PASS": "[\"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_drop_frequent[if_binary]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_drop_frequent[first]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_drop_frequent[drop2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_drop_idx_infrequent_categories\"]",
  "PASS_TO_PASS": "[\"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_sparse_dense\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown[ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown[infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_not_fitted\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown_strings[ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown_strings[infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_unicode\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_custom_feature_name_combiner\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_set_params\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed-nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed-float-nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed-None]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed-None-nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed-None-float-nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[None-False-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[None-False-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[None-True-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[None-True-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[first-False-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[first-False-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[first-True-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse[first-True-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse_transform_raise_error_with_unknown[X0-X_trans0-False]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse_transform_raise_error_with_unknown[X0-X_trans0-True]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse_transform_raise_error_with_unknown[X1-X_trans1-False]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse_transform_raise_error_with_unknown[X1-X_trans1-True]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse_if_binary\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[if_binary-if_binary]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[if_binary-first]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[if_binary-None]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[first-if_binary]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[first-first]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[first-None]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[None-if_binary]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[None-first]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_reset[None-None]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X0-fit]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X0-fit_transform]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X1-fit]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D[X1-fit_transform]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D_pandas[fit]\", \"sklearn/preprocessing/tests/test_encoders.py::test_X_is_not_1D_pandas[fit_transform]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[string]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[missing-float]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[missing-np.nan-object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[missing-float-nan-object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[numeric-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[numeric-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-none-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-none-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-nan-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-nan-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-None-and-nan-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-None-and-nan-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-nan-and-None-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-nan-and-None-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_unsorted_categories\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories_mixed_columns\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_drop[first]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_drop[binary]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_drop[manual]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_equals_if_binary\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories[object-string-cat]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_inverse\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknowns_string\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknowns_numeric[float]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknowns_numeric[int]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknowns_nan\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknowns_nan_non_float_dtype\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_raise_categories_shape\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_warning\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_manual[nan0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_manual[None]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_drop_manual[nan1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_invalid_drop_length[drop0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_invalid_drop_length[drop1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[first-sparse]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[first-dense]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[manual-sparse]\", \"sklearn/preprocessing/tests/test_encoders.py::test_categories[manual-dense]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_has_categorical_tags[OneHotEncoder]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_has_categorical_tags[OrdinalEncoder]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[auto-kwargs0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[auto-kwargs1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[auto-kwargs2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[auto-kwargs3]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[auto-kwargs4]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[categories1-kwargs0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[categories1-kwargs1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[categories1-kwargs2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[categories1-kwargs3]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels[categories1-kwargs4]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_drop_infrequent_errors[drop0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_drop_infrequent_errors[drop1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels[kwargs0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels[kwargs1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels[kwargs2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels[kwargs3]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels[kwargs4]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels[kwargs5]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels[kwargs6]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels_drop_frequent[first]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels_drop_frequent[drop1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels_drop_infrequent_errors[drop0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels_drop_infrequent_errors[drop1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_handle_unknown_error\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_user_cats_one_frequent[kwargs0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_user_cats_one_frequent[kwargs1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_two_levels_user_cats\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_three_levels_user_cats\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_mixed\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_multiple_categories\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_multiple_categories_dtypes\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_one_level_errors[kwargs0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_infrequent_user_cats_unknown_training_errors[kwargs0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_sparse_deprecated\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[list-O-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[list-O-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[list-U-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[list-U-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[list-S-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[list-S-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[list-S-S]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[array-O-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[array-O-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[array-U-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[array-U-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[array-S-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[array-S-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[array-S-S]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[dataframe-O-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[dataframe-O-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[dataframe-U-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[dataframe-U-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[dataframe-S-O]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[dataframe-S-U]\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoders_string_categories[dataframe-S-S]\", \"sklearn/preprocessing/tests/test_encoders.py::test_mixed_string_bytes_categoricals\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_missing_values_get_feature_names[nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_missing_values_get_feature_names[None]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_missing_value_support_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_missing_value_support_pandas_categorical[pd.NA-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_missing_value_support_pandas_categorical[pd.NA-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_missing_value_support_pandas_categorical[np.nan-infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_missing_value_support_pandas_categorical[np.nan-ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_drop_first_handle_unknown_ignore_warns[ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_drop_first_handle_unknown_ignore_warns[infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_drop_if_binary_handle_unknown_ignore_warns[ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_drop_if_binary_handle_unknown_ignore_warns[infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_drop_first_explicit_categories[ignore]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ohe_drop_first_explicit_categories[infrequent_if_exist]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_passthrough_missing_values_float_errors_dtype\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_passthrough_missing_values_float[nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_passthrough_missing_values_float[-2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_missing_value_support_pandas_categorical[nan-pd.NA]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_missing_value_support_pandas_categorical[nan-np.nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_missing_value_support_pandas_categorical[-2-pd.NA]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_missing_value_support_pandas_categorical[-2-np.nan]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories_missing_passthrough[object-None-missing-value]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories_missing_passthrough[object-nan-missing_value]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_specified_categories_missing_passthrough[numeric-missing-value]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_missing_and_unknown[X0-expected_X_trans0-X_test0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_missing_and_unknown[X1-expected_X_trans1-X_test1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_missing_and_unknown[X2-expected_X_trans2-X_test2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_missing_and_unknown[X3-expected_X_trans3-X_test3]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_sparse\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_fit_with_unseen_category\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test0-X_train0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test0-X_train1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test0-X_train2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test1-X_train0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test1-X_train1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test1-X_train2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test2-X_train0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test2-X_train1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_handle_unknown_string_dtypes[X_test2-X_train2]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_python_integer\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_features_names_out_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_unknown_missing_interaction\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_encoded_missing_value_error[True]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_encoded_missing_value_error[False]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_unknown_missing_interaction_both_nan[X_train0-X_test_trans_expected0-X_roundtrip_expected0]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_unknown_missing_interaction_both_nan[X_train1-X_test_trans_expected1-X_roundtrip_expected1]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_set_output\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_set_output\", \"sklearn/preprocessing/tests/test_encoders.py::test_predefined_categories_dtype\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_missing_unknown_encoding_max\"]",
  "environment_setup_commit": "1e8a5b833d1b58f3ab84099c4582239af854b23a",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.020722",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}