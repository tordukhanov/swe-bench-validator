{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-15120",
  "base_commit": "7cb5dafebbebefbe7e991272fad1feb12f4d630c",
  "patch": "diff --git a/sklearn/cluster/mean_shift_.py b/sklearn/cluster/mean_shift_.py\n--- a/sklearn/cluster/mean_shift_.py\n+++ b/sklearn/cluster/mean_shift_.py\n@@ -101,8 +101,9 @@ def _mean_shift_single_seed(my_mean, X, nbrs, max_iter):\n         # If converged or at max_iter, adds the cluster\n         if (np.linalg.norm(my_mean - my_old_mean) < stop_thresh or\n                 completed_iterations == max_iter):\n-            return tuple(my_mean), len(points_within)\n+            break\n         completed_iterations += 1\n+    return tuple(my_mean), len(points_within), completed_iterations\n \n \n def mean_shift(X, bandwidth=None, seeds=None, bin_seeding=False,\n@@ -178,72 +179,12 @@ def mean_shift(X, bandwidth=None, seeds=None, bin_seeding=False,\n     <sphx_glr_auto_examples_cluster_plot_mean_shift.py>`.\n \n     \"\"\"\n-\n-    if bandwidth is None:\n-        bandwidth = estimate_bandwidth(X, n_jobs=n_jobs)\n-    elif bandwidth <= 0:\n-        raise ValueError(\"bandwidth needs to be greater than zero or None,\"\n-                         \" got %f\" % bandwidth)\n-    if seeds is None:\n-        if bin_seeding:\n-            seeds = get_bin_seeds(X, bandwidth, min_bin_freq)\n-        else:\n-            seeds = X\n-    n_samples, n_features = X.shape\n-    center_intensity_dict = {}\n-\n-    # We use n_jobs=1 because this will be used in nested calls under\n-    # parallel calls to _mean_shift_single_seed so there is no need for\n-    # for further parallelism.\n-    nbrs = NearestNeighbors(radius=bandwidth, n_jobs=1).fit(X)\n-\n-    # execute iterations on all seeds in parallel\n-    all_res = Parallel(n_jobs=n_jobs)(\n-        delayed(_mean_shift_single_seed)\n-        (seed, X, nbrs, max_iter) for seed in seeds)\n-    # copy results in a dictionary\n-    for i in range(len(seeds)):\n-        if all_res[i] is not None:\n-            center_intensity_dict[all_res[i][0]] = all_res[i][1]\n-\n-    if not center_intensity_dict:\n-        # nothing near seeds\n-        raise ValueError(\"No point was within bandwidth=%f of any seed.\"\n-                         \" Try a different seeding strategy \\\n-                         or increase the bandwidth.\"\n-                         % bandwidth)\n-\n-    # POST PROCESSING: remove near duplicate points\n-    # If the distance between two kernels is less than the bandwidth,\n-    # then we have to remove one because it is a duplicate. Remove the\n-    # one with fewer points.\n-\n-    sorted_by_intensity = sorted(center_intensity_dict.items(),\n-                                 key=lambda tup: (tup[1], tup[0]),\n-                                 reverse=True)\n-    sorted_centers = np.array([tup[0] for tup in sorted_by_intensity])\n-    unique = np.ones(len(sorted_centers), dtype=np.bool)\n-    nbrs = NearestNeighbors(radius=bandwidth,\n-                            n_jobs=n_jobs).fit(sorted_centers)\n-    for i, center in enumerate(sorted_centers):\n-        if unique[i]:\n-            neighbor_idxs = nbrs.radius_neighbors([center],\n-                                                  return_distance=False)[0]\n-            unique[neighbor_idxs] = 0\n-            unique[i] = 1  # leave the current point as unique\n-    cluster_centers = sorted_centers[unique]\n-\n-    # ASSIGN LABELS: a point belongs to the cluster that it is closest to\n-    nbrs = NearestNeighbors(n_neighbors=1, n_jobs=n_jobs).fit(cluster_centers)\n-    labels = np.zeros(n_samples, dtype=np.int)\n-    distances, idxs = nbrs.kneighbors(X)\n-    if cluster_all:\n-        labels = idxs.flatten()\n-    else:\n-        labels.fill(-1)\n-        bool_selector = distances.flatten() <= bandwidth\n-        labels[bool_selector] = idxs.flatten()[bool_selector]\n-    return cluster_centers, labels\n+    model = MeanShift(bandwidth=bandwidth, seeds=seeds,\n+                      min_bin_freq=min_bin_freq,\n+                      bin_seeding=bin_seeding,\n+                      cluster_all=cluster_all, n_jobs=n_jobs,\n+                      max_iter=max_iter).fit(X)\n+    return model.cluster_centers_, model.labels_\n \n \n def get_bin_seeds(X, bin_size, min_bin_freq=1):\n@@ -347,6 +288,12 @@ class MeanShift(ClusterMixin, BaseEstimator):\n         ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n         for more details.\n \n+    max_iter : int, default=300\n+        Maximum number of iterations, per seed point before the clustering\n+        operation terminates (for that seed point), if has not converged yet.\n+\n+        .. versionadded:: 0.22\n+\n     Attributes\n     ----------\n     cluster_centers_ : array, [n_clusters, n_features]\n@@ -355,6 +302,11 @@ class MeanShift(ClusterMixin, BaseEstimator):\n     labels_ :\n         Labels of each point.\n \n+    n_iter_ : int\n+        Maximum number of iterations performed on each seed.\n+\n+        .. versionadded:: 0.22\n+\n     Examples\n     --------\n     >>> from sklearn.cluster import MeanShift\n@@ -395,13 +347,14 @@ class MeanShift(ClusterMixin, BaseEstimator):\n \n     \"\"\"\n     def __init__(self, bandwidth=None, seeds=None, bin_seeding=False,\n-                 min_bin_freq=1, cluster_all=True, n_jobs=None):\n+                 min_bin_freq=1, cluster_all=True, n_jobs=None, max_iter=300):\n         self.bandwidth = bandwidth\n         self.seeds = seeds\n         self.bin_seeding = bin_seeding\n         self.cluster_all = cluster_all\n         self.min_bin_freq = min_bin_freq\n         self.n_jobs = n_jobs\n+        self.max_iter = max_iter\n \n     def fit(self, X, y=None):\n         \"\"\"Perform clustering.\n@@ -415,11 +368,78 @@ def fit(self, X, y=None):\n \n         \"\"\"\n         X = check_array(X)\n-        self.cluster_centers_, self.labels_ = \\\n-            mean_shift(X, bandwidth=self.bandwidth, seeds=self.seeds,\n-                       min_bin_freq=self.min_bin_freq,\n-                       bin_seeding=self.bin_seeding,\n-                       cluster_all=self.cluster_all, n_jobs=self.n_jobs)\n+        bandwidth = self.bandwidth\n+        if bandwidth is None:\n+            bandwidth = estimate_bandwidth(X, n_jobs=self.n_jobs)\n+        elif bandwidth <= 0:\n+            raise ValueError(\"bandwidth needs to be greater than zero or None,\"\n+                             \" got %f\" % bandwidth)\n+\n+        seeds = self.seeds\n+        if seeds is None:\n+            if self.bin_seeding:\n+                seeds = get_bin_seeds(X, bandwidth, self.min_bin_freq)\n+            else:\n+                seeds = X\n+        n_samples, n_features = X.shape\n+        center_intensity_dict = {}\n+\n+        # We use n_jobs=1 because this will be used in nested calls under\n+        # parallel calls to _mean_shift_single_seed so there is no need for\n+        # for further parallelism.\n+        nbrs = NearestNeighbors(radius=bandwidth, n_jobs=1).fit(X)\n+\n+        # execute iterations on all seeds in parallel\n+        all_res = Parallel(n_jobs=self.n_jobs)(\n+            delayed(_mean_shift_single_seed)\n+            (seed, X, nbrs, self.max_iter) for seed in seeds)\n+        # copy results in a dictionary\n+        for i in range(len(seeds)):\n+            if all_res[i][1]:  # i.e. len(points_within) > 0\n+                center_intensity_dict[all_res[i][0]] = all_res[i][1]\n+\n+        self.n_iter_ = max([x[2] for x in all_res])\n+\n+        if not center_intensity_dict:\n+            # nothing near seeds\n+            raise ValueError(\"No point was within bandwidth=%f of any seed.\"\n+                             \" Try a different seeding strategy \\\n+                             or increase the bandwidth.\"\n+                             % bandwidth)\n+\n+        # POST PROCESSING: remove near duplicate points\n+        # If the distance between two kernels is less than the bandwidth,\n+        # then we have to remove one because it is a duplicate. Remove the\n+        # one with fewer points.\n+\n+        sorted_by_intensity = sorted(center_intensity_dict.items(),\n+                                     key=lambda tup: (tup[1], tup[0]),\n+                                     reverse=True)\n+        sorted_centers = np.array([tup[0] for tup in sorted_by_intensity])\n+        unique = np.ones(len(sorted_centers), dtype=np.bool)\n+        nbrs = NearestNeighbors(radius=bandwidth,\n+                                n_jobs=self.n_jobs).fit(sorted_centers)\n+        for i, center in enumerate(sorted_centers):\n+            if unique[i]:\n+                neighbor_idxs = nbrs.radius_neighbors([center],\n+                                                      return_distance=False)[0]\n+                unique[neighbor_idxs] = 0\n+                unique[i] = 1  # leave the current point as unique\n+        cluster_centers = sorted_centers[unique]\n+\n+        # ASSIGN LABELS: a point belongs to the cluster that it is closest to\n+        nbrs = NearestNeighbors(n_neighbors=1,\n+                                n_jobs=self.n_jobs).fit(cluster_centers)\n+        labels = np.zeros(n_samples, dtype=np.int)\n+        distances, idxs = nbrs.kneighbors(X)\n+        if self.cluster_all:\n+            labels = idxs.flatten()\n+        else:\n+            labels.fill(-1)\n+            bool_selector = distances.flatten() <= bandwidth\n+            labels[bool_selector] = idxs.flatten()[bool_selector]\n+\n+        self.cluster_centers_, self.labels_ = cluster_centers, labels\n         return self\n \n     def predict(self, X):\n",
  "test_patch": "diff --git a/sklearn/cluster/tests/test_mean_shift.py b/sklearn/cluster/tests/test_mean_shift.py\n--- a/sklearn/cluster/tests/test_mean_shift.py\n+++ b/sklearn/cluster/tests/test_mean_shift.py\n@@ -155,3 +155,16 @@ def test_bin_seeds():\n                       cluster_std=0.1, random_state=0)\n     test_bins = get_bin_seeds(X, 1)\n     assert_array_equal(test_bins, [[0, 0], [1, 1]])\n+\n+\n+@pytest.mark.parametrize('max_iter', [1, 100])\n+def test_max_iter(max_iter):\n+    clusters1, _ = mean_shift(X, max_iter=max_iter)\n+    ms = MeanShift(max_iter=max_iter).fit(X)\n+    clusters2 = ms.cluster_centers_\n+\n+    assert ms.n_iter_ <= ms.max_iter\n+    assert len(clusters1) == len(clusters2)\n+\n+    for c1, c2 in zip(clusters1, clusters2):\n+        assert np.allclose(c1, c2)\n",
  "problem_statement": "mean_shift and MeanShift don't have the same API\nI'm trying to make `mean_shift` call `MeanShift.fit` (related to #14897 )\r\n\r\nbut `mean_shift` has a `max_iter=300` parameter and `MeanShift.fit`  uses the default, so I cannot preserve backward compatibility without adding `max_iter` to `MeanShift`.\r\n\r\nShould I just do that?\n",
  "hints_text": "",
  "created_at": "2019-10-02T12:41:40Z",
  "version": "0.22",
  "FAIL_TO_PASS": "[\"sklearn/cluster/tests/test_mean_shift.py::test_max_iter[1]\", \"sklearn/cluster/tests/test_mean_shift.py::test_max_iter[100]\"]",
  "PASS_TO_PASS": "[\"sklearn/cluster/tests/test_mean_shift.py::test_estimate_bandwidth\", \"sklearn/cluster/tests/test_mean_shift.py::test_estimate_bandwidth_1sample\", \"sklearn/cluster/tests/test_mean_shift.py::test_mean_shift[1.2-True-3-0]\", \"sklearn/cluster/tests/test_mean_shift.py::test_mean_shift[1.2-False-4--1]\", \"sklearn/cluster/tests/test_mean_shift.py::test_mean_shift_negative_bandwidth\", \"sklearn/cluster/tests/test_mean_shift.py::test_estimate_bandwidth_with_sparse_matrix\", \"sklearn/cluster/tests/test_mean_shift.py::test_parallel\", \"sklearn/cluster/tests/test_mean_shift.py::test_meanshift_predict\", \"sklearn/cluster/tests/test_mean_shift.py::test_meanshift_all_orphans\", \"sklearn/cluster/tests/test_mean_shift.py::test_unfitted\", \"sklearn/cluster/tests/test_mean_shift.py::test_cluster_intensity_tie\", \"sklearn/cluster/tests/test_mean_shift.py::test_bin_seeds\"]",
  "environment_setup_commit": "7e85a6d1f038bbb932b36f18d75df6be937ed00d",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:31.012167",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}