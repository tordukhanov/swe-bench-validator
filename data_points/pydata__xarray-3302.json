{
  "repo": "pydata/xarray",
  "instance_id": "pydata__xarray-3302",
  "base_commit": "94525bbaf417476dbe9a70b98801ae04aceaebf3",
  "patch": "diff --git a/doc/conf.py b/doc/conf.py\n--- a/doc/conf.py\n+++ b/doc/conf.py\n@@ -340,9 +340,10 @@\n # Example configuration for intersphinx: refer to the Python standard library.\n intersphinx_mapping = {\n     \"python\": (\"https://docs.python.org/3/\", None),\n-    \"pandas\": (\"https://pandas.pydata.org/pandas-docs/stable/\", None),\n-    \"iris\": (\"http://scitools.org.uk/iris/docs/latest/\", None),\n-    \"numpy\": (\"https://docs.scipy.org/doc/numpy/\", None),\n-    \"numba\": (\"https://numba.pydata.org/numba-doc/latest/\", None),\n-    \"matplotlib\": (\"https://matplotlib.org/\", None),\n+    \"pandas\": (\"https://pandas.pydata.org/pandas-docs/stable\", None),\n+    \"iris\": (\"https://scitools.org.uk/iris/docs/latest\", None),\n+    \"numpy\": (\"https://docs.scipy.org/doc/numpy\", None),\n+    \"scipy\": (\"https://docs.scipy.org/doc/scipy/reference\", None),\n+    \"numba\": (\"https://numba.pydata.org/numba-doc/latest\", None),\n+    \"matplotlib\": (\"https://matplotlib.org\", None),\n }\ndiff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -2018,44 +2018,69 @@ def fillna(self, value: Any) -> \"DataArray\":\n \n     def interpolate_na(\n         self,\n-        dim=None,\n+        dim: Hashable = None,\n         method: str = \"linear\",\n         limit: int = None,\n         use_coordinate: Union[bool, str] = True,\n+        max_gap: Union[int, float, str, pd.Timedelta, np.timedelta64] = None,\n         **kwargs: Any,\n     ) -> \"DataArray\":\n-        \"\"\"Interpolate values according to different methods.\n+        \"\"\"Fill in NaNs by interpolating according to different methods.\n \n         Parameters\n         ----------\n         dim : str\n             Specifies the dimension along which to interpolate.\n-        method : {'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n-                  'polynomial', 'barycentric', 'krog', 'pchip',\n-                  'spline', 'akima'}, optional\n+        method : str, optional\n             String indicating which method to use for interpolation:\n \n             - 'linear': linear interpolation (Default). Additional keyword\n-              arguments are passed to ``numpy.interp``\n-            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n-              'polynomial': are passed to ``scipy.interpolate.interp1d``. If\n-              method=='polynomial', the ``order`` keyword argument must also be\n+              arguments are passed to :py:func:`numpy.interp`\n+            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'polynomial':\n+              are passed to :py:func:`scipy.interpolate.interp1d`. If\n+              ``method='polynomial'``, the ``order`` keyword argument must also be\n               provided.\n-            - 'barycentric', 'krog', 'pchip', 'spline', and `akima`: use their\n-              respective``scipy.interpolate`` classes.\n-        use_coordinate : boolean or str, default True\n+            - 'barycentric', 'krog', 'pchip', 'spline', 'akima': use their\n+              respective :py:class:`scipy.interpolate` classes.\n+        use_coordinate : bool, str, default True\n             Specifies which index to use as the x values in the interpolation\n             formulated as `y = f(x)`. If False, values are treated as if\n-            eqaully-spaced along `dim`. If True, the IndexVariable `dim` is\n-            used. If use_coordinate is a string, it specifies the name of a\n+            eqaully-spaced along ``dim``. If True, the IndexVariable `dim` is\n+            used. If ``use_coordinate`` is a string, it specifies the name of a\n             coordinate variariable to use as the index.\n         limit : int, default None\n             Maximum number of consecutive NaNs to fill. Must be greater than 0\n-            or None for no limit.\n+            or None for no limit. This filling is done regardless of the size of\n+            the gap in the data. To only interpolate over gaps less than a given length,\n+            see ``max_gap``.\n+        max_gap: int, float, str, pandas.Timedelta, numpy.timedelta64, default None.\n+            Maximum size of gap, a continuous sequence of NaNs, that will be filled.\n+            Use None for no limit. When interpolating along a datetime64 dimension\n+            and ``use_coordinate=True``, ``max_gap`` can be one of the following:\n+\n+            - a string that is valid input for pandas.to_timedelta\n+            - a :py:class:`numpy.timedelta64` object\n+            - a :py:class:`pandas.Timedelta` object\n+            Otherwise, ``max_gap`` must be an int or a float. Use of ``max_gap`` with unlabeled\n+            dimensions has not been implemented yet. Gap length is defined as the difference\n+            between coordinate values at the first data point after a gap and the last value\n+            before a gap. For gaps at the beginning (end), gap length is defined as the difference\n+            between coordinate values at the first (last) valid data point and the first (last) NaN.\n+            For example, consider::\n+\n+                <xarray.DataArray (x: 9)>\n+                array([nan, nan, nan,  1., nan, nan,  4., nan, nan])\n+                Coordinates:\n+                  * x        (x) int64 0 1 2 3 4 5 6 7 8\n+\n+            The gap lengths are 3-0 = 3; 6-3 = 3; and 8-6 = 2 respectively\n+        kwargs : dict, optional\n+            parameters passed verbatim to the underlying interpolation function\n \n         Returns\n         -------\n-        DataArray\n+        interpolated: DataArray\n+            Filled in DataArray.\n \n         See also\n         --------\n@@ -2070,6 +2095,7 @@ def interpolate_na(\n             method=method,\n             limit=limit,\n             use_coordinate=use_coordinate,\n+            max_gap=max_gap,\n             **kwargs,\n         )\n \ndiff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3900,42 +3900,65 @@ def interpolate_na(\n         method: str = \"linear\",\n         limit: int = None,\n         use_coordinate: Union[bool, Hashable] = True,\n+        max_gap: Union[int, float, str, pd.Timedelta, np.timedelta64] = None,\n         **kwargs: Any,\n     ) -> \"Dataset\":\n-        \"\"\"Interpolate values according to different methods.\n+        \"\"\"Fill in NaNs by interpolating according to different methods.\n \n         Parameters\n         ----------\n-        dim : Hashable\n+        dim : str\n             Specifies the dimension along which to interpolate.\n-        method : {'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n-                  'polynomial', 'barycentric', 'krog', 'pchip',\n-                  'spline'}, optional\n+        method : str, optional\n             String indicating which method to use for interpolation:\n \n             - 'linear': linear interpolation (Default). Additional keyword\n-              arguments are passed to ``numpy.interp``\n-            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n-              'polynomial': are passed to ``scipy.interpolate.interp1d``. If\n-              method=='polynomial', the ``order`` keyword argument must also be\n+              arguments are passed to :py:func:`numpy.interp`\n+            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'polynomial':\n+              are passed to :py:func:`scipy.interpolate.interp1d`. If\n+              ``method='polynomial'``, the ``order`` keyword argument must also be\n               provided.\n-            - 'barycentric', 'krog', 'pchip', 'spline': use their respective\n-              ``scipy.interpolate`` classes.\n-        use_coordinate : boolean or str, default True\n+            - 'barycentric', 'krog', 'pchip', 'spline', 'akima': use their\n+              respective :py:class:`scipy.interpolate` classes.\n+        use_coordinate : bool, str, default True\n             Specifies which index to use as the x values in the interpolation\n             formulated as `y = f(x)`. If False, values are treated as if\n-            eqaully-spaced along `dim`. If True, the IndexVariable `dim` is\n-            used. If use_coordinate is a string, it specifies the name of a\n+            eqaully-spaced along ``dim``. If True, the IndexVariable `dim` is\n+            used. If ``use_coordinate`` is a string, it specifies the name of a\n             coordinate variariable to use as the index.\n         limit : int, default None\n             Maximum number of consecutive NaNs to fill. Must be greater than 0\n-            or None for no limit.\n-        kwargs : any\n-            parameters passed verbatim to the underlying interplation function\n+            or None for no limit. This filling is done regardless of the size of\n+            the gap in the data. To only interpolate over gaps less than a given length,\n+            see ``max_gap``.\n+        max_gap: int, float, str, pandas.Timedelta, numpy.timedelta64, default None.\n+            Maximum size of gap, a continuous sequence of NaNs, that will be filled.\n+            Use None for no limit. When interpolating along a datetime64 dimension\n+            and ``use_coordinate=True``, ``max_gap`` can be one of the following:\n+\n+            - a string that is valid input for pandas.to_timedelta\n+            - a :py:class:`numpy.timedelta64` object\n+            - a :py:class:`pandas.Timedelta` object\n+            Otherwise, ``max_gap`` must be an int or a float. Use of ``max_gap`` with unlabeled\n+            dimensions has not been implemented yet. Gap length is defined as the difference\n+            between coordinate values at the first data point after a gap and the last value\n+            before a gap. For gaps at the beginning (end), gap length is defined as the difference\n+            between coordinate values at the first (last) valid data point and the first (last) NaN.\n+            For example, consider::\n+\n+                <xarray.DataArray (x: 9)>\n+                array([nan, nan, nan,  1., nan, nan,  4., nan, nan])\n+                Coordinates:\n+                  * x        (x) int64 0 1 2 3 4 5 6 7 8\n+\n+            The gap lengths are 3-0 = 3; 6-3 = 3; and 8-6 = 2 respectively\n+        kwargs : dict, optional\n+            parameters passed verbatim to the underlying interpolation function\n \n         Returns\n         -------\n-        Dataset\n+        interpolated: Dataset\n+            Filled in Dataset.\n \n         See also\n         --------\n@@ -3951,6 +3974,7 @@ def interpolate_na(\n             method=method,\n             limit=limit,\n             use_coordinate=use_coordinate,\n+            max_gap=max_gap,\n             **kwargs,\n         )\n         return new\ndiff --git a/xarray/core/missing.py b/xarray/core/missing.py\n--- a/xarray/core/missing.py\n+++ b/xarray/core/missing.py\n@@ -1,18 +1,46 @@\n import warnings\n from functools import partial\n-from typing import Any, Callable, Dict, Sequence\n+from numbers import Number\n+from typing import Any, Callable, Dict, Hashable, Sequence, Union\n \n import numpy as np\n import pandas as pd\n \n from . import utils\n-from .common import _contains_datetime_like_objects\n+from .common import _contains_datetime_like_objects, ones_like\n from .computation import apply_ufunc\n from .duck_array_ops import dask_array_type\n from .utils import OrderedSet, is_scalar\n from .variable import Variable, broadcast_variables\n \n \n+def _get_nan_block_lengths(obj, dim: Hashable, index: Variable):\n+    \"\"\"\n+    Return an object where each NaN element in 'obj' is replaced by the\n+    length of the gap the element is in.\n+    \"\"\"\n+\n+    # make variable so that we get broadcasting for free\n+    index = Variable([dim], index)\n+\n+    # algorithm from https://github.com/pydata/xarray/pull/3302#discussion_r324707072\n+    arange = ones_like(obj) * index\n+    valid = obj.notnull()\n+    valid_arange = arange.where(valid)\n+    cumulative_nans = valid_arange.ffill(dim=dim).fillna(index[0])\n+\n+    nan_block_lengths = (\n+        cumulative_nans.diff(dim=dim, label=\"upper\")\n+        .reindex({dim: obj[dim]})\n+        .where(valid)\n+        .bfill(dim=dim)\n+        .where(~valid, 0)\n+        .fillna(index[-1] - valid_arange.max())\n+    )\n+\n+    return nan_block_lengths\n+\n+\n class BaseInterpolator:\n     \"\"\"Generic interpolator class for normalizing interpolation methods\n     \"\"\"\n@@ -178,7 +206,7 @@ def _apply_over_vars_with_dim(func, self, dim=None, **kwargs):\n     return ds\n \n \n-def get_clean_interp_index(arr, dim, use_coordinate=True):\n+def get_clean_interp_index(arr, dim: Hashable, use_coordinate: Union[str, bool] = True):\n     \"\"\"get index to use for x values in interpolation.\n \n     If use_coordinate is True, the coordinate that shares the name of the\n@@ -195,23 +223,33 @@ def get_clean_interp_index(arr, dim, use_coordinate=True):\n             index = arr.coords[use_coordinate]\n             if index.ndim != 1:\n                 raise ValueError(\n-                    \"Coordinates used for interpolation must be 1D, \"\n-                    \"%s is %dD.\" % (use_coordinate, index.ndim)\n+                    f\"Coordinates used for interpolation must be 1D, \"\n+                    f\"{use_coordinate} is {index.ndim}D.\"\n                 )\n+            index = index.to_index()\n+\n+        # TODO: index.name is None for multiindexes\n+        # set name for nice error messages below\n+        if isinstance(index, pd.MultiIndex):\n+            index.name = dim\n+\n+        if not index.is_monotonic:\n+            raise ValueError(f\"Index {index.name!r} must be monotonically increasing\")\n+\n+        if not index.is_unique:\n+            raise ValueError(f\"Index {index.name!r} has duplicate values\")\n \n         # raise if index cannot be cast to a float (e.g. MultiIndex)\n         try:\n             index = index.values.astype(np.float64)\n         except (TypeError, ValueError):\n             # pandas raises a TypeError\n-            # xarray/nuppy raise a ValueError\n+            # xarray/numpy raise a ValueError\n             raise TypeError(\n-                \"Index must be castable to float64 to support\"\n-                \"interpolation, got: %s\" % type(index)\n+                f\"Index {index.name!r} must be castable to float64 to support \"\n+                f\"interpolation, got {type(index).__name__}.\"\n             )\n-        # check index sorting now so we can skip it later\n-        if not (np.diff(index) > 0).all():\n-            raise ValueError(\"Index must be monotonicly increasing\")\n+\n     else:\n         axis = arr.get_axis_num(dim)\n         index = np.arange(arr.shape[axis], dtype=np.float64)\n@@ -220,7 +258,13 @@ def get_clean_interp_index(arr, dim, use_coordinate=True):\n \n \n def interp_na(\n-    self, dim=None, use_coordinate=True, method=\"linear\", limit=None, **kwargs\n+    self,\n+    dim: Hashable = None,\n+    use_coordinate: Union[bool, str] = True,\n+    method: str = \"linear\",\n+    limit: int = None,\n+    max_gap: Union[int, float, str, pd.Timedelta, np.timedelta64] = None,\n+    **kwargs,\n ):\n     \"\"\"Interpolate values according to different methods.\n     \"\"\"\n@@ -230,6 +274,40 @@ def interp_na(\n     if limit is not None:\n         valids = _get_valid_fill_mask(self, dim, limit)\n \n+    if max_gap is not None:\n+        max_type = type(max_gap).__name__\n+        if not is_scalar(max_gap):\n+            raise ValueError(\"max_gap must be a scalar.\")\n+\n+        if (\n+            dim in self.indexes\n+            and isinstance(self.indexes[dim], pd.DatetimeIndex)\n+            and use_coordinate\n+        ):\n+            if not isinstance(max_gap, (np.timedelta64, pd.Timedelta, str)):\n+                raise TypeError(\n+                    f\"Underlying index is DatetimeIndex. Expected max_gap of type str, pandas.Timedelta or numpy.timedelta64 but received {max_type}\"\n+                )\n+\n+            if isinstance(max_gap, str):\n+                try:\n+                    max_gap = pd.to_timedelta(max_gap)\n+                except ValueError:\n+                    raise ValueError(\n+                        f\"Could not convert {max_gap!r} to timedelta64 using pandas.to_timedelta\"\n+                    )\n+\n+            if isinstance(max_gap, pd.Timedelta):\n+                max_gap = np.timedelta64(max_gap.value, \"ns\")\n+\n+            max_gap = np.timedelta64(max_gap, \"ns\").astype(np.float64)\n+\n+        if not use_coordinate:\n+            if not isinstance(max_gap, (Number, np.number)):\n+                raise TypeError(\n+                    f\"Expected integer or floating point max_gap since use_coordinate=False. Received {max_type}.\"\n+                )\n+\n     # method\n     index = get_clean_interp_index(self, dim, use_coordinate=use_coordinate)\n     interp_class, kwargs = _get_interpolator(method, **kwargs)\n@@ -253,6 +331,14 @@ def interp_na(\n     if limit is not None:\n         arr = arr.where(valids)\n \n+    if max_gap is not None:\n+        if dim not in self.coords:\n+            raise NotImplementedError(\n+                \"max_gap not implemented for unlabeled coordinates yet.\"\n+            )\n+        nan_block_lengths = _get_nan_block_lengths(self, dim, index)\n+        arr = arr.where(nan_block_lengths <= max_gap)\n+\n     return arr\n \n \n",
  "test_patch": "diff --git a/xarray/tests/test_missing.py b/xarray/tests/test_missing.py\n--- a/xarray/tests/test_missing.py\n+++ b/xarray/tests/test_missing.py\n@@ -5,7 +5,13 @@\n import pytest\n \n import xarray as xr\n-from xarray.core.missing import NumpyInterpolator, ScipyInterpolator, SplineInterpolator\n+from xarray.core.missing import (\n+    NumpyInterpolator,\n+    ScipyInterpolator,\n+    SplineInterpolator,\n+    get_clean_interp_index,\n+    _get_nan_block_lengths,\n+)\n from xarray.core.pycompat import dask_array_type\n from xarray.tests import (\n     assert_array_equal,\n@@ -153,7 +159,7 @@ def test_interpolate_pd_compat_polynomial():\n def test_interpolate_unsorted_index_raises():\n     vals = np.array([1, 2, 3], dtype=np.float64)\n     expected = xr.DataArray(vals, dims=\"x\", coords={\"x\": [2, 1, 3]})\n-    with raises_regex(ValueError, \"Index must be monotonicly increasing\"):\n+    with raises_regex(ValueError, \"Index 'x' must be monotonically increasing\"):\n         expected.interpolate_na(dim=\"x\", method=\"index\")\n \n \n@@ -169,12 +175,19 @@ def test_interpolate_invalid_interpolator_raises():\n         da.interpolate_na(dim=\"x\", method=\"foo\")\n \n \n+def test_interpolate_duplicate_values_raises():\n+    data = np.random.randn(2, 3)\n+    da = xr.DataArray(data, coords=[(\"x\", [\"a\", \"a\"]), (\"y\", [0, 1, 2])])\n+    with raises_regex(ValueError, \"Index 'x' has duplicate values\"):\n+        da.interpolate_na(dim=\"x\", method=\"foo\")\n+\n+\n def test_interpolate_multiindex_raises():\n     data = np.random.randn(2, 3)\n     data[1, 1] = np.nan\n     da = xr.DataArray(data, coords=[(\"x\", [\"a\", \"b\"]), (\"y\", [0, 1, 2])])\n     das = da.stack(z=(\"x\", \"y\"))\n-    with raises_regex(TypeError, \"Index must be castable to float64\"):\n+    with raises_regex(TypeError, \"Index 'z' must be castable to float64\"):\n         das.interpolate_na(dim=\"z\")\n \n \n@@ -439,3 +452,114 @@ def test_ffill_dataset(ds):\n @requires_bottleneck\n def test_bfill_dataset(ds):\n     ds.ffill(dim=\"time\")\n+\n+\n+@requires_bottleneck\n+@pytest.mark.parametrize(\n+    \"y, lengths\",\n+    [\n+        [np.arange(9), [[3, 3, 3, 0, 3, 3, 0, 2, 2]]],\n+        [np.arange(9) * 3, [[9, 9, 9, 0, 9, 9, 0, 6, 6]]],\n+        [[0, 2, 5, 6, 7, 8, 10, 12, 14], [[6, 6, 6, 0, 4, 4, 0, 4, 4]]],\n+    ],\n+)\n+def test_interpolate_na_nan_block_lengths(y, lengths):\n+    arr = [[np.nan, np.nan, np.nan, 1, np.nan, np.nan, 4, np.nan, np.nan]]\n+    da = xr.DataArray(arr * 2, dims=[\"x\", \"y\"], coords={\"x\": [0, 1], \"y\": y})\n+    index = get_clean_interp_index(da, dim=\"y\", use_coordinate=True)\n+    actual = _get_nan_block_lengths(da, dim=\"y\", index=index)\n+    expected = da.copy(data=lengths * 2)\n+    assert_equal(actual, expected)\n+\n+\n+@pytest.fixture\n+def da_time():\n+    return xr.DataArray(\n+        [np.nan, 1, 2, np.nan, np.nan, 5, np.nan, np.nan, np.nan, np.nan, 10],\n+        dims=[\"t\"],\n+    )\n+\n+\n+def test_interpolate_na_max_gap_errors(da_time):\n+    with raises_regex(\n+        NotImplementedError, \"max_gap not implemented for unlabeled coordinates\"\n+    ):\n+        da_time.interpolate_na(\"t\", max_gap=1)\n+\n+    with raises_regex(ValueError, \"max_gap must be a scalar.\"):\n+        da_time.interpolate_na(\"t\", max_gap=(1,))\n+\n+    da_time[\"t\"] = pd.date_range(\"2001-01-01\", freq=\"H\", periods=11)\n+    with raises_regex(TypeError, \"Underlying index is\"):\n+        da_time.interpolate_na(\"t\", max_gap=1)\n+\n+    with raises_regex(TypeError, \"Expected integer or floating point\"):\n+        da_time.interpolate_na(\"t\", max_gap=\"1H\", use_coordinate=False)\n+\n+    with raises_regex(ValueError, \"Could not convert 'huh' to timedelta64\"):\n+        da_time.interpolate_na(\"t\", max_gap=\"huh\")\n+\n+\n+@requires_bottleneck\n+@pytest.mark.parametrize(\n+    \"time_range_func\",\n+    [pd.date_range, pytest.param(xr.cftime_range, marks=pytest.mark.xfail)],\n+)\n+@pytest.mark.parametrize(\"transform\", [lambda x: x, lambda x: x.to_dataset(name=\"a\")])\n+@pytest.mark.parametrize(\n+    \"max_gap\", [\"3H\", np.timedelta64(3, \"h\"), pd.to_timedelta(\"3H\")]\n+)\n+def test_interpolate_na_max_gap_time_specifier(\n+    da_time, max_gap, transform, time_range_func\n+):\n+    da_time[\"t\"] = time_range_func(\"2001-01-01\", freq=\"H\", periods=11)\n+    expected = transform(\n+        da_time.copy(data=[np.nan, 1, 2, 3, 4, 5, np.nan, np.nan, np.nan, np.nan, 10])\n+    )\n+    actual = transform(da_time).interpolate_na(\"t\", max_gap=max_gap)\n+    assert_equal(actual, expected)\n+\n+\n+@requires_bottleneck\n+@pytest.mark.parametrize(\n+    \"coords\",\n+    [\n+        pytest.param(None, marks=pytest.mark.xfail()),\n+        {\"x\": np.arange(4), \"y\": np.arange(11)},\n+    ],\n+)\n+def test_interpolate_na_2d(coords):\n+    da = xr.DataArray(\n+        [\n+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+        ],\n+        dims=[\"x\", \"y\"],\n+        coords=coords,\n+    )\n+\n+    actual = da.interpolate_na(\"y\", max_gap=2)\n+    expected_y = da.copy(\n+        data=[\n+            [1, 2, 3, 4, 5, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, 4, 5, 6, 7, np.nan, np.nan, np.nan, 11],\n+        ]\n+    )\n+    assert_equal(actual, expected_y)\n+\n+    actual = da.interpolate_na(\"x\", max_gap=3)\n+    expected_x = xr.DataArray(\n+        [\n+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],\n+        ],\n+        dims=[\"x\", \"y\"],\n+        coords=coords,\n+    )\n+    assert_equal(actual, expected_x)\n",
  "problem_statement": "Improving interpolate_na()'s limit argument\nI've been working with some time-series data with occasional nans peppered throughout. I want to interpolate small gaps of nans (say, when there is a single isolated nan or perhaps a block of two) but leave larger blocks as nans. That is, it's not appropriate to fill large gaps, but it acceptable to do so for small gaps.\r\n\r\nI was hoping `interpolate_na()` with the `limit` argument would do exactly this, but it turns out that if you specify, say, `limit=2`, it will fill the first two nans of nan-blocks of any length, no matter how long. There are [definitely](https://stackoverflow.com/questions/43077166/interpolate-only-if-single-nan/43079055#43079055) [solutions](https://stackoverflow.com/questions/43082316/mask-only-where-consecutive-nans-exceeds-x#) for dealing with this, but it seems like a common issue, and has cropped up over on [Pandas](https://github.com/pandas-dev/pandas/issues/12187) as well.\r\n\r\nI'm not able to attempt tackling this right now, but I guess I wanted to put in a feature request for an additional argument to `interpolate_na()` that would do this.\r\n\n",
  "hints_text": "",
  "created_at": "2019-09-12T15:07:20Z",
  "version": "0.12",
  "FAIL_TO_PASS": "[\"xarray/tests/test_missing.py::test_interpolate_no_dim_raises\", \"xarray/tests/test_missing.py::test_interpolate_2d_coord_raises\"]",
  "PASS_TO_PASS": "[\"xarray/tests/test_missing.py::test_interpolate_pd_compat\", \"xarray/tests/test_missing.py::test_scipy_methods_function[barycentric]\", \"xarray/tests/test_missing.py::test_scipy_methods_function[krog]\", \"xarray/tests/test_missing.py::test_scipy_methods_function[pchip]\", \"xarray/tests/test_missing.py::test_scipy_methods_function[spline]\", \"xarray/tests/test_missing.py::test_scipy_methods_function[akima]\", \"xarray/tests/test_missing.py::test_interpolate_pd_compat_non_uniform_index\", \"xarray/tests/test_missing.py::test_interpolate_pd_compat_polynomial\", \"xarray/tests/test_missing.py::test_interpolate_unsorted_index_raises\", \"xarray/tests/test_missing.py::test_interpolate_invalid_interpolator_raises\", \"xarray/tests/test_missing.py::test_interpolate_duplicate_values_raises\", \"xarray/tests/test_missing.py::test_interpolate_multiindex_raises\", \"xarray/tests/test_missing.py::test_interpolate_kwargs\", \"xarray/tests/test_missing.py::test_interpolate\", \"xarray/tests/test_missing.py::test_interpolate_nonans\", \"xarray/tests/test_missing.py::test_interpolate_allnans\", \"xarray/tests/test_missing.py::test_interpolate_limits\", \"xarray/tests/test_missing.py::test_interpolate_methods\", \"xarray/tests/test_missing.py::test_interpolators\", \"xarray/tests/test_missing.py::test_interpolate_use_coordinate\", \"xarray/tests/test_missing.py::test_interpolate_dask\", \"xarray/tests/test_missing.py::test_interpolate_dask_raises_for_invalid_chunk_dim\", \"xarray/tests/test_missing.py::test_ffill\", \"xarray/tests/test_missing.py::test_ffill_dask\", \"xarray/tests/test_missing.py::test_bfill_dask\", \"xarray/tests/test_missing.py::test_ffill_bfill_nonans\", \"xarray/tests/test_missing.py::test_ffill_bfill_allnans\", \"xarray/tests/test_missing.py::test_ffill_functions\", \"xarray/tests/test_missing.py::test_ffill_limit\", \"xarray/tests/test_missing.py::test_interpolate_dataset\", \"xarray/tests/test_missing.py::test_ffill_dataset\", \"xarray/tests/test_missing.py::test_bfill_dataset\", \"xarray/tests/test_missing.py::test_interpolate_na_nan_block_lengths[y0-lengths0]\", \"xarray/tests/test_missing.py::test_interpolate_na_nan_block_lengths[y1-lengths1]\", \"xarray/tests/test_missing.py::test_interpolate_na_nan_block_lengths[y2-lengths2]\", \"xarray/tests/test_missing.py::test_interpolate_na_max_gap_errors\", \"xarray/tests/test_missing.py::test_interpolate_na_max_gap_time_specifier[3H-<lambda>0-date_range]\", \"xarray/tests/test_missing.py::test_interpolate_na_max_gap_time_specifier[3H-<lambda>1-date_range]\", \"xarray/tests/test_missing.py::test_interpolate_na_max_gap_time_specifier[max_gap1-<lambda>0-date_range]\", \"xarray/tests/test_missing.py::test_interpolate_na_max_gap_time_specifier[max_gap1-<lambda>1-date_range]\", \"xarray/tests/test_missing.py::test_interpolate_na_max_gap_time_specifier[max_gap2-<lambda>0-date_range]\", \"xarray/tests/test_missing.py::test_interpolate_na_max_gap_time_specifier[max_gap2-<lambda>1-date_range]\", \"xarray/tests/test_missing.py::test_interpolate_na_2d[coords1]\"]",
  "environment_setup_commit": "1c198a191127c601d091213c4b3292a8bb3054e1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.870017",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}