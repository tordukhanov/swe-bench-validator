{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-13485",
  "base_commit": "93e09aaae68ec2fc2d7b78818364ca868442e61e",
  "patch": "diff --git a/sklearn/calibration.py b/sklearn/calibration.py\n--- a/sklearn/calibration.py\n+++ b/sklearn/calibration.py\n@@ -131,7 +131,7 @@ def fit(self, X, y, sample_weight=None):\n             Returns an instance of self.\n         \"\"\"\n         X, y = check_X_y(X, y, accept_sparse=['csc', 'csr', 'coo'],\n-                         force_all_finite=False)\n+                         force_all_finite=False, allow_nd=True)\n         X, y = indexable(X, y)\n         le = LabelBinarizer().fit(y)\n         self.classes_ = le.classes_\n",
  "test_patch": "diff --git a/sklearn/tests/test_calibration.py b/sklearn/tests/test_calibration.py\n--- a/sklearn/tests/test_calibration.py\n+++ b/sklearn/tests/test_calibration.py\n@@ -4,13 +4,15 @@\n import pytest\n import numpy as np\n from scipy import sparse\n+\n+from sklearn.base import BaseEstimator\n from sklearn.model_selection import LeaveOneOut\n \n from sklearn.utils.testing import (assert_array_almost_equal, assert_equal,\n                                    assert_greater, assert_almost_equal,\n                                    assert_greater_equal,\n                                    assert_array_equal,\n-                                   assert_raises)\n+                                   assert_raises, ignore_warnings)\n from sklearn.datasets import make_classification, make_blobs\n from sklearn.naive_bayes import MultinomialNB\n from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n@@ -320,3 +322,26 @@ def test_calibration_less_classes():\n         assert_array_equal(proba[:, i], np.zeros(len(y)))\n         assert_equal(np.all(np.hstack([proba[:, :i],\n                                        proba[:, i + 1:]])), True)\n+\n+\n+@ignore_warnings(category=(DeprecationWarning, FutureWarning))\n+@pytest.mark.parametrize('X', [np.random.RandomState(42).randn(15, 5, 2),\n+                               np.random.RandomState(42).randn(15, 5, 2, 6)])\n+def test_calibration_accepts_ndarray(X):\n+    \"\"\"Test that calibration accepts n-dimensional arrays as input\"\"\"\n+    y = [1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n+\n+    class MockTensorClassifier(BaseEstimator):\n+        \"\"\"A toy estimator that accepts tensor inputs\"\"\"\n+\n+        def fit(self, X, y):\n+            self.classes_ = np.unique(y)\n+            return self\n+\n+        def decision_function(self, X):\n+            # toy decision function that just needs to have the right shape:\n+            return X.reshape(X.shape[0], -1).sum(axis=1)\n+\n+    calibrated_clf = CalibratedClassifierCV(MockTensorClassifier())\n+    # we should be able to fit this classifier with no error\n+    calibrated_clf.fit(X, y)\n",
  "problem_statement": "Be more tolerant in check_array for CalibratedClassifierCV\nFor our package http://github.com/metric-learn/metric-learn, the function `CalibratedClassifierCV` is very convenient for Weakly Supervised Learners, as it can make PairsClassifier estimators return a probability for a pair of points to be labeled as similar or dissimilar, when those return a decision function.\r\n\r\nHowever, we currently cannot use it because our inputs can be 3D (example: `pairs=[[[2.3, 5.4], [4.4, 5.6]], [[7.5, 1.2], [4.4, 5.6]]]`), and `CalibratedClassifierCV` uses `check_array` with default parameters that does not allow 3D inputs.\r\n\r\nHowever, other meta-estimators like `GridSearchCV` do not call `check_array`, so we can use them easily in metric-learn.\r\n\r\nIs the `check_array` in `CalibratedClassifierCV` really useful or could we do without it ? If we could, I'd be happy to provide a PR to do so\n",
  "hints_text": "I think if removing it results in tests passing, I'm fine with it. I'd be\nmore surprised if prediction works than fitting.\n",
  "created_at": "2019-03-21T11:00:19Z",
  "version": "0.21",
  "FAIL_TO_PASS": "[\"sklearn/tests/test_calibration.py::test_calibration_accepts_ndarray[X0]\", \"sklearn/tests/test_calibration.py::test_calibration_accepts_ndarray[X1]\"]",
  "PASS_TO_PASS": "[\"sklearn/tests/test_calibration.py::test_calibration\", \"sklearn/tests/test_calibration.py::test_sample_weight\", \"sklearn/tests/test_calibration.py::test_calibration_multiclass\", \"sklearn/tests/test_calibration.py::test_calibration_prefit\", \"sklearn/tests/test_calibration.py::test_sigmoid_calibration\", \"sklearn/tests/test_calibration.py::test_calibration_curve\", \"sklearn/tests/test_calibration.py::test_calibration_nan_imputer\", \"sklearn/tests/test_calibration.py::test_calibration_prob_sum\", \"sklearn/tests/test_calibration.py::test_calibration_less_classes\"]",
  "environment_setup_commit": "7813f7efb5b2012412888b69e73d76f2df2b50b6",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.995373",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}