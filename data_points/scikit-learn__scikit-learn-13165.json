{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-13165",
  "base_commit": "1c8668b0a021832386470ddf740d834e02c66f69",
  "patch": "diff --git a/sklearn/preprocessing/_discretization.py b/sklearn/preprocessing/_discretization.py\n--- a/sklearn/preprocessing/_discretization.py\n+++ b/sklearn/preprocessing/_discretization.py\n@@ -56,7 +56,8 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):\n     Attributes\n     ----------\n     n_bins_ : int array, shape (n_features,)\n-        Number of bins per feature.\n+        Number of bins per feature. Bins whose width are too small\n+        (i.e., <= 1e-8) are removed with a warning.\n \n     bin_edges_ : array of arrays, shape (n_features, )\n         The edges of each bin. Contain arrays of varying shapes ``(n_bins_, )``\n@@ -102,6 +103,11 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):\n     :class:`sklearn.compose.ColumnTransformer` if you only want to preprocess\n     part of the features.\n \n+    ``KBinsDiscretizer`` might produce constant features (e.g., when\n+    ``encode = 'onehot'`` and certain bins do not contain any data).\n+    These features can be removed with feature selection algorithms\n+    (e.g., :class:`sklearn.feature_selection.VarianceThreshold`).\n+\n     See also\n     --------\n      sklearn.preprocessing.Binarizer : class used to bin values as ``0`` or\n@@ -177,6 +183,16 @@ def fit(self, X, y=None):\n                 bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5\n                 bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]\n \n+            # Remove bins whose width are too small (i.e., <= 1e-8)\n+            if self.strategy in ('quantile', 'kmeans'):\n+                mask = np.ediff1d(bin_edges[jj], to_begin=np.inf) > 1e-8\n+                bin_edges[jj] = bin_edges[jj][mask]\n+                if len(bin_edges[jj]) - 1 != n_bins[jj]:\n+                    warnings.warn('Bins whose width are too small (i.e., <= '\n+                                  '1e-8) in feature %d are removed. Consider '\n+                                  'decreasing the number of bins.' % jj)\n+                    n_bins[jj] = len(bin_edges[jj]) - 1\n+\n         self.bin_edges_ = bin_edges\n         self.n_bins_ = n_bins\n \n",
  "test_patch": "diff --git a/sklearn/preprocessing/tests/test_discretization.py b/sklearn/preprocessing/tests/test_discretization.py\n--- a/sklearn/preprocessing/tests/test_discretization.py\n+++ b/sklearn/preprocessing/tests/test_discretization.py\n@@ -7,6 +7,7 @@\n from sklearn.preprocessing import KBinsDiscretizer\n from sklearn.preprocessing import OneHotEncoder\n from sklearn.utils.testing import (\n+    assert_array_almost_equal,\n     assert_array_equal,\n     assert_raises,\n     assert_raise_message,\n@@ -209,24 +210,22 @@ def test_nonuniform_strategies(\n     assert_array_equal(expected_5bins, Xt.ravel())\n \n \n-@pytest.mark.parametrize('strategy', ['uniform', 'kmeans', 'quantile'])\n+@pytest.mark.parametrize(\n+    'strategy, expected_inv',\n+    [('uniform', [[-1.5, 2., -3.5, -0.5], [-0.5, 3., -2.5, -0.5],\n+                  [0.5, 4., -1.5, 0.5], [0.5, 4., -1.5, 1.5]]),\n+     ('kmeans', [[-1.375, 2.125, -3.375, -0.5625],\n+                 [-1.375, 2.125, -3.375, -0.5625],\n+                 [-0.125, 3.375, -2.125, 0.5625],\n+                 [0.75, 4.25, -1.25, 1.625]]),\n+     ('quantile', [[-1.5, 2., -3.5, -0.75], [-0.5, 3., -2.5, 0.],\n+                   [0.5, 4., -1.5, 1.25], [0.5, 4., -1.5, 1.25]])])\n @pytest.mark.parametrize('encode', ['ordinal', 'onehot', 'onehot-dense'])\n-def test_inverse_transform(strategy, encode):\n-    X = np.random.RandomState(0).randn(100, 3)\n+def test_inverse_transform(strategy, encode, expected_inv):\n     kbd = KBinsDiscretizer(n_bins=3, strategy=strategy, encode=encode)\n     Xt = kbd.fit_transform(X)\n-    X2 = kbd.inverse_transform(Xt)\n-    X2t = kbd.fit_transform(X2)\n-    if encode == 'onehot':\n-        assert_array_equal(Xt.todense(), X2t.todense())\n-    else:\n-        assert_array_equal(Xt, X2t)\n-    if 'onehot' in encode:\n-        Xt = kbd._encoder.inverse_transform(Xt)\n-        X2t = kbd._encoder.inverse_transform(X2t)\n-\n-    assert_array_equal(Xt.max(axis=0) + 1, kbd.n_bins_)\n-    assert_array_equal(X2t.max(axis=0) + 1, kbd.n_bins_)\n+    Xinv = kbd.inverse_transform(Xt)\n+    assert_array_almost_equal(expected_inv, Xinv)\n \n \n @pytest.mark.parametrize('strategy', ['uniform', 'kmeans', 'quantile'])\n@@ -253,3 +252,28 @@ def test_overwrite():\n     Xinv = est.inverse_transform(Xt)\n     assert_array_equal(Xt, Xt_before)\n     assert_array_equal(Xinv, np.array([[0.5], [1.5], [2.5], [2.5]]))\n+\n+\n+@pytest.mark.parametrize(\n+    'strategy, expected_bin_edges',\n+    [('quantile', [0, 1, 3]), ('kmeans', [0, 1.5, 3])])\n+def test_redundant_bins(strategy, expected_bin_edges):\n+    X = [[0], [0], [0], [0], [3], [3]]\n+    kbd = KBinsDiscretizer(n_bins=3, strategy=strategy)\n+    msg = (\"Bins whose width are too small (i.e., <= 1e-8) in feature 0 \"\n+           \"are removed. Consider decreasing the number of bins.\")\n+    assert_warns_message(UserWarning, msg, kbd.fit, X)\n+    assert_array_almost_equal(kbd.bin_edges_[0], expected_bin_edges)\n+\n+\n+def test_percentile_numeric_stability():\n+    X = np.array([0.05, 0.05, 0.95]).reshape(-1, 1)\n+    bin_edges = np.array([0.05, 0.23, 0.41, 0.59, 0.77, 0.95])\n+    Xt = np.array([0, 0, 4]).reshape(-1, 1)\n+    kbd = KBinsDiscretizer(n_bins=10, encode='ordinal',\n+                           strategy='quantile')\n+    msg = (\"Bins whose width are too small (i.e., <= 1e-8) in feature 0 \"\n+           \"are removed. Consider decreasing the number of bins.\")\n+    assert_warns_message(UserWarning, msg, kbd.fit, X)\n+    assert_array_almost_equal(kbd.bin_edges_[0], bin_edges)\n+    assert_array_almost_equal(kbd.transform(X), Xt)\n",
  "problem_statement": "Fix #13194: Ensure monotonic bin edges for KBinsDiscretizer strategy quantile\n#### Reference Issues/PRs\r\nFixes #13194\r\n\r\n#### What does this implement/fix? Explain your changes.\r\nThe percentiles returned from np.percentile are monotonic up to possible numeric instabilities. Monotonicity is enforced by applying a simple maximum on subsequent values to deal with this case and increase robustness.\r\n\r\n#### Any other comments?\r\nThe additional line is a no-op in almost all cases. This is unfortunate, but since there is essentially no performance impact, I guess robustness is worth the effort.\r\n\n",
  "hints_text": "",
  "created_at": "2019-02-14T14:53:40Z",
  "version": "0.21",
  "FAIL_TO_PASS": "[\"sklearn/preprocessing/tests/test_discretization.py::test_redundant_bins[quantile-expected_bin_edges0]\", \"sklearn/preprocessing/tests/test_discretization.py::test_redundant_bins[kmeans-expected_bin_edges1]\", \"sklearn/preprocessing/tests/test_discretization.py::test_percentile_numeric_stability\"]",
  "PASS_TO_PASS": "[\"sklearn/preprocessing/tests/test_discretization.py::test_fit_transform[uniform-expected0]\", \"sklearn/preprocessing/tests/test_discretization.py::test_fit_transform[kmeans-expected1]\", \"sklearn/preprocessing/tests/test_discretization.py::test_fit_transform[quantile-expected2]\", \"sklearn/preprocessing/tests/test_discretization.py::test_valid_n_bins\", \"sklearn/preprocessing/tests/test_discretization.py::test_invalid_n_bins\", \"sklearn/preprocessing/tests/test_discretization.py::test_invalid_n_bins_array\", \"sklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[uniform-expected0]\", \"sklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[kmeans-expected1]\", \"sklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[quantile-expected2]\", \"sklearn/preprocessing/tests/test_discretization.py::test_invalid_n_features\", \"sklearn/preprocessing/tests/test_discretization.py::test_same_min_max[uniform]\", \"sklearn/preprocessing/tests/test_discretization.py::test_same_min_max[kmeans]\", \"sklearn/preprocessing/tests/test_discretization.py::test_same_min_max[quantile]\", \"sklearn/preprocessing/tests/test_discretization.py::test_transform_1d_behavior\", \"sklearn/preprocessing/tests/test_discretization.py::test_numeric_stability\", \"sklearn/preprocessing/tests/test_discretization.py::test_invalid_encode_option\", \"sklearn/preprocessing/tests/test_discretization.py::test_encode_options\", \"sklearn/preprocessing/tests/test_discretization.py::test_invalid_strategy_option\", \"sklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[uniform-expected_2bins0-expected_3bins0-expected_5bins0]\", \"sklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[kmeans-expected_2bins1-expected_3bins1-expected_5bins1]\", \"sklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[quantile-expected_2bins2-expected_3bins2-expected_5bins2]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-uniform-expected_inv0]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-kmeans-expected_inv1]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-quantile-expected_inv2]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-uniform-expected_inv0]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-kmeans-expected_inv1]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-quantile-expected_inv2]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-uniform-expected_inv0]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-kmeans-expected_inv1]\", \"sklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-quantile-expected_inv2]\", \"sklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[uniform]\", \"sklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[kmeans]\", \"sklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[quantile]\", \"sklearn/preprocessing/tests/test_discretization.py::test_overwrite\"]",
  "environment_setup_commit": "7813f7efb5b2012412888b69e73d76f2df2b50b6",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.990471",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}