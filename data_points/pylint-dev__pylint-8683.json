{
  "repo": "pylint-dev/pylint",
  "instance_id": "pylint-dev__pylint-8683",
  "base_commit": "aed3c080388a8dc1d44c1a14a5ed243233f77c1c",
  "patch": "diff --git a/pylint/lint/parallel.py b/pylint/lint/parallel.py\n--- a/pylint/lint/parallel.py\n+++ b/pylint/lint/parallel.py\n@@ -52,6 +52,11 @@ def _worker_initialize(\n     _worker_linter.set_reporter(reporters.CollectingReporter())\n     _worker_linter.open()\n \n+    # Re-register dynamic plugins, since the pool does not have access to the\n+    # astroid module that existed when the linter was pickled.\n+    _worker_linter.load_plugin_modules(_worker_linter._dynamic_plugins, force=True)\n+    _worker_linter.load_plugin_configuration()\n+\n     if extra_packages_paths:\n         _augment_sys_path(extra_packages_paths)\n \ndiff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -13,7 +13,7 @@\n import tokenize\n import traceback\n from collections import defaultdict\n-from collections.abc import Callable, Iterator, Sequence\n+from collections.abc import Callable, Iterable, Iterator, Sequence\n from io import TextIOWrapper\n from pathlib import Path\n from re import Pattern\n@@ -363,15 +363,18 @@ def load_default_plugins(self) -> None:\n         checkers.initialize(self)\n         reporters.initialize(self)\n \n-    def load_plugin_modules(self, modnames: list[str]) -> None:\n+    def load_plugin_modules(self, modnames: Iterable[str], force: bool = False) -> None:\n         \"\"\"Check a list of pylint plugins modules, load and register them.\n \n         If a module cannot be loaded, never try to load it again and instead\n         store the error message for later use in ``load_plugin_configuration``\n         below.\n+\n+        If `force` is True (useful when multiprocessing), then the plugin is\n+        reloaded regardless if an entry exists in self._dynamic_plugins.\n         \"\"\"\n         for modname in modnames:\n-            if modname in self._dynamic_plugins:\n+            if modname in self._dynamic_plugins and not force:\n                 continue\n             try:\n                 module = astroid.modutils.load_module_from_name(modname)\n",
  "test_patch": "diff --git a/tests/test_check_parallel.py b/tests/test_check_parallel.py\n--- a/tests/test_check_parallel.py\n+++ b/tests/test_check_parallel.py\n@@ -14,10 +14,11 @@\n from concurrent.futures import ProcessPoolExecutor\n from concurrent.futures.process import BrokenProcessPool\n from pickle import PickleError\n+from typing import TYPE_CHECKING\n+from unittest.mock import patch\n \n import dill\n import pytest\n-from astroid import nodes\n \n import pylint.interfaces\n import pylint.lint.parallel\n@@ -30,6 +31,9 @@\n from pylint.typing import FileItem\n from pylint.utils import LinterStats, ModuleStats\n \n+if TYPE_CHECKING:\n+    from astroid import nodes\n+\n \n def _gen_file_data(idx: int = 0) -> FileItem:\n     \"\"\"Generates a file to use as a stream.\"\"\"\n@@ -182,6 +186,17 @@ def test_worker_initialize_with_package_paths(self) -> None:\n             )\n             assert \"fake-path\" in sys.path\n \n+    def test_worker_initialize_reregisters_custom_plugins(self) -> None:\n+        linter = PyLinter(reporter=Reporter())\n+        linter.load_plugin_modules([\"pylint.extensions.private_import\"])\n+\n+        pickled = dill.dumps(linter)\n+        with patch(\n+            \"pylint.extensions.private_import.register\", side_effect=AssertionError\n+        ):\n+            with pytest.raises(AssertionError):\n+                worker_initialize(linter=pickled)\n+\n     @pytest.mark.needs_two_cores\n     def test_worker_initialize_pickling(self) -> None:\n         \"\"\"Test that we can pickle objects that standard pickling in multiprocessing can't.\n",
  "problem_statement": "fail/warn on using parallel execution with custom plugins\nAccording to documentation:\r\nhttp://pylint.pycqa.org/en/latest/user_guide/run.html#parallel-execution\r\n\r\n> There are some limitations in running checks in parallel in the current implementation. It is not possible to use custom plugins (i.e. --load-plugins option)...\r\n\r\nActually, it is possible but silently broken.\r\n`If this is still by design` then Pylint should inform a user about it in such cases.\r\nAs for now, I could run:\r\n```\r\npylint -j 10 --load-plugins plugin_foo bar.py\r\n```\r\nwithout any warning or error.\r\nUnfortunately, linting results are not the same as a single process linting, but Pylint silently pass. So, results are not predictable.\r\n\r\nProposal: emit a warning or better explicitly fail on using parallel execution with custom Pylint plugins, because people usually don't read the documentation while things works.\r\n\r\n\n",
  "hints_text": "Thanks for opening an issue @stanislavlevin I agree, we should communicate this better. I think we should check that it's still the case, and if so, we should add some runtime warnings to make it more obvious (or maybe raising an error when we detect custom plugins and the parallel mode).\nOriginal ticket:\r\nhttps://pagure.io/freeipa/issue/8116\nThis is still the case - I just spent some time figuring out why my plugin was not loading and found those docs eventually. A warning would have helped greatly.\r\n\r\ncc @PCManticore \nI've started work on this and got\r\n```\r\n        if linter.config.jobs >= 0:\r\n            if self._plugins:\r\n                warnings.warn(\r\n                    \"Running pylint in parallel with custom plugins is not currently supported.\",\r\n                    UserWarning,\r\n                )\r\n                # sys.exit(32)\r\n```\r\n\r\nbut wanted to check if we want both a warning and a crash (sys.exit) or just a warning. With the crash I have to update quite a few tests so I wanted to make sure before investing that time.\nTagging @Pierre-Sassoulas for an opinion on this!\nI'm not super up to date on this issue but imo if the result would be rubbish and plain wrong we need to crash, if it's still usable with a possible issue and we're not sure about it then we should warn. \nGiven original statement\r\n\r\n>Unfortunately, linting results are not the same as a single process linting, but Pylint silently pass. So, results are not predictable.\r\n\r\nsounds like we should indeed crash.\nI'm not sure the issue hasn't been resolved in the meantime.\r\n\r\nHome-Assistant uses `-j 2` be default, even for all CI runs, and also uses custom plugins. There has been the occasional unstable result, but that wasn't because of custom plugins. Rather a result of the way files are passed to works in an unpredictable order which results in different astroid caches for different worker processes.\r\n\r\nOf course that's probably exaggerated at -j 32/64. Maybe instead of adding a `UserWarning` we should instead update the documentation to suggest using a lower number. We could also limit the default to `2` or `4`. That's enough for most projects.\nI thought the most severe problem was #4874, and as far as I know, it's still applicable.\n> Rather a result of the way files are passed to works in an unpredictable order which results in different astroid caches for different worker processes.\r\n\r\nThis one should be fixed in #7747 hopefully.\r\n\r\n> I thought the most severe problem was https://github.com/PyCQA/pylint/issues/4874,\r\n\r\nIndeed and there's of course #2525 which coupled with the small problem of multiprocessing make multiprocessing not worth the small benefit it bring.\nSounds like we should still fix this issue then. Do we agree on both raising a UserWarning and exiting pylint? And we're talking about the case when jobs is 0 OR any positive number other than 1, correct?\n> Do we agree on both raising a UserWarning and exiting pylint? And we're talking about the case when jobs is 0 OR any positive number other than 1, correct?\r\n\r\nI would say yes because the exit code could be 0 because of an issue with the processing.\nHm, as @cdce8p mentions this isn't really an issue for basic plugins. I expect this would slow down the home assistant CI considerably and also have personal CIs that would get slowed down.\r\n\r\nCan we detect if it is a transform plugin?\n@DanielNoord doesn't seem like this is the same conclusion reached above by the other 2 maintainers. What do you all think? @Pierre-Sassoulas  @jacobtylerwalls ?\nI like Daniel's idea, actually. Don't know if it's feasible but sounds promising.\n> Can we detect if it is a transform plugin?\r\n\r\nWhat is a transform plugin?\nA plugin that calls `register_transform`: see [extending docs in astroid](https://pylint.pycqa.org/projects/astroid/en/latest/extending.html).\r\n\r\nThe transforms are stored on the `AstroidManager` object, stored at `pylint.lint.MANAGER`. Maybe compare a before and after snapshot of the the transform registry before and after forking?\nIf not possible, I would suggest trying to find a way to show this warning more explicitly without crashing. This would really hurt the adoption of newer versions by companies/projects that have their own little plugins. I think the people we would annoy with this without reason vs. the people that are actually helped by this is not really balanced.\nTrue, it might be worth investing the extra effort of doing the snapshots (versus just doing a warning) in fixing the root problem in #4874 instead....\nDoesn't this all fall down to us using a single Manager instance for all processes which breaks both transform plugins and creates interdependencies for processes?\nWe might be investing time in fixing a broken multiprocessing approach..\nSounds like the scope of this issue has changed. I'll close the PR and let maintainers update the title and summarize the new requirements.\nI think a warning would be acceptable. Doesn't sound like there's consensus for raising an exception at this juncture.",
  "created_at": "2023-05-13T21:02:16Z",
  "version": "3.0",
  "FAIL_TO_PASS": "[\"tests/test_check_parallel.py::TestCheckParallelFramework::test_worker_initialize_reregisters_custom_plugins\"]",
  "PASS_TO_PASS": "[\"tests/test_check_parallel.py::TestCheckParallelFramework::test_worker_initialize\", \"tests/test_check_parallel.py::TestCheckParallelFramework::test_worker_initialize_with_package_paths\", \"tests/test_check_parallel.py::TestCheckParallelFramework::test_worker_initialize_pickling\", \"tests/test_check_parallel.py::TestCheckParallelFramework::test_worker_check_single_file_uninitialised\", \"tests/test_check_parallel.py::TestCheckParallelFramework::test_worker_check_single_file_no_checkers\", \"tests/test_check_parallel.py::TestCheckParallelFramework::test_linter_with_unpickleable_plugins_is_pickleable\", \"tests/test_check_parallel.py::TestCheckParallelFramework::test_worker_check_sequential_checker\", \"tests/test_check_parallel.py::TestCheckParallel::test_sequential_checkers_work\", \"tests/test_check_parallel.py::TestCheckParallel::test_invoke_single_job\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[1-2-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[1-2-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[1-2-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[2-2-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[2-2-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[2-2-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[3-2-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[3-2-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[3-2-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[3-1-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[3-1-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[3-1-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[10-2-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[10-2-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_compare_workers_to_single_proc[10-2-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[2-2-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[2-2-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[2-2-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[3-2-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[3-2-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[3-2-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[3-1-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[3-1-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[3-1-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[10-2-1]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[10-2-2]\", \"tests/test_check_parallel.py::TestCheckParallel::test_map_reduce[10-2-3]\", \"tests/test_check_parallel.py::TestCheckParallel::test_no_deadlock_due_to_initializer_error\"]",
  "environment_setup_commit": "a0ce6e424e3a208f3aed1cbf6e16c40853bec3c0",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.917520",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}