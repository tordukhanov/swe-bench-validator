{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-10198",
  "base_commit": "726fa36f2556e0d604d85a1de48ba56a8b6550db",
  "patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -240,6 +240,8 @@ class OneHotEncoder(_BaseEncoder):\n     >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n     array([['Male', 1],\n            [None, 2]], dtype=object)\n+    >>> enc.get_feature_names()\n+    array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object)\n \n     See also\n     --------\n@@ -639,6 +641,38 @@ def inverse_transform(self, X):\n \n         return X_tr\n \n+    def get_feature_names(self, input_features=None):\n+        \"\"\"Return feature names for output features.\n+\n+        Parameters\n+        ----------\n+        input_features : list of string, length n_features, optional\n+            String names for input features if available. By default,\n+            \"x0\", \"x1\", ... \"xn_features\" is used.\n+\n+        Returns\n+        -------\n+        output_feature_names : array of string, length n_output_features\n+\n+        \"\"\"\n+        check_is_fitted(self, 'categories_')\n+        cats = self.categories_\n+        if input_features is None:\n+            input_features = ['x%d' % i for i in range(len(cats))]\n+        elif(len(input_features) != len(self.categories_)):\n+            raise ValueError(\n+                \"input_features should have length equal to number of \"\n+                \"features ({}), got {}\".format(len(self.categories_),\n+                                               len(input_features)))\n+\n+        feature_names = []\n+        for i in range(len(cats)):\n+            names = [\n+                input_features[i] + '_' + six.text_type(t) for t in cats[i]]\n+            feature_names.extend(names)\n+\n+        return np.array(feature_names, dtype=object)\n+\n \n class OrdinalEncoder(_BaseEncoder):\n     \"\"\"Encode categorical features as an integer array.\n",
  "test_patch": "diff --git a/sklearn/preprocessing/tests/test_encoders.py b/sklearn/preprocessing/tests/test_encoders.py\n--- a/sklearn/preprocessing/tests/test_encoders.py\n+++ b/sklearn/preprocessing/tests/test_encoders.py\n@@ -1,3 +1,4 @@\n+# -*- coding: utf-8 -*-\n from __future__ import division\n \n import re\n@@ -455,6 +456,47 @@ def test_one_hot_encoder_pandas():\n     assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])\n \n \n+def test_one_hot_encoder_feature_names():\n+    enc = OneHotEncoder()\n+    X = [['Male', 1, 'girl', 2, 3],\n+         ['Female', 41, 'girl', 1, 10],\n+         ['Male', 51, 'boy', 12, 3],\n+         ['Male', 91, 'girl', 21, 30]]\n+\n+    enc.fit(X)\n+    feature_names = enc.get_feature_names()\n+    assert isinstance(feature_names, np.ndarray)\n+\n+    assert_array_equal(['x0_Female', 'x0_Male',\n+                        'x1_1', 'x1_41', 'x1_51', 'x1_91',\n+                        'x2_boy', 'x2_girl',\n+                        'x3_1', 'x3_2', 'x3_12', 'x3_21',\n+                        'x4_3',\n+                        'x4_10', 'x4_30'], feature_names)\n+\n+    feature_names2 = enc.get_feature_names(['one', 'two',\n+                                            'three', 'four', 'five'])\n+\n+    assert_array_equal(['one_Female', 'one_Male',\n+                        'two_1', 'two_41', 'two_51', 'two_91',\n+                        'three_boy', 'three_girl',\n+                        'four_1', 'four_2', 'four_12', 'four_21',\n+                        'five_3', 'five_10', 'five_30'], feature_names2)\n+\n+    with pytest.raises(ValueError, match=\"input_features should have length\"):\n+        enc.get_feature_names(['one', 'two'])\n+\n+\n+def test_one_hot_encoder_feature_names_unicode():\n+    enc = OneHotEncoder()\n+    X = np.array([[u'c❤t1', u'dat2']], dtype=object).T\n+    enc.fit(X)\n+    feature_names = enc.get_feature_names()\n+    assert_array_equal([u'x0_c❤t1', u'x0_dat2'], feature_names)\n+    feature_names = enc.get_feature_names(input_features=[u'n👍me'])\n+    assert_array_equal([u'n👍me_c❤t1', u'n👍me_dat2'], feature_names)\n+\n+\n @pytest.mark.parametrize(\"X\", [\n     [['abc', 2, 55], ['def', 1, 55]],\n     np.array([[10, 2, 55], [20, 1, 55]]),\n",
  "problem_statement": "add get_feature_names to CategoricalEncoder\nWe should add a ``get_feature_names`` to the new CategoricalEncoder, as discussed [here](https://github.com/scikit-learn/scikit-learn/pull/9151#issuecomment-345830056). I think it would be good to be consistent with the PolynomialFeature which allows passing in original feature names to map them to new feature names. Also see #6425.\n",
  "hints_text": "I'd like to try this one.\nIf you haven't contributed before, I suggest you try an issue labeled \"good first issue\". Though this one isn't too hard, eigher.\n@amueller \r\nI think I can handle it.\r\nSo we want something like this right?\r\n\r\n    enc.fit([['male',0], ['female', 1]])\r\n    enc.get_feature_names()\r\n\r\n    >> ['female', 'male', 0, 1]\r\n\r\nCan you please give an example of how original feature names can map to new feature names? I have seen the `get_feature_names()` from PolynomialFeatures, but I don't understand what that means in this case.\nI think the idea is that if you have multiple input features containing the\nvalue \"hello\" they need to be distinguished in the feature names listed for\noutput. so you prefix the value with the input feature name, defaulting to\nx1 etc as in polynomial. clearer?\n\n@jnothman Is this what you mean?\r\n\r\n    enc.fit(  [ [ 'male' ,    0,  1],\r\n                 [ 'female' ,  1 , 0]  ] )\r\n\r\n    enc.get_feature_names(['one','two','three'])\r\n\r\n    >> ['one_female', 'one_male' , 'two_0' , 'two_1' , 'three_0' , 'three_1']\r\n\r\n\r\nAnd in case I don't pass any strings, it should just use `x0` , `x1` and so on for the prefixes right?\nPrecisely.\n\n>\n>\n\nI like the idea to be able to specify input feature names.\r\n\r\nRegarding syntax of combining the two names, as prior art we have eg `DictVectorizer` that does something like `['0=female', '0=male', '1=0', '1=1']` (assuming we use 0 and 1 as the column names for arrays) or Pipelines that uses double underscores (`['0__female', '0__male', '1__0', '1__1']`). Others? \r\nI personally like the `__` a bit more I think, but the fact that this is used by pipelines is for me actually a reason to use `=` in this case. Eg in combination with the ColumnTransformer (assuming this would use the `__` syntax like pipeline), you could then get a feature name like `'cat__0=male'` instead of `'cat__0__male'`.\nAdditional question:\r\n\r\n- if the input is a pandas DataFrame, do we want to preserve the column names (to use instead of 0, 1, ..)? \r\n  (ideally yes IMO, but this would require some extra code as currently it is not detected whether a DataFrame is passed or not, it is just coerced to array)\nno, we shouldn't use column names automatically. it's hard for us to keep\nthem and easy for the user to pass them.\n\n>  it's hard for us to keep them\r\n\r\nIt's not really 'hard':\r\n\r\n```\r\nclass CategoricalEncoder():\r\n\r\n    def fit(self, X, ...):\r\n        ...\r\n        if hasattr(X, 'iloc'):\r\n            self._input_features = X.columns\r\n        ...\r\n\r\n    def get_feature_names(self, input_features=None):\r\n        if input_features is None:\r\n            input_features = self._input_features\r\n        ...\r\n```\r\n\r\nbut of course it is added complexity, and more explicit support for pandas dataframes, which is not necessarily something we want to add (I just don't think 'hard' is the correct reason :-)).\r\n\r\nBut eg if you combine multiple sets of columns and transformers in a ColumnTransformer, it is not always that straightforward for the user to keep track of IMO, because you then need to combine the different sets of selected column into one list to pass to `get_feature_names`.\nNo, then you just need get_feature_names implemented everywhere and let\nPipeline's (not yet) implementation of get_feature_names handle it for you.\n(Note: There remain some problems with this design in a meta-estimator\ncontext.) I've implemented similar within the eli5 package, but we also got\nsomewhat stuck when it came to making arbitrary decisions about how to make\nfeature names for linear transforms like PCA. A structured representation\nrather than a string name might be nice...\n\nOn 23 November 2017 at 10:00, Joris Van den Bossche <\nnotifications@github.com> wrote:\n\n> it's hard for us to keep them\n>\n> It's not really 'hard':\n>\n> class CategoricalEncoder():\n>\n>     def fit(self, X, ...):\n>         ...\n>         if hasattr(X, 'iloc'):\n>             self._input_features = X.columns\n>         ...\n>\n>     def get_feature_names(self, input_features=None):\n>         if input_features is None:\n>             input_features = self._input_features\n>         ...\n>\n> but of course it is added complexity, and more explicit support for pandas\n> dataframes, which is not necessarily something we want to add (I just don't\n> think 'hard' is the correct reason :-)).\n>\n> But eg if you combine multiple sets of columns and transformers in a\n> ColumnTransformer, it is not always that straightforward for the user to\n> keep track of IMO, because you then need to combine the different sets of\n> selected column into one list to pass to get_feature_names.\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/10181#issuecomment-346495657>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz62rb6pYYTi80NzltL4u4biA3_-ARks5s5KePgaJpZM4Ql59C>\n> .\n>\n",
  "created_at": "2017-11-24T16:19:38Z",
  "version": "0.20",
  "FAIL_TO_PASS": "[\"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_feature_names_unicode\"]",
  "PASS_TO_PASS": "[\"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_sparse\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dense\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_deprecationwarnings\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_force_new_behaviour\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categorical_features\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_handle_unknown\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[int32-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float32-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype[float64-float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[int32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float32]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_dtype_pandas[float64]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_set_params\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_inverse\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_categories[string]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories[object-string-cat]\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_unsorted_categories\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_specified_categories_mixed_columns\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[mixed]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[numeric]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder[object]\", \"sklearn/preprocessing/tests/test_encoders.py::test_ordinal_encoder_inverse\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes\", \"sklearn/preprocessing/tests/test_encoders.py::test_encoder_dtypes_pandas\", \"sklearn/preprocessing/tests/test_encoders.py::test_one_hot_encoder_warning\", \"sklearn/preprocessing/tests/test_encoders.py::test_categorical_encoder_stub\"]",
  "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.948927",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}