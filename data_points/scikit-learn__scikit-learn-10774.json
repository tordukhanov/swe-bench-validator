{
  "repo": "scikit-learn/scikit-learn",
  "instance_id": "scikit-learn__scikit-learn-10774",
  "base_commit": "ccbf9975fcf1676f6ac4f311e388529d3a3c4d3f",
  "patch": "diff --git a/sklearn/datasets/california_housing.py b/sklearn/datasets/california_housing.py\n--- a/sklearn/datasets/california_housing.py\n+++ b/sklearn/datasets/california_housing.py\n@@ -50,7 +50,8 @@\n logger = logging.getLogger(__name__)\n \n \n-def fetch_california_housing(data_home=None, download_if_missing=True):\n+def fetch_california_housing(data_home=None, download_if_missing=True,\n+                             return_X_y=False):\n     \"\"\"Loader for the California housing dataset from StatLib.\n \n     Read more in the :ref:`User Guide <datasets>`.\n@@ -65,6 +66,12 @@ def fetch_california_housing(data_home=None, download_if_missing=True):\n         If False, raise a IOError if the data is not locally available\n         instead of trying to download the data from the source site.\n \n+\n+    return_X_y : boolean, default=False. If True, returns ``(data.data,\n+    data.target)`` instead of a Bunch object.\n+\n+        .. versionadded:: 0.20\n+\n     Returns\n     -------\n     dataset : dict-like object with the following attributes:\n@@ -81,6 +88,10 @@ def fetch_california_housing(data_home=None, download_if_missing=True):\n     dataset.DESCR : string\n         Description of the California housing dataset.\n \n+    (data, target) : tuple if ``return_X_y`` is True\n+\n+        .. versionadded:: 0.20\n+\n     Notes\n     ------\n \n@@ -132,6 +143,9 @@ def fetch_california_housing(data_home=None, download_if_missing=True):\n     # target in units of 100,000\n     target = target / 100000.0\n \n+    if return_X_y:\n+        return data, target\n+\n     return Bunch(data=data,\n                  target=target,\n                  feature_names=feature_names,\ndiff --git a/sklearn/datasets/covtype.py b/sklearn/datasets/covtype.py\n--- a/sklearn/datasets/covtype.py\n+++ b/sklearn/datasets/covtype.py\n@@ -42,7 +42,7 @@\n \n \n def fetch_covtype(data_home=None, download_if_missing=True,\n-                  random_state=None, shuffle=False):\n+                  random_state=None, shuffle=False, return_X_y=False):\n     \"\"\"Load the covertype dataset, downloading it if necessary.\n \n     Read more in the :ref:`User Guide <datasets>`.\n@@ -67,6 +67,11 @@ def fetch_covtype(data_home=None, download_if_missing=True,\n     shuffle : bool, default=False\n         Whether to shuffle dataset.\n \n+    return_X_y : boolean, default=False. If True, returns ``(data.data,\n+    data.target)`` instead of a Bunch object.\n+\n+        .. versionadded:: 0.20\n+\n     Returns\n     -------\n     dataset : dict-like object with the following attributes:\n@@ -81,6 +86,9 @@ def fetch_covtype(data_home=None, download_if_missing=True,\n     dataset.DESCR : string\n         Description of the forest covertype dataset.\n \n+    (data, target) : tuple if ``return_X_y`` is True\n+\n+        .. versionadded:: 0.20\n     \"\"\"\n \n     data_home = get_data_home(data_home=data_home)\n@@ -120,4 +128,7 @@ def fetch_covtype(data_home=None, download_if_missing=True,\n         X = X[ind]\n         y = y[ind]\n \n+    if return_X_y:\n+        return X, y\n+\n     return Bunch(data=X, target=y, DESCR=__doc__)\ndiff --git a/sklearn/datasets/kddcup99.py b/sklearn/datasets/kddcup99.py\n--- a/sklearn/datasets/kddcup99.py\n+++ b/sklearn/datasets/kddcup99.py\n@@ -47,7 +47,7 @@\n \n def fetch_kddcup99(subset=None, data_home=None, shuffle=False,\n                    random_state=None,\n-                   percent10=True, download_if_missing=True):\n+                   percent10=True, download_if_missing=True, return_X_y=False):\n     \"\"\"Load and return the kddcup 99 dataset (classification).\n \n     The KDD Cup '99 dataset was created by processing the tcpdump portions\n@@ -155,6 +155,12 @@ def fetch_kddcup99(subset=None, data_home=None, shuffle=False,\n         If False, raise a IOError if the data is not locally available\n         instead of trying to download the data from the source site.\n \n+    return_X_y : boolean, default=False.\n+        If True, returns ``(data, target)`` instead of a Bunch object. See\n+        below for more information about the `data` and `target` object.\n+\n+        .. versionadded:: 0.20\n+\n     Returns\n     -------\n     data : Bunch\n@@ -162,6 +168,9 @@ def fetch_kddcup99(subset=None, data_home=None, shuffle=False,\n         'data', the data to learn and 'target', the regression target for each\n         sample.\n \n+    (data, target) : tuple if ``return_X_y`` is True\n+\n+        .. versionadded:: 0.20\n \n     References\n     ----------\n@@ -230,6 +239,9 @@ def fetch_kddcup99(subset=None, data_home=None, shuffle=False,\n     if shuffle:\n         data, target = shuffle_method(data, target, random_state=random_state)\n \n+    if return_X_y:\n+        return data, target\n+\n     return Bunch(data=data, target=target)\n \n \ndiff --git a/sklearn/datasets/lfw.py b/sklearn/datasets/lfw.py\n--- a/sklearn/datasets/lfw.py\n+++ b/sklearn/datasets/lfw.py\n@@ -238,7 +238,7 @@ def _fetch_lfw_people(data_folder_path, slice_=None, color=False, resize=None,\n def fetch_lfw_people(data_home=None, funneled=True, resize=0.5,\n                      min_faces_per_person=0, color=False,\n                      slice_=(slice(70, 195), slice(78, 172)),\n-                     download_if_missing=True):\n+                     download_if_missing=True, return_X_y=False):\n     \"\"\"Loader for the Labeled Faces in the Wild (LFW) people dataset\n \n     This dataset is a collection of JPEG pictures of famous people\n@@ -287,6 +287,12 @@ def fetch_lfw_people(data_home=None, funneled=True, resize=0.5,\n         If False, raise a IOError if the data is not locally available\n         instead of trying to download the data from the source site.\n \n+    return_X_y : boolean, default=False. If True, returns ``(dataset.data,\n+    dataset.target)`` instead of a Bunch object. See below for more\n+    information about the `dataset.data` and `dataset.target` object.\n+\n+        .. versionadded:: 0.20\n+\n     Returns\n     -------\n     dataset : dict-like object with the following attributes:\n@@ -307,6 +313,11 @@ def fetch_lfw_people(data_home=None, funneled=True, resize=0.5,\n \n     dataset.DESCR : string\n         Description of the Labeled Faces in the Wild (LFW) dataset.\n+\n+    (data, target) : tuple if ``return_X_y`` is True\n+\n+        .. versionadded:: 0.20\n+\n     \"\"\"\n     lfw_home, data_folder_path = check_fetch_lfw(\n         data_home=data_home, funneled=funneled,\n@@ -323,8 +334,13 @@ def fetch_lfw_people(data_home=None, funneled=True, resize=0.5,\n         data_folder_path, resize=resize,\n         min_faces_per_person=min_faces_per_person, color=color, slice_=slice_)\n \n+    X = faces.reshape(len(faces), -1)\n+\n+    if return_X_y:\n+        return X, target\n+\n     # pack the results as a Bunch instance\n-    return Bunch(data=faces.reshape(len(faces), -1), images=faces,\n+    return Bunch(data=X, images=faces,\n                  target=target, target_names=target_names,\n                  DESCR=\"LFW faces dataset\")\n \ndiff --git a/sklearn/datasets/rcv1.py b/sklearn/datasets/rcv1.py\n--- a/sklearn/datasets/rcv1.py\n+++ b/sklearn/datasets/rcv1.py\n@@ -70,7 +70,7 @@\n \n \n def fetch_rcv1(data_home=None, subset='all', download_if_missing=True,\n-               random_state=None, shuffle=False):\n+               random_state=None, shuffle=False, return_X_y=False):\n     \"\"\"Load the RCV1 multilabel dataset, downloading it if necessary.\n \n     Version: RCV1-v2, vectors, full sets, topics multilabels.\n@@ -112,6 +112,12 @@ def fetch_rcv1(data_home=None, subset='all', download_if_missing=True,\n     shuffle : bool, default=False\n         Whether to shuffle dataset.\n \n+    return_X_y : boolean, default=False. If True, returns ``(dataset.data,\n+    dataset.target)`` instead of a Bunch object. See below for more\n+    information about the `dataset.data` and `dataset.target` object.\n+\n+        .. versionadded:: 0.20\n+\n     Returns\n     -------\n     dataset : dict-like object with the following attributes:\n@@ -132,6 +138,10 @@ def fetch_rcv1(data_home=None, subset='all', download_if_missing=True,\n     dataset.DESCR : string\n         Description of the RCV1 dataset.\n \n+    (data, target) : tuple if ``return_X_y`` is True\n+\n+        .. versionadded:: 0.20\n+\n     References\n     ----------\n     Lewis, D. D., Yang, Y., Rose, T. G., & Li, F. (2004). RCV1: A new\n@@ -254,6 +264,9 @@ def fetch_rcv1(data_home=None, subset='all', download_if_missing=True,\n     if shuffle:\n         X, y, sample_id = shuffle_(X, y, sample_id, random_state=random_state)\n \n+    if return_X_y:\n+        return X, y\n+\n     return Bunch(data=X, target=y, sample_id=sample_id,\n                  target_names=categories, DESCR=__doc__)\n \ndiff --git a/sklearn/datasets/twenty_newsgroups.py b/sklearn/datasets/twenty_newsgroups.py\n--- a/sklearn/datasets/twenty_newsgroups.py\n+++ b/sklearn/datasets/twenty_newsgroups.py\n@@ -275,7 +275,7 @@ def fetch_20newsgroups(data_home=None, subset='train', categories=None,\n \n \n def fetch_20newsgroups_vectorized(subset=\"train\", remove=(), data_home=None,\n-                                  download_if_missing=True):\n+                                  download_if_missing=True, return_X_y=False):\n     \"\"\"Load the 20 newsgroups dataset and transform it into tf-idf vectors.\n \n     This is a convenience function; the tf-idf transformation is done using the\n@@ -309,12 +309,21 @@ def fetch_20newsgroups_vectorized(subset=\"train\", remove=(), data_home=None,\n         If False, raise an IOError if the data is not locally available\n         instead of trying to download the data from the source site.\n \n+    return_X_y : boolean, default=False. If True, returns ``(data.data,\n+    data.target)`` instead of a Bunch object.\n+\n+        .. versionadded:: 0.20\n+\n     Returns\n     -------\n     bunch : Bunch object\n         bunch.data: sparse matrix, shape [n_samples, n_features]\n         bunch.target: array, shape [n_samples]\n         bunch.target_names: list, length [n_classes]\n+\n+    (data, target) : tuple if ``return_X_y`` is True\n+\n+        .. versionadded:: 0.20\n     \"\"\"\n     data_home = get_data_home(data_home=data_home)\n     filebase = '20newsgroup_vectorized'\n@@ -369,4 +378,7 @@ def fetch_20newsgroups_vectorized(subset=\"train\", remove=(), data_home=None,\n         raise ValueError(\"%r is not a valid subset: should be one of \"\n                          \"['train', 'test', 'all']\" % subset)\n \n+    if return_X_y:\n+        return data, target\n+\n     return Bunch(data=data, target=target, target_names=target_names)\n",
  "test_patch": "diff --git a/sklearn/datasets/tests/test_20news.py b/sklearn/datasets/tests/test_20news.py\n--- a/sklearn/datasets/tests/test_20news.py\n+++ b/sklearn/datasets/tests/test_20news.py\n@@ -5,6 +5,8 @@\n from sklearn.utils.testing import assert_equal\n from sklearn.utils.testing import assert_true\n from sklearn.utils.testing import SkipTest\n+from sklearn.datasets.tests.test_common import check_return_X_y\n+from functools import partial\n \n from sklearn import datasets\n \n@@ -77,6 +79,10 @@ def test_20news_vectorized():\n     assert_equal(bunch.target.shape[0], 7532)\n     assert_equal(bunch.data.dtype, np.float64)\n \n+    # test return_X_y option\n+    fetch_func = partial(datasets.fetch_20newsgroups_vectorized, subset='test')\n+    check_return_X_y(bunch, fetch_func)\n+\n     # test subset = all\n     bunch = datasets.fetch_20newsgroups_vectorized(subset='all')\n     assert_true(sp.isspmatrix_csr(bunch.data))\ndiff --git a/sklearn/datasets/tests/test_base.py b/sklearn/datasets/tests/test_base.py\n--- a/sklearn/datasets/tests/test_base.py\n+++ b/sklearn/datasets/tests/test_base.py\n@@ -5,6 +5,7 @@\n import numpy\n from pickle import loads\n from pickle import dumps\n+from functools import partial\n \n from sklearn.datasets import get_data_home\n from sklearn.datasets import clear_data_home\n@@ -19,6 +20,7 @@\n from sklearn.datasets import load_boston\n from sklearn.datasets import load_wine\n from sklearn.datasets.base import Bunch\n+from sklearn.datasets.tests.test_common import check_return_X_y\n \n from sklearn.externals.six import b, u\n from sklearn.externals._pilutil import pillow_installed\n@@ -27,7 +29,6 @@\n from sklearn.utils.testing import assert_true\n from sklearn.utils.testing import assert_equal\n from sklearn.utils.testing import assert_raises\n-from sklearn.utils.testing import assert_array_equal\n \n \n DATA_HOME = tempfile.mkdtemp(prefix=\"scikit_learn_data_home_test_\")\n@@ -139,11 +140,7 @@ def test_load_digits():\n     assert_equal(numpy.unique(digits.target).size, 10)\n \n     # test return_X_y option\n-    X_y_tuple = load_digits(return_X_y=True)\n-    bunch = load_digits()\n-    assert_true(isinstance(X_y_tuple, tuple))\n-    assert_array_equal(X_y_tuple[0], bunch.data)\n-    assert_array_equal(X_y_tuple[1], bunch.target)\n+    check_return_X_y(digits, partial(load_digits))\n \n \n def test_load_digits_n_class_lt_10():\n@@ -177,11 +174,7 @@ def test_load_diabetes():\n     assert_true(res.DESCR)\n \n     # test return_X_y option\n-    X_y_tuple = load_diabetes(return_X_y=True)\n-    bunch = load_diabetes()\n-    assert_true(isinstance(X_y_tuple, tuple))\n-    assert_array_equal(X_y_tuple[0], bunch.data)\n-    assert_array_equal(X_y_tuple[1], bunch.target)\n+    check_return_X_y(res, partial(load_diabetes))\n \n \n def test_load_linnerud():\n@@ -194,11 +187,7 @@ def test_load_linnerud():\n     assert_true(os.path.exists(res.target_filename))\n \n     # test return_X_y option\n-    X_y_tuple = load_linnerud(return_X_y=True)\n-    bunch = load_linnerud()\n-    assert_true(isinstance(X_y_tuple, tuple))\n-    assert_array_equal(X_y_tuple[0], bunch.data)\n-    assert_array_equal(X_y_tuple[1], bunch.target)\n+    check_return_X_y(res, partial(load_linnerud))\n \n \n def test_load_iris():\n@@ -210,11 +199,7 @@ def test_load_iris():\n     assert_true(os.path.exists(res.filename))\n \n     # test return_X_y option\n-    X_y_tuple = load_iris(return_X_y=True)\n-    bunch = load_iris()\n-    assert_true(isinstance(X_y_tuple, tuple))\n-    assert_array_equal(X_y_tuple[0], bunch.data)\n-    assert_array_equal(X_y_tuple[1], bunch.target)\n+    check_return_X_y(res, partial(load_iris))\n \n \n def test_load_wine():\n@@ -225,11 +210,7 @@ def test_load_wine():\n     assert_true(res.DESCR)\n \n     # test return_X_y option\n-    X_y_tuple = load_wine(return_X_y=True)\n-    bunch = load_wine()\n-    assert_true(isinstance(X_y_tuple, tuple))\n-    assert_array_equal(X_y_tuple[0], bunch.data)\n-    assert_array_equal(X_y_tuple[1], bunch.target)\n+    check_return_X_y(res, partial(load_wine))\n \n \n def test_load_breast_cancer():\n@@ -241,11 +222,7 @@ def test_load_breast_cancer():\n     assert_true(os.path.exists(res.filename))\n \n     # test return_X_y option\n-    X_y_tuple = load_breast_cancer(return_X_y=True)\n-    bunch = load_breast_cancer()\n-    assert_true(isinstance(X_y_tuple, tuple))\n-    assert_array_equal(X_y_tuple[0], bunch.data)\n-    assert_array_equal(X_y_tuple[1], bunch.target)\n+    check_return_X_y(res, partial(load_breast_cancer))\n \n \n def test_load_boston():\n@@ -257,11 +234,7 @@ def test_load_boston():\n     assert_true(os.path.exists(res.filename))\n \n     # test return_X_y option\n-    X_y_tuple = load_boston(return_X_y=True)\n-    bunch = load_boston()\n-    assert_true(isinstance(X_y_tuple, tuple))\n-    assert_array_equal(X_y_tuple[0], bunch.data)\n-    assert_array_equal(X_y_tuple[1], bunch.target)\n+    check_return_X_y(res, partial(load_boston))\n \n \n def test_loads_dumps_bunch():\ndiff --git a/sklearn/datasets/tests/test_california_housing.py b/sklearn/datasets/tests/test_california_housing.py\nnew file mode 100644\n--- /dev/null\n+++ b/sklearn/datasets/tests/test_california_housing.py\n@@ -0,0 +1,26 @@\n+\"\"\"Test the california_housing loader.\n+\n+Skipped if california_housing is not already downloaded to data_home.\n+\"\"\"\n+\n+from sklearn.datasets import fetch_california_housing\n+from sklearn.utils.testing import SkipTest\n+from sklearn.datasets.tests.test_common import check_return_X_y\n+from functools import partial\n+\n+\n+def fetch(*args, **kwargs):\n+    return fetch_california_housing(*args, download_if_missing=False, **kwargs)\n+\n+\n+def test_fetch():\n+    try:\n+        data = fetch()\n+    except IOError:\n+        raise SkipTest(\"California housing dataset can not be loaded.\")\n+    assert((20640, 8) == data.data.shape)\n+    assert((20640, ) == data.target.shape)\n+\n+    # test return_X_y option\n+    fetch_func = partial(fetch)\n+    check_return_X_y(data, fetch_func)\ndiff --git a/sklearn/datasets/tests/test_common.py b/sklearn/datasets/tests/test_common.py\nnew file mode 100644\n--- /dev/null\n+++ b/sklearn/datasets/tests/test_common.py\n@@ -0,0 +1,9 @@\n+\"\"\"Test loaders for common functionality.\n+\"\"\"\n+\n+\n+def check_return_X_y(bunch, fetch_func_partial):\n+    X_y_tuple = fetch_func_partial(return_X_y=True)\n+    assert(isinstance(X_y_tuple, tuple))\n+    assert(X_y_tuple[0].shape == bunch.data.shape)\n+    assert(X_y_tuple[1].shape == bunch.target.shape)\ndiff --git a/sklearn/datasets/tests/test_covtype.py b/sklearn/datasets/tests/test_covtype.py\n--- a/sklearn/datasets/tests/test_covtype.py\n+++ b/sklearn/datasets/tests/test_covtype.py\n@@ -5,6 +5,8 @@\n \n from sklearn.datasets import fetch_covtype\n from sklearn.utils.testing import assert_equal, SkipTest\n+from sklearn.datasets.tests.test_common import check_return_X_y\n+from functools import partial\n \n \n def fetch(*args, **kwargs):\n@@ -28,3 +30,7 @@ def test_fetch():\n     y1, y2 = data1['target'], data2['target']\n     assert_equal((X1.shape[0],), y1.shape)\n     assert_equal((X1.shape[0],), y2.shape)\n+\n+    # test return_X_y option\n+    fetch_func = partial(fetch)\n+    check_return_X_y(data1, fetch_func)\ndiff --git a/sklearn/datasets/tests/test_kddcup99.py b/sklearn/datasets/tests/test_kddcup99.py\n--- a/sklearn/datasets/tests/test_kddcup99.py\n+++ b/sklearn/datasets/tests/test_kddcup99.py\n@@ -6,7 +6,10 @@\n \"\"\"\n \n from sklearn.datasets import fetch_kddcup99\n+from sklearn.datasets.tests.test_common import check_return_X_y\n from sklearn.utils.testing import assert_equal, SkipTest\n+from functools import partial\n+\n \n \n def test_percent10():\n@@ -38,6 +41,9 @@ def test_percent10():\n     assert_equal(data.data.shape, (9571, 3))\n     assert_equal(data.target.shape, (9571,))\n \n+    fetch_func = partial(fetch_kddcup99, 'smtp')\n+    check_return_X_y(data, fetch_func)\n+\n \n def test_shuffle():\n     try:\ndiff --git a/sklearn/datasets/tests/test_lfw.py b/sklearn/datasets/tests/test_lfw.py\n--- a/sklearn/datasets/tests/test_lfw.py\n+++ b/sklearn/datasets/tests/test_lfw.py\n@@ -13,6 +13,7 @@\n import shutil\n import tempfile\n import numpy as np\n+from functools import partial\n from sklearn.externals import six\n from sklearn.externals._pilutil import pillow_installed, imsave\n from sklearn.datasets import fetch_lfw_pairs\n@@ -22,6 +23,7 @@\n from sklearn.utils.testing import assert_equal\n from sklearn.utils.testing import SkipTest\n from sklearn.utils.testing import assert_raises\n+from sklearn.datasets.tests.test_common import check_return_X_y\n \n \n SCIKIT_LEARN_DATA = tempfile.mkdtemp(prefix=\"scikit_learn_lfw_test_\")\n@@ -139,6 +141,13 @@ def test_load_fake_lfw_people():\n                        ['Abdelatif Smith', 'Abhati Kepler', 'Camara Alvaro',\n                         'Chen Dupont', 'John Lee', 'Lin Bauman', 'Onur Lopez'])\n \n+    # test return_X_y option\n+    fetch_func = partial(fetch_lfw_people, data_home=SCIKIT_LEARN_DATA,\n+                         resize=None,\n+                         slice_=None, color=True,\n+                         download_if_missing=False)\n+    check_return_X_y(lfw_people, fetch_func)\n+\n \n def test_load_fake_lfw_people_too_restrictive():\n     assert_raises(ValueError, fetch_lfw_people, data_home=SCIKIT_LEARN_DATA,\ndiff --git a/sklearn/datasets/tests/test_rcv1.py b/sklearn/datasets/tests/test_rcv1.py\n--- a/sklearn/datasets/tests/test_rcv1.py\n+++ b/sklearn/datasets/tests/test_rcv1.py\n@@ -6,7 +6,9 @@\n import errno\n import scipy.sparse as sp\n import numpy as np\n+from functools import partial\n from sklearn.datasets import fetch_rcv1\n+from sklearn.datasets.tests.test_common import check_return_X_y\n from sklearn.utils.testing import assert_almost_equal\n from sklearn.utils.testing import assert_array_equal\n from sklearn.utils.testing import assert_equal\n@@ -53,6 +55,11 @@ def test_fetch_rcv1():\n     X2, Y2 = data2.data, data2.target\n     s2 = data2.sample_id\n \n+    # test return_X_y option\n+    fetch_func = partial(fetch_rcv1, shuffle=False, subset='train',\n+                         download_if_missing=False)\n+    check_return_X_y(data2, fetch_func)\n+\n     # The first 23149 samples are the training samples\n     assert_array_equal(np.sort(s1[:23149]), np.sort(s2))\n \n",
  "problem_statement": "return_X_y should be available on more dataset loaders/fetchers\nVersion 0.18 added a `return_X_y` option to `load_iris` et al., but not to, for example, `fetch_kddcup99`.\r\n\r\nAll dataset loaders that currently return Bunches should also be able to return (X, y).\n",
  "hints_text": "Looks like a doable first issue - may I take it on?\nSure.\n\nOn 1 March 2018 at 12:59, Chris Catalfo <notifications@github.com> wrote:\n\n> Looks like a doable first issue - may I take it on?\n>\n> —\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/scikit-learn/scikit-learn/issues/10734#issuecomment-369448829>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAEz6wB-I558FOQMikXvOGJLH12xAcD7ks5tZ1XygaJpZM4SXlSa>\n> .\n>\n\nPlease refer to the implementation and testing of load_iris's similar\nfeature.\n\nThanks - will do.",
  "created_at": "2018-03-08T02:48:49Z",
  "version": "0.20",
  "FAIL_TO_PASS": "[\"sklearn/datasets/tests/test_lfw.py::test_load_fake_lfw_people\"]",
  "PASS_TO_PASS": "[\"sklearn/datasets/tests/test_base.py::test_data_home\", \"sklearn/datasets/tests/test_base.py::test_default_empty_load_files\", \"sklearn/datasets/tests/test_base.py::test_default_load_files\", \"sklearn/datasets/tests/test_base.py::test_load_files_w_categories_desc_and_encoding\", \"sklearn/datasets/tests/test_base.py::test_load_files_wo_load_content\", \"sklearn/datasets/tests/test_base.py::test_load_sample_images\", \"sklearn/datasets/tests/test_base.py::test_load_digits\", \"sklearn/datasets/tests/test_base.py::test_load_digits_n_class_lt_10\", \"sklearn/datasets/tests/test_base.py::test_load_sample_image\", \"sklearn/datasets/tests/test_base.py::test_load_missing_sample_image_error\", \"sklearn/datasets/tests/test_base.py::test_load_diabetes\", \"sklearn/datasets/tests/test_base.py::test_load_linnerud\", \"sklearn/datasets/tests/test_base.py::test_load_iris\", \"sklearn/datasets/tests/test_base.py::test_load_wine\", \"sklearn/datasets/tests/test_base.py::test_load_breast_cancer\", \"sklearn/datasets/tests/test_base.py::test_load_boston\", \"sklearn/datasets/tests/test_base.py::test_loads_dumps_bunch\", \"sklearn/datasets/tests/test_base.py::test_bunch_pickle_generated_with_0_16_and_read_with_0_17\", \"sklearn/datasets/tests/test_base.py::test_bunch_dir\", \"sklearn/datasets/tests/test_lfw.py::test_load_empty_lfw_people\", \"sklearn/datasets/tests/test_lfw.py::test_load_fake_lfw_people_too_restrictive\", \"sklearn/datasets/tests/test_lfw.py::test_load_empty_lfw_pairs\", \"sklearn/datasets/tests/test_lfw.py::test_load_fake_lfw_pairs\"]",
  "environment_setup_commit": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1",
  "_download_metadata": {
    "downloaded_at": "2025-10-07T21:23:30.954329",
    "dataset_name": "swe-bench",
    "split": "test",
    "downloader_version": "0.1.0"
  }
}